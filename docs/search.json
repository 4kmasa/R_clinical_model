[
  {
    "objectID": "model-compare_tidymodels.html#加载数据和r包",
    "href": "model-compare_tidymodels.html#加载数据和r包",
    "title": "42  tidymodels实现多模型比较",
    "section": "42.1 加载数据和R包",
    "text": "42.1 加载数据和R包\n没有安装的R包的自己安装下~\n\nrm(list = ls())\nsuppressPackageStartupMessages(library(tidyverse))\n## Warning: package 'ggplot2' was built under R version 4.2.3\n## Warning: package 'tibble' was built under R version 4.2.3\n## Warning: package 'dplyr' was built under R version 4.2.3\nsuppressPackageStartupMessages(library(tidymodels))\n## Warning: package 'tidymodels' was built under R version 4.2.3\n## Warning: package 'recipes' was built under R version 4.2.3\n## Warning: package 'yardstick' was built under R version 4.2.3\ntidymodels_prefer()\n\n由于要做演示用，肯定要一份比较好的数据才能说明问题，今天用的这份数据，结果变量是一个二分类的。\n一共有91976行，26列，其中play_type是结果变量，因子型，其余列都是预测变量。\n\nall_plays &lt;- read_rds(\"./datasets/all_plays.rds\")\nglimpse(all_plays)\n## Rows: 91,976\n## Columns: 26\n## $ game_id                    &lt;dbl&gt; 2017090700, 2017090700, 2017090700, 2017090…\n## $ posteam                    &lt;chr&gt; \"NE\", \"NE\", \"NE\", \"NE\", \"NE\", \"NE\", \"NE\", \"…\n## $ play_type                  &lt;fct&gt; pass, pass, run, run, pass, run, pass, pass…\n## $ yards_gained               &lt;dbl&gt; 0, 8, 8, 3, 19, 5, 16, 0, 2, 7, 0, 3, 10, 0…\n## $ ydstogo                    &lt;dbl&gt; 10, 10, 2, 10, 7, 10, 5, 2, 2, 10, 10, 10, …\n## $ down                       &lt;ord&gt; 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 1, 2, 3, 1, 2…\n## $ game_seconds_remaining     &lt;dbl&gt; 3595, 3589, 3554, 3532, 3506, 3482, 3455, 3…\n## $ yardline_100               &lt;dbl&gt; 73, 73, 65, 57, 54, 35, 30, 2, 2, 75, 32, 3…\n## $ qtr                        &lt;ord&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n## $ posteam_score              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7…\n## $ defteam                    &lt;chr&gt; \"KC\", \"KC\", \"KC\", \"KC\", \"KC\", \"KC\", \"KC\", \"…\n## $ defteam_score              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0…\n## $ score_differential         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, -7, 7, 7, 7, 7, …\n## $ shotgun                    &lt;fct&gt; 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0…\n## $ no_huddle                  &lt;fct&gt; 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n## $ posteam_timeouts_remaining &lt;fct&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n## $ defteam_timeouts_remaining &lt;fct&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n## $ wp                         &lt;dbl&gt; 0.5060180, 0.4840546, 0.5100098, 0.5529816,…\n## $ goal_to_go                 &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n## $ half_seconds_remaining     &lt;dbl&gt; 1795, 1789, 1754, 1732, 1706, 1682, 1655, 1…\n## $ total_runs                 &lt;dbl&gt; 0, 0, 0, 1, 2, 2, 3, 3, 3, 0, 4, 4, 4, 5, 5…\n## $ total_pass                 &lt;dbl&gt; 0, 1, 2, 2, 2, 3, 3, 4, 5, 0, 5, 6, 7, 7, 8…\n## $ previous_play              &lt;fct&gt; First play of Drive, pass, pass, run, run, …\n## $ in_red_zone                &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1…\n## $ in_fg_range                &lt;fct&gt; 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1…\n## $ two_min_drill              &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…"
  },
  {
    "objectID": "model-compare_tidymodels.html#数据划分",
    "href": "model-compare_tidymodels.html#数据划分",
    "title": "42  tidymodels实现多模型比较",
    "section": "42.2 数据划分",
    "text": "42.2 数据划分\n把75%的数据用于训练集，剩下的做测试集。\n\nset.seed(20220520)\n\n# 数据划分，根据play_type分层\nsplit_pbp &lt;- initial_split(all_plays, 0.75, strata = play_type)\n\ntrain_data &lt;- training(split_pbp) # 训练集\ntest_data &lt;- testing(split_pbp) # 测试集"
  },
  {
    "objectID": "model-compare_tidymodels.html#数据预处理",
    "href": "model-compare_tidymodels.html#数据预处理",
    "title": "42  tidymodels实现多模型比较",
    "section": "42.3 数据预处理",
    "text": "42.3 数据预处理\n\npbp_rec &lt;- recipe(play_type ~ ., data = train_data)  %&gt;%\n  step_rm(half_seconds_remaining,yards_gained, game_id) %&gt;% # 移除这3列\n  step_string2factor(posteam, defteam) %&gt;%  # 变为因子类型\n  #update_role(yards_gained, game_id, new_role = \"ID\") %&gt;% \n  # 去掉高度相关的变量\n  step_corr(all_numeric(), threshold = 0.7) %&gt;% \n  step_center(all_numeric()) %&gt;%  # 中心化\n  step_zv(all_predictors())  # 去掉零方差变量"
  },
  {
    "objectID": "model-compare_tidymodels.html#建立多个模型",
    "href": "model-compare_tidymodels.html#建立多个模型",
    "title": "42  tidymodels实现多模型比较",
    "section": "42.4 建立多个模型",
    "text": "42.4 建立多个模型\n\n42.4.1 logistic\n选择模型，连接数据预处理步骤。\n\nlm_spec &lt;- logistic_reg(mode = \"classification\",engine = \"glm\")\nlm_wflow &lt;- workflow() %&gt;% \n  add_recipe(pbp_rec) %&gt;% \n  add_model(lm_spec)\n\n建立模型：\n\nfit_lm &lt;- lm_wflow %&gt;% fit(data = train_data)\n\n应用于测试集：\n\npred_lm &lt;- select(test_data, play_type) %&gt;% \n  bind_cols(predict(fit_lm, test_data, type = \"prob\")) %&gt;% \n  bind_cols(predict(fit_lm, test_data))\n## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n## prediction from a rank-deficient fit may be misleading\n\n## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n## prediction from a rank-deficient fit may be misleading\n\npred_lm\n## # A tibble: 22,995 × 4\n##    play_type .pred_pass .pred_run .pred_class\n##    &lt;fct&gt;          &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;      \n##  1 pass           0.399     0.601 run        \n##  2 pass           0.817     0.183 pass       \n##  3 pass           0.754     0.246 pass       \n##  4 pass           0.683     0.317 pass       \n##  5 run            0.327     0.673 run        \n##  6 run            0.615     0.385 pass       \n##  7 pass           0.591     0.409 pass       \n##  8 run            0.669     0.331 pass       \n##  9 pass           0.767     0.233 pass       \n## 10 pass           0.437     0.563 run        \n## # ℹ 22,985 more rows\n\n查看模型表现：\n\n# 选择多种评价指标\nmetricsets &lt;- metric_set(accuracy, mcc, f_meas, j_index)\n\npred_lm %&gt;% metricsets(truth = play_type, estimate = .pred_class)\n## # A tibble: 4 × 3\n##   .metric  .estimator .estimate\n##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n## 1 accuracy binary         0.724\n## 2 mcc      binary         0.423\n## 3 f_meas   binary         0.774\n## 4 j_index  binary         0.416\n\n大家最喜欢的AUC：\n\npred_lm %&gt;% roc_auc(truth = play_type, .pred_pass)\n## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 roc_auc binary         0.781\n\n可视化结果，首先是大家喜闻乐见的ROC曲线：\n\npred_lm %&gt;% roc_curve(truth = play_type, .pred_pass) %&gt;% \n  autoplot()\n\n\n\n\npr曲线：\n\npred_lm %&gt;% pr_curve(truth = play_type, .pred_pass) %&gt;% \n  autoplot()\n\n\n\n\ngain_curve：\n\npred_lm %&gt;% gain_curve(truth = play_type, .pred_pass) %&gt;% \n  autoplot()\n\n\n\n\nlift_curve：\n\npred_lm %&gt;% lift_curve(truth = play_type, .pred_pass) %&gt;% \n  autoplot()\n\n\n\n\n混淆矩阵：\n\npred_lm %&gt;% \n  conf_mat(play_type,.pred_class) %&gt;% \n  autoplot()\n\n\n\n\n\n\n42.4.2 knn\nk最近邻法，和上面的逻辑回归一模一样的流程。\n首先也是选择模型，连接数据预处理步骤：\n\nknn_spec &lt;- nearest_neighbor(mode = \"classification\", engine = \"kknn\")\n\nknn_wflow &lt;- workflow() %&gt;% \n  add_recipe(pbp_rec) %&gt;% \n  add_model(knn_spec)\n\n建立模型：\n\nlibrary(kknn)\nfit_knn &lt;- knn_wflow %&gt;% \n  fit(train_data)\n\n#saveRDS(fit_knn,file = \"datasets/fit_knn.rds\")\n\n应用于测试集：\n\npred_knn &lt;- test_data %&gt;% select(play_type) %&gt;% \n  bind_cols(predict(fit_knn, test_data, type = \"prob\")) %&gt;% \n  bind_cols(predict(fit_knn, test_data, type = \"class\"))\n\n查看模型表现：\n\nmetricsets &lt;- metric_set(accuracy, mcc, f_meas, j_index)\n\npred_knn %&gt;% metricsets(truth = play_type, estimate = .pred_class)\n## # A tibble: 4 × 3\n##   .metric  .estimator .estimate\n##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n## 1 accuracy binary         0.672\n## 2 mcc      binary         0.317\n## 3 f_meas   binary         0.727\n## 4 j_index  binary         0.315\n\n\npred_knn %&gt;% roc_auc(play_type, .pred_pass)\n## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 roc_auc binary         0.718\n\n可视化模型的部分就不说了，和上面的一模一样！\n\n\n42.4.3 随机森林\n同样的流程来第3遍！\n\nrf_spec &lt;- rand_forest(mode = \"classification\") %&gt;% \n  set_engine(\"ranger\",importance = \"permutation\")\nrf_wflow &lt;- workflow() %&gt;% \n  add_recipe(pbp_rec) %&gt;% \n  add_model(rf_spec)\n\n建立模型：\n\nfit_rf &lt;- rf_wflow %&gt;% \n  fit(train_data)\n\n应用于测试集：\n\npred_rf &lt;- test_data %&gt;% select(play_type) %&gt;% \n  bind_cols(predict(fit_rf, test_data, type = \"prob\")) %&gt;% \n  bind_cols(predict(fit_rf, test_data, type = \"class\"))\n\n查看模型表现：\n\npred_rf %&gt;% metricsets(truth = play_type, estimate = .pred_class)\n## # A tibble: 4 × 3\n##   .metric  .estimator .estimate\n##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n## 1 accuracy binary         0.731\n## 2 mcc      binary         0.441\n## 3 f_meas   binary         0.774\n## 4 j_index  binary         0.439\n\n\npred_rf %&gt;% conf_mat(truth = play_type, estimate = .pred_class)\n##           Truth\n## Prediction  pass   run\n##       pass 10622  3226\n##       run   2962  6185\n\n\npred_rf %&gt;% roc_auc(play_type, .pred_pass)\n## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 roc_auc binary         0.799\n\n下面给大家手动画一个校准曲线。\n两种画法，差别不大，主要是分组方法不一样，第2种分组方法是大家常见的哦~\n\ncalibration_df &lt;- pred_rf %&gt;% \n   mutate(pass = if_else(play_type == \"pass\", 1, 0),\n          pred_rnd = round(.pred_pass, 2)\n          ) %&gt;% \n  group_by(pred_rnd) %&gt;% \n  dplyr::summarize(mean_pred = mean(.pred_pass),\n            mean_obs = mean(pass),\n            n = n()\n            )\n\nggplot(calibration_df, aes(mean_pred, mean_obs))+ \n  geom_point(aes(size = n), alpha = 0.5)+\n  geom_abline(linetype = \"dashed\")+\n  theme_minimal()\n\n\n\n\n第2种方法：\n\ncali_df &lt;- pred_rf %&gt;% \n  arrange(.pred_pass) %&gt;% \n  mutate(pass = if_else(play_type == \"pass\", 1, 0),\n         group = c(rep(1:249,each=92), rep(250,87))\n         ) %&gt;% \n  group_by(group) %&gt;% \n  dplyr::summarise(mean_pred = mean(.pred_pass),\n            mean_obs = mean(pass)\n            )\n\n\ncali_plot &lt;- ggplot(cali_df, aes(mean_pred, mean_obs))+ \n  geom_point(alpha = 0.5)+\n  geom_abline(linetype = \"dashed\")+\n  theme_minimal()\n\ncali_plot\n\n\n\n\n随机森林这种方法是可以计算变量重要性的，当然也是能把结果可视化的。\n给大家演示下如何可视化随机森林结果的变量重要性：\n\nlibrary(vip)\n\nfit_rf %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip(num_features = 10)\n\n\n\n\n\n\n42.4.4 决策树\n同样的流程来第4遍！不知道你看懂了没有。。。\n\ntree_spec &lt;- decision_tree(mode = \"classification\",engine = \"rpart\")\ntree_wflow &lt;- workflow() %&gt;% \n  add_recipe(pbp_rec) %&gt;% \n  add_model(tree_spec)\n\n建立模型：\n\nfit_tree &lt;- tree_wflow %&gt;% \n  fit(train_data)\n\n应用于测试集：\n\npred_tree &lt;- test_data %&gt;% select(play_type) %&gt;% \n  bind_cols(predict(fit_tree, test_data, type = \"prob\")) %&gt;% \n  bind_cols(predict(fit_tree, test_data, type = \"class\"))\n\n查看结果：\n\npred_tree %&gt;% roc_auc(play_type, .pred_pass)\n## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 roc_auc binary         0.706\n\n\npred_tree %&gt;% metricsets(truth = play_type, estimate = .pred_class)\n## # A tibble: 4 × 3\n##   .metric  .estimator .estimate\n##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n## 1 accuracy binary         0.721\n## 2 mcc      binary         0.417\n## 3 f_meas   binary         0.770\n## 4 j_index  binary         0.411"
  },
  {
    "objectID": "model-compare_tidymodels.html#交叉验证",
    "href": "model-compare_tidymodels.html#交叉验证",
    "title": "42  tidymodels实现多模型比较",
    "section": "42.5 交叉验证",
    "text": "42.5 交叉验证\n交叉验证也是大家喜闻乐见的，就用随机森林给大家顺便演示下交叉验证。\n首先要选择重抽样方法，这里我们选择10折交叉验证：\n\nset.seed(20220520)\n\nfolds &lt;- vfold_cv(train_data, v = 10)\nfolds\n## #  10-fold cross-validation \n## # A tibble: 10 × 2\n##    splits               id    \n##    &lt;list&gt;               &lt;chr&gt; \n##  1 &lt;split [62082/6899]&gt; Fold01\n##  2 &lt;split [62083/6898]&gt; Fold02\n##  3 &lt;split [62083/6898]&gt; Fold03\n##  4 &lt;split [62083/6898]&gt; Fold04\n##  5 &lt;split [62083/6898]&gt; Fold05\n##  6 &lt;split [62083/6898]&gt; Fold06\n##  7 &lt;split [62083/6898]&gt; Fold07\n##  8 &lt;split [62083/6898]&gt; Fold08\n##  9 &lt;split [62083/6898]&gt; Fold09\n## 10 &lt;split [62083/6898]&gt; Fold10\n\n然后就是让模型在训练集上跑起来：\n\nkeep_pred &lt;- control_resamples(save_pred = T, verbose = T)\n\nset.seed(20220520)\n\nlibrary(doParallel)\n\ncl &lt;- makePSOCKcluster(12) # 加速，用12个线程\nregisterDoParallel(cl)\n\nrf_res &lt;- fit_resamples(rf_wflow, resamples = folds, control = keep_pred)\n\nstopCluster(cl)\n\n#saveRDS(rf_res,file = \"datasets/rf_res.rds\")\n\n查看模型表现：\n\nrf_res %&gt;% \n  collect_metrics(summarize = T)\n## # A tibble: 2 × 6\n##   .metric  .estimator  mean     n std_err .config             \n##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n## 1 accuracy binary     0.732    10 0.00157 Preprocessor1_Model1\n## 2 roc_auc  binary     0.799    10 0.00193 Preprocessor1_Model1\n\n查看具体的结果：\n\nrf_res %&gt;% collect_predictions()\n## # A tibble: 68,981 × 7\n##    id     .pred_pass .pred_run  .row .pred_class play_type .config             \n##    &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt; &lt;fct&gt;       &lt;fct&gt;     &lt;chr&gt;               \n##  1 Fold01      0.572    0.428      6 pass        pass      Preprocessor1_Model1\n##  2 Fold01      0.470    0.530      8 run         pass      Preprocessor1_Model1\n##  3 Fold01      0.898    0.102     22 pass        pass      Preprocessor1_Model1\n##  4 Fold01      0.915    0.0847    69 pass        pass      Preprocessor1_Model1\n##  5 Fold01      0.841    0.159     97 pass        pass      Preprocessor1_Model1\n##  6 Fold01      0.931    0.0688   112 pass        pass      Preprocessor1_Model1\n##  7 Fold01      0.727    0.273    123 pass        pass      Preprocessor1_Model1\n##  8 Fold01      0.640    0.360    129 pass        pass      Preprocessor1_Model1\n##  9 Fold01      0.740    0.260    136 pass        pass      Preprocessor1_Model1\n## 10 Fold01      0.902    0.0979   143 pass        pass      Preprocessor1_Model1\n## # ℹ 68,971 more rows\n\n可视化结果也是和上面的一模一样，就不一一介绍了，简单说下训练集的校准曲线画法，其实也是和上面一样的~\n\nres_calib_plot &lt;- collect_predictions(rf_res) %&gt;% \n  mutate(\n    pass = if_else(play_type == \"pass\", 1, 0),\n    pred_rnd = round(.pred_pass, 2)\n    ) %&gt;% \n  group_by(pred_rnd) %&gt;%\n  dplyr::summarize(\n    mean_pred = mean(.pred_pass),\n    mean_obs = mean(pass),\n    n = n()\n    ) %&gt;% \n  ggplot(aes(x = mean_pred, y = mean_obs)) +\n  geom_abline(linetype = \"dashed\") +\n  geom_point(aes(size = n), alpha = 0.5) +\n  theme_minimal() +\n  labs(\n    x = \"Predicted Pass\", \n    y = \"Observed Pass\"\n    ) +\n  coord_cartesian(\n    xlim = c(0,1), ylim = c(0, 1)\n    )\n\nres_calib_plot\n\n\n\n\n然后就是应用于测试集，并查看测试集上的表现：\n\nrf_test_res &lt;- last_fit(rf_wflow, split_pbp) %&gt;% \n  collect_metrics()\n\nrf_test_res\n## # A tibble: 2 × 4\n##   .metric  .estimator .estimate .config             \n##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n## 1 accuracy binary         0.731 Preprocessor1_Model1\n## 2 roc_auc  binary         0.799 Preprocessor1_Model1\n\n多种指标：\n\nmetricsets &lt;- metric_set(accuracy, mcc, f_meas, j_index)\n\ncollect_predictions(last_fit(rf_wflow, split_pbp)) %&gt;% \n  metricsets(truth = play_type, estimate = .pred_class)\n## # A tibble: 4 × 3\n##   .metric  .estimator .estimate\n##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n## 1 accuracy binary         0.731\n## 2 mcc      binary         0.441\n## 3 f_meas   binary         0.774\n## 4 j_index  binary         0.439"
  },
  {
    "objectID": "model-compare_tidymodels.html#roc曲线画一起",
    "href": "model-compare_tidymodels.html#roc曲线画一起",
    "title": "42  tidymodels实现多模型比较",
    "section": "42.6 ROC曲线画一起",
    "text": "42.6 ROC曲线画一起\n其实非常简单，就是把结果拼在一起画个图就行了~\n\nroc_lm &lt;- pred_lm %&gt;% roc_curve(play_type, .pred_pass) %&gt;% \n  mutate(model = \"logistic\")\n\nroc_knn &lt;- pred_knn %&gt;% roc_curve(play_type, .pred_pass) %&gt;% \n  mutate(model = \"kknn\")\n\nroc_rf &lt;- pred_rf %&gt;% roc_curve(play_type, .pred_pass) %&gt;% \n  mutate(model = \"randomforest\")\n\nroc_tree &lt;- pred_tree %&gt;% roc_curve(play_type, .pred_pass) %&gt;% \n  mutate(model = \"decision tree\")\n\n\nrocs &lt;- bind_rows(roc_lm,roc_knn,roc_rf,roc_tree) %&gt;% \n  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model))+\n  geom_path(lwd = 1.2, alpha = 0.6)+\n  geom_abline(lty = 3)+\n  coord_fixed()+\n  scale_color_brewer(palette = \"Set1\")+\n  theme_minimal()\n\nrocs\n\n\n\n\n是不是很简单呢？二分类资料常见的各种评价指标都有了，图也有了，还比较了多个模型，一举多得，tidymodels，你值得拥有！"
  },
  {
    "objectID": "model-compare_workflow.html#加载数据和r包",
    "href": "model-compare_workflow.html#加载数据和r包",
    "title": "43  workflow实现多模型比较",
    "section": "43.1 加载数据和R包",
    "text": "43.1 加载数据和R包\n首先还是加载数据和R包，和前面的一模一样的操作，数据也没变。\n\nrm(list = ls())\nsuppressPackageStartupMessages(library(tidyverse))\n## Warning: package 'ggplot2' was built under R version 4.2.3\n## Warning: package 'tibble' was built under R version 4.2.3\n## Warning: package 'dplyr' was built under R version 4.2.3\nsuppressPackageStartupMessages(library(tidymodels))\n## Warning: package 'tidymodels' was built under R version 4.2.3\n## Warning: package 'recipes' was built under R version 4.2.3\n## Warning: package 'yardstick' was built under R version 4.2.3\nlibrary(kknn)\ntidymodels_prefer()\n\nall_plays &lt;- read_rds(\"./datasets/all_plays.rds\")\n\nset.seed(20220520)\n\nsplit_pbp &lt;- initial_split(all_plays, 0.75, strata = play_type)\n\ntrain_data &lt;- training(split_pbp)\ntest_data &lt;- testing(split_pbp)"
  },
  {
    "objectID": "model-compare_workflow.html#数据预处理",
    "href": "model-compare_workflow.html#数据预处理",
    "title": "43  workflow实现多模型比较",
    "section": "43.2 数据预处理",
    "text": "43.2 数据预处理\n\npbp_rec &lt;- recipe(play_type ~ ., data = train_data)  %&gt;%\n  step_rm(half_seconds_remaining,yards_gained, game_id) %&gt;% \n  step_string2factor(posteam, defteam) %&gt;%  \n  step_corr(all_numeric(), threshold = 0.7) %&gt;% \n  step_center(all_numeric()) %&gt;%  \n  step_zv(all_predictors())"
  },
  {
    "objectID": "model-compare_workflow.html#选择模型",
    "href": "model-compare_workflow.html#选择模型",
    "title": "43  workflow实现多模型比较",
    "section": "43.3 选择模型",
    "text": "43.3 选择模型\n直接选择4个模型，你想选几个都是可以的。\n\nlm_mod &lt;- logistic_reg(mode = \"classification\",engine = \"glm\")\nknn_mod &lt;- nearest_neighbor(mode = \"classification\", engine = \"kknn\")\nrf_mod &lt;- rand_forest(mode = \"classification\", engine = \"ranger\")\ntree_mod &lt;- decision_tree(mode = \"classification\",engine = \"rpart\")"
  },
  {
    "objectID": "model-compare_workflow.html#选择重抽样方法",
    "href": "model-compare_workflow.html#选择重抽样方法",
    "title": "43  workflow实现多模型比较",
    "section": "43.4 选择重抽样方法",
    "text": "43.4 选择重抽样方法\n\nset.seed(20220520)\n\nfolds &lt;- vfold_cv(train_data, v = 10)\nfolds\n## #  10-fold cross-validation \n## # A tibble: 10 × 2\n##    splits               id    \n##    &lt;list&gt;               &lt;chr&gt; \n##  1 &lt;split [62082/6899]&gt; Fold01\n##  2 &lt;split [62083/6898]&gt; Fold02\n##  3 &lt;split [62083/6898]&gt; Fold03\n##  4 &lt;split [62083/6898]&gt; Fold04\n##  5 &lt;split [62083/6898]&gt; Fold05\n##  6 &lt;split [62083/6898]&gt; Fold06\n##  7 &lt;split [62083/6898]&gt; Fold07\n##  8 &lt;split [62083/6898]&gt; Fold08\n##  9 &lt;split [62083/6898]&gt; Fold09\n## 10 &lt;split [62083/6898]&gt; Fold10"
  },
  {
    "objectID": "model-compare_workflow.html#构建workflow",
    "href": "model-compare_workflow.html#构建workflow",
    "title": "43  workflow实现多模型比较",
    "section": "43.5 构建workflow",
    "text": "43.5 构建workflow\n这一步就是不用重复写代码的关键，把所有模型和数据预处理步骤自动连接起来。\n\nlibrary(workflowsets)\n\nfour_mods &lt;- workflow_set(list(rec = pbp_rec), \n                          list(lm = lm_mod,\n                               knn = knn_mod,\n                               rf = rf_mod,\n                               tree = tree_mod\n                               ),\n                          cross = T\n                          )\nfour_mods\n## # A workflow set/tibble: 4 × 4\n##   wflow_id info             option    result    \n##   &lt;chr&gt;    &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n## 1 rec_lm   &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n## 2 rec_knn  &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n## 3 rec_rf   &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n## 4 rec_tree &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;"
  },
  {
    "objectID": "model-compare_workflow.html#运行模型",
    "href": "model-compare_workflow.html#运行模型",
    "title": "43  workflow实现多模型比较",
    "section": "43.6 运行模型",
    "text": "43.6 运行模型\n首先是一些运行过程中的参数设置：\n\nkeep_pred &lt;- control_resamples(save_pred = T, verbose = T)\n\n然后就是运行4个模型（目前一直是在训练集中），我们给它加速一下：\n\nlibrary(doParallel) \n\ncl &lt;- makePSOCKcluster(12) # 加速，用12个线程\nregisterDoParallel(cl)\n\nfour_fits &lt;- four_mods %&gt;% \n  workflow_map(\"fit_resamples\",\n               seed = 0520,\n               verbose = T,\n               resamples = folds,\n               control = keep_pred\n               )\n\ni 1 of 4 resampling: rec_lm\n✔ 1 of 4 resampling: rec_lm (26.6s)\ni 2 of 4 resampling: rec_knn\n✔ 2 of 4 resampling: rec_knn (3m 44.1s)\ni 3 of 4 resampling: rec_rf\n✔ 3 of 4 resampling: rec_rf (1m 10.9s)\ni 4 of 4 resampling: rec_tree\n✔ 4 of 4 resampling: rec_tree (4.5s)\n\n#saveRDS(four_fits,file=\"datasets/four_fits.rds\")\nstopCluster(cl)\n\nfour_fits\n\n需要很长时间！大家笔记本如果内存不够可能会失败哦~"
  },
  {
    "objectID": "model-compare_workflow.html#查看结果",
    "href": "model-compare_workflow.html#查看结果",
    "title": "43  workflow实现多模型比较",
    "section": "43.7 查看结果",
    "text": "43.7 查看结果\n查看模型在训练集中的表现：\n\ncollect_metrics(four_fits)\n## # A tibble: 8 × 9\n##   wflow_id .config          preproc model .metric .estimator  mean     n std_err\n##   &lt;chr&gt;    &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n## 1 rec_lm   Preprocessor1_M… recipe  logi… accura… binary     0.724    10 1.91e-3\n## 2 rec_lm   Preprocessor1_M… recipe  logi… roc_auc binary     0.781    10 1.88e-3\n## 3 rec_knn  Preprocessor1_M… recipe  near… accura… binary     0.671    10 7.31e-4\n## 4 rec_knn  Preprocessor1_M… recipe  near… roc_auc binary     0.716    10 1.28e-3\n## 5 rec_rf   Preprocessor1_M… recipe  rand… accura… binary     0.732    10 1.48e-3\n## 6 rec_rf   Preprocessor1_M… recipe  rand… roc_auc binary     0.799    10 1.90e-3\n## 7 rec_tree Preprocessor1_M… recipe  deci… accura… binary     0.720    10 1.97e-3\n## 8 rec_tree Preprocessor1_M… recipe  deci… roc_auc binary     0.704    10 2.01e-3\n\n查看每一个预测结果，这个就不运行了，毕竟好几万行，太多了。。。\n\ncollect_predictions(four_fits)"
  },
  {
    "objectID": "model-compare_workflow.html#可视化结果",
    "href": "model-compare_workflow.html#可视化结果",
    "title": "43  workflow实现多模型比较",
    "section": "43.8 可视化结果",
    "text": "43.8 可视化结果\n直接可视化4个模型的结果，感觉比ROC曲线更好看，还给出了可信区间。\n这个图可以自己用ggplot2语法修改。\n\nfour_fits %&gt;% autoplot(metric = \"roc_auc\")+theme_bw()"
  },
  {
    "objectID": "model-compare_workflow.html#选择最好的模型用于测试集",
    "href": "model-compare_workflow.html#选择最好的模型用于测试集",
    "title": "43  workflow实现多模型比较",
    "section": "43.9 选择最好的模型用于测试集",
    "text": "43.9 选择最好的模型用于测试集\n选择表现最好的应用于测试集：\n\nrand_res &lt;- last_fit(rf_mod,pbp_rec,split_pbp)\n\n查看在测试集的模型表现：\n\ncollect_metrics(rand_res) # test 中的模型表现\n## # A tibble: 2 × 4\n##   .metric  .estimator .estimate .config             \n##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n## 1 accuracy binary         0.731 Preprocessor1_Model1\n## 2 roc_auc  binary         0.799 Preprocessor1_Model1\n\n使用其他指标查看模型表现：\n\nmetricsets &lt;- metric_set(accuracy, mcc, f_meas, j_index)\n\ncollect_predictions(rand_res) %&gt;% \n  metricsets(truth = play_type, estimate = .pred_class)\n## # A tibble: 4 × 3\n##   .metric  .estimator .estimate\n##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n## 1 accuracy binary         0.731\n## 2 mcc      binary         0.440\n## 3 f_meas   binary         0.774\n## 4 j_index  binary         0.438\n\n可视化结果，喜闻乐见的混淆矩阵：\n\ncollect_predictions(rand_res) %&gt;% \n  conf_mat(play_type,.pred_class) %&gt;% \n  autoplot()\n\n\n\n\n喜闻乐见的ROC曲线：\n\ncollect_predictions(rand_res) %&gt;% \n  roc_curve(play_type,.pred_pass) %&gt;% \n  autoplot()\n\n\n\n\n还有非常多曲线和评价指标可选，大家可以看我之前的介绍推文~"
  },
  {
    "objectID": "model-compare_mlr3.html#加载r包",
    "href": "model-compare_mlr3.html#加载r包",
    "title": "44  mlr3实现多模型比较",
    "section": "44.1 加载R包",
    "text": "44.1 加载R包\n首先还是加载数据和R包，和之前的数据一样的。\n\nrm(list = ls())\nlibrary(mlr3verse)\n## Warning: package 'mlr3verse' was built under R version 4.2.3\n## Loading required package: mlr3\n## Warning: package 'mlr3' was built under R version 4.2.3\nlibrary(mlr3pipelines)\nlibrary(mlr3filters)"
  },
  {
    "objectID": "model-compare_mlr3.html#建立任务",
    "href": "model-compare_mlr3.html#建立任务",
    "title": "44  mlr3实现多模型比较",
    "section": "44.2 建立任务",
    "text": "44.2 建立任务\n然后是对数据进行划分训练集和测试集，对数据进行预处理，为了和之前的tidymodels进行比较，这里使用的数据和预处理步骤都是和之前一样的。\n\n# 读取数据\nall_plays &lt;- readRDS(\"./datasets/all_plays.rds\")\n\n# 建立任务\npbp_task &lt;- as_task_classif(all_plays, target=\"play_type\")\n\n# 数据划分\nsplit_task &lt;- partition(pbp_task, ratio=0.75)\n\ntask_train &lt;- pbp_task$clone()$filter(split_task$train)\ntask_test &lt;- pbp_task$clone()$filter(split_task$test)"
  },
  {
    "objectID": "model-compare_mlr3.html#数据预处理",
    "href": "model-compare_mlr3.html#数据预处理",
    "title": "44  mlr3实现多模型比较",
    "section": "44.3 数据预处理",
    "text": "44.3 数据预处理\n建立任务后就是建立数据预处理步骤，这里采用和上篇推文tidymodels中一样的预处理步骤：\n\n# 数据预处理\npbp_prep &lt;- po(\"select\", # 去掉3列\n               selector = selector_invert(\n                 selector_name(c(\"half_seconds_remaining\",\"yards_gained\",\"game_id\")))\n               ) %&gt;&gt;%\n  po(\"colapply\", # 把这两列变成因子类型\n     affect_columns = selector_name(c(\"posteam\",\"defteam\")),\n     applicator = as.factor) %&gt;&gt;% \n  po(\"filter\", # 去除高度相关的列\n     filter = mlr3filters::flt(\"find_correlation\"), filter.cutoff=0.3) %&gt;&gt;%\n  po(\"scale\", scale = F) %&gt;&gt;% # 中心化\n  po(\"removeconstants\") # 去掉零方差变量\n\n可以看到mlr3的数据预处理与tidymodels相比，在语法上确实是有些复杂了，而且由于使用的R6，很多语法看起来很别扭，文档也说的不清楚，对于新手来说还是tidymodels更好些。目前来说最大的优势可能就是速度了吧。。。\n如果你想把预处理步骤应用于数据，得到预处理之后的数据，可以用以下代码：\n\ntask_prep &lt;- pbp_prep$clone()$train(task_train)[[1]]\ndim(task_train$data())\n## [1] 68982    26\n\ntask_prep$feature_types\n##                             id    type\n##  1:                    defteam  factor\n##  2:              defteam_score numeric\n##  3: defteam_timeouts_remaining  factor\n##  4:                       down ordered\n##  5:                 goal_to_go  factor\n##  6:                in_fg_range  factor\n##  7:                in_red_zone  factor\n##  8:                  no_huddle  factor\n##  9:                    posteam  factor\n## 10:              posteam_score numeric\n## 11: posteam_timeouts_remaining  factor\n## 12:              previous_play  factor\n## 13:                        qtr ordered\n## 14:         score_differential numeric\n## 15:                    shotgun  factor\n## 16:                 total_pass numeric\n## 17:              two_min_drill  factor\n## 18:               yardline_100 numeric\n## 19:                    ydstogo numeric\n\n这样就得到了处理好的数据，但是对于mlr3pipelines来说，这一步做不做都可以。"
  },
  {
    "objectID": "model-compare_mlr3.html#选择多个模型",
    "href": "model-compare_mlr3.html#选择多个模型",
    "title": "44  mlr3实现多模型比较",
    "section": "44.4 选择多个模型",
    "text": "44.4 选择多个模型\n还是选择和之前一样的4个模型：逻辑回归、随机森林、决策树、k最近邻：\n\n# 随机森林\nrf_glr &lt;- as_learner(pbp_prep %&gt;&gt;% lrn(\"classif.ranger\", predict_type=\"prob\")) \nrf_glr$id &lt;- \"randomForest\"\n\n# 逻辑回归\nlog_glr &lt;-as_learner(pbp_prep %&gt;&gt;% lrn(\"classif.log_reg\", predict_type=\"prob\")) \nlog_glr$id &lt;- \"logistic\"\n\n# 决策树\ntree_glr &lt;- as_learner(pbp_prep %&gt;&gt;% lrn(\"classif.rpart\", predict_type=\"prob\")) \ntree_glr$id &lt;- \"decisionTree\"\n\n# k近邻\nkknn_glr &lt;- as_learner(pbp_prep %&gt;&gt;% lrn(\"classif.kknn\", predict_type=\"prob\")) \nkknn_glr$id &lt;- \"kknn\""
  },
  {
    "objectID": "model-compare_mlr3.html#建立benchmark_grid",
    "href": "model-compare_mlr3.html#建立benchmark_grid",
    "title": "44  mlr3实现多模型比较",
    "section": "44.5 建立benchmark_grid",
    "text": "44.5 建立benchmark_grid\n类似于tidymodels中的workflow_set。\n选择10折交叉验证，建立多个模型，语法也是很简单了。\n\nset.seed(0520)\n\n# 10折交叉验证\ncv &lt;- rsmp(\"cv\",folds=10)\n\nset.seed(0520)\n\n# 建立多个模型\ndesign &lt;- benchmark_grid(\n  tasks = task_train,\n  learners = list(rf_glr,log_glr,tree_glr,kknn_glr),\n  resampling = cv\n)\n\n在训练集中，使用10折交叉验证，运行4个模型，看这语法是不是也很简单清稀？"
  },
  {
    "objectID": "model-compare_mlr3.html#开始计算",
    "href": "model-compare_mlr3.html#开始计算",
    "title": "44  mlr3实现多模型比较",
    "section": "44.6 开始计算",
    "text": "44.6 开始计算\n下面就是开始计算，和tidymodels相比，这一块语法更加简单一点，就是建立benchmark_grid，然后使用benchmark()函数即可。\n\n# 加速\nlibrary(future)\nplan(\"multisession\",workers=12)\n\n# 减少屏幕输出\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\nlgr::get_logger(\"bbotk\")$set_threshold(\"warn\")\n\n# 开始运行\nbmr &lt;- benchmark(design,store_models = T) # 速度比tidymodels快很多\n\n#saveRDS(bmr,file = \"datasets/bmr.rds\")\nbmr"
  },
  {
    "objectID": "model-compare_mlr3.html#查看模型表现",
    "href": "model-compare_mlr3.html#查看模型表现",
    "title": "44  mlr3实现多模型比较",
    "section": "44.7 查看模型表现",
    "text": "44.7 查看模型表现\n查看结果，也是支持同时查看多个结果的：\n\n# 默认结果\nbmr$aggregate()\n##    nr   task_id   learner_id resampling_id iters classif.ce\n## 1:  1 all_plays randomForest            cv    10  0.2696791\n## 2:  2 all_plays     logistic            cv    10  0.2768839\n## 3:  3 all_plays decisionTree            cv    10  0.2801601\n## 4:  4 all_plays         kknn            cv    10  0.3227799\n## Hidden columns: resample_result\n\n\n# 查看多个结果\nmeasures &lt;- msrs(c(\"classif.auc\",\"classif.acc\",\"classif.bbrier\"))\n\nbmr_res &lt;- bmr$aggregate(measures)\nbmr_res[,c(4,7:9)]\n##      learner_id classif.auc classif.acc classif.bbrier\n## 1: randomForest   0.7983164   0.7303209      0.1789120\n## 2:     logistic   0.7801990   0.7231161      0.1864776\n## 3: decisionTree   0.7038680   0.7198399      0.2003211\n## 4:         kknn   0.7311780   0.6772201      0.2215549"
  },
  {
    "objectID": "model-compare_mlr3.html#结果可视化",
    "href": "model-compare_mlr3.html#结果可视化",
    "title": "44  mlr3实现多模型比较",
    "section": "44.8 结果可视化",
    "text": "44.8 结果可视化\n支持ggplot2语法，使用起来和tidymodels差不多，也是对结果直接autoplot()即可。\n\nlibrary(ggplot2)\n## Warning: package 'ggplot2' was built under R version 4.2.3\nautoplot(bmr)+theme(axis.text.x = element_text(angle = 45))\n\n\n\n\n喜闻乐见的ROC曲线：\n\nautoplot(bmr,type = \"roc\")"
  },
  {
    "objectID": "model-compare_mlr3.html#选择最好的模型用于测试集",
    "href": "model-compare_mlr3.html#选择最好的模型用于测试集",
    "title": "44  mlr3实现多模型比较",
    "section": "44.9 选择最好的模型用于测试集",
    "text": "44.9 选择最好的模型用于测试集\n通过比较结果可以发现还是随机森林效果最好~，下面选择随机森林，在训练集上训练，在测试集上测试结果。\n这一步并没有使用10折交叉验证，如果你想用，也是可以的~\n\n# 训练\nrf_glr$train(task_train)\n## Growing trees.. Progress: 69%. Estimated remaining time: 14 seconds.\n\n训练好之后就是在测试集上测试并查看结果：\n\n# 测试\nprediction &lt;- rf_glr$predict(task_test)\nhead(as.data.table(prediction))\n##    row_ids truth response prob.pass  prob.run\n## 1:       5  pass     pass 0.8407674 0.1592326\n## 2:       6   run      run 0.4135679 0.5864321\n## 3:      15   run      run 0.1719599 0.8280401\n## 4:      20  pass     pass 0.6567402 0.3432598\n## 5:      29   run     pass 0.6880750 0.3119250\n## 6:      40   run     pass 0.5459646 0.4540354\n\n混淆矩阵：\n\nprediction$confusion\n##         truth\n## response  pass   run\n##     pass 10664  3282\n##     run   2920  6128\n\n混淆矩阵可视化：\n\nautoplot(prediction)\n\n\n\n\n查看其他结果：\n\nprediction$score(msrs(c(\"classif.auc\",\"classif.acc\",\"classif.bbrier\")))\n##    classif.auc    classif.acc classif.bbrier \n##      0.7993217      0.7302775      0.1784343\n\n喜闻乐见ROC曲线：\n\nautoplot(prediction,type = \"roc\")\n\n\n\n\n简单吗？"
  },
  {
    "objectID": "model-compare_caret.html#数据划分",
    "href": "model-compare_caret.html#数据划分",
    "title": "45  caret实现多模型比较",
    "section": "45.1 数据划分",
    "text": "45.1 数据划分\n下面是一个分类数据的演示。\n\n# 使用的数据集\nlibrary(mlbench)\n## Warning: package 'mlbench' was built under R version 4.2.3\ndata(Sonar)\nstr(Sonar[, 1:10])\n## 'data.frame':    208 obs. of  10 variables:\n##  $ V1 : num  0.02 0.0453 0.0262 0.01 0.0762 0.0286 0.0317 0.0519 0.0223 0.0164 ...\n##  $ V2 : num  0.0371 0.0523 0.0582 0.0171 0.0666 0.0453 0.0956 0.0548 0.0375 0.0173 ...\n##  $ V3 : num  0.0428 0.0843 0.1099 0.0623 0.0481 ...\n##  $ V4 : num  0.0207 0.0689 0.1083 0.0205 0.0394 ...\n##  $ V5 : num  0.0954 0.1183 0.0974 0.0205 0.059 ...\n##  $ V6 : num  0.0986 0.2583 0.228 0.0368 0.0649 ...\n##  $ V7 : num  0.154 0.216 0.243 0.11 0.121 ...\n##  $ V8 : num  0.16 0.348 0.377 0.128 0.247 ...\n##  $ V9 : num  0.3109 0.3337 0.5598 0.0598 0.3564 ...\n##  $ V10: num  0.211 0.287 0.619 0.126 0.446 ...\n\n用caret包实现boosted tree模型。\n\n# 加载R包，划分数据集\nlibrary(caret)\n## Loading required package: ggplot2\n## Warning: package 'ggplot2' was built under R version 4.2.3\n## Loading required package: lattice\n\n# 训练集、测试集划分，比例为0.75\nset.seed(998)\ninTraining &lt;- createDataPartition(Sonar$Class, p = .75, list = FALSE)\ntraining &lt;- Sonar[inTraining,]\ntesting  &lt;- Sonar[-inTraining,]"
  },
  {
    "objectID": "model-compare_caret.html#重抽样",
    "href": "model-compare_caret.html#重抽样",
    "title": "45  caret实现多模型比较",
    "section": "45.2 重抽样",
    "text": "45.2 重抽样\ntrainControl()选择重抽样方法。\n\n# 选择重抽样方法，重复10折交叉验证\nfitControl &lt;- trainControl(method = \"repeatedcv\", #默认是simple boost\n                           number = 10,\n                           repeats = 10,\n                           classProbs = T # 计算概率\n                           )\n\n# 借助 gbm 包实现 boosted tree\nset.seed(825)\ngbmFit1 &lt;- train(Class ~ ., \n                 data = training, \n                 method = \"gbm\", \n                 trControl = fitControl,\n                 verbose = FALSE)\ngbmFit1\n## Stochastic Gradient Boosting \n## \n## 157 samples\n##  60 predictor\n##   2 classes: 'M', 'R' \n## \n## No pre-processing\n## Resampling: Cross-Validated (10 fold, repeated 10 times) \n## Summary of sample sizes: 141, 142, 141, 142, 141, 142, ... \n## Resampling results across tuning parameters:\n## \n##   interaction.depth  n.trees  Accuracy   Kappa    \n##   1                   50      0.7935784  0.5797839\n##   1                  100      0.8171078  0.6290208\n##   1                  150      0.8219608  0.6383173\n##   2                   50      0.8041912  0.6027771\n##   2                  100      0.8296176  0.6544713\n##   2                  150      0.8283627  0.6520181\n##   3                   50      0.8110343  0.6170317\n##   3                  100      0.8301275  0.6551379\n##   3                  150      0.8310343  0.6577252\n## \n## Tuning parameter 'shrinkage' was held constant at a value of 0.1\n## \n## Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n## Accuracy was used to select the optimal model using the largest value.\n## The final values used for the model were n.trees = 150, interaction.depth =\n##  3, shrinkage = 0.1 and n.minobsinnode = 10.\n\n结果很详细，就不做解释了。\n上面的例子也展示了caret包建模的基本语法，就是一个train()就可以了，method参数选择模型，trControl选择重抽样方法，preProcess选择数据预处理方法（上面这个例子没有进行数据预处理）。"
  },
  {
    "objectID": "model-compare_caret.html#超参数调整",
    "href": "model-compare_caret.html#超参数调整",
    "title": "45  caret实现多模型比较",
    "section": "45.3 超参数调整",
    "text": "45.3 超参数调整\n上面是交叉验证的例子，并没有加入超参数调优的环节，下面将加入超参数调优的过程。\n但是说实话caret虽然是一个整合包，但是对于每一种算法，它支持调整的超参数都很有限！\n\n# 网格搜索，首先设定超参数范围\ngbmGrid &lt;-  expand.grid(interaction.depth = c(1, 5, 9), \n                        n.trees = (1:30)*50, \n                        shrinkage = 0.1,\n                        n.minobsinnode = 20)\n\nnrow(gbmGrid)\n## [1] 90\nhead(gbmGrid)\n##   interaction.depth n.trees shrinkage n.minobsinnode\n## 1                 1      50       0.1             20\n## 2                 5      50       0.1             20\n## 3                 9      50       0.1             20\n## 4                 1     100       0.1             20\n## 5                 5     100       0.1             20\n## 6                 9     100       0.1             20\n\n\n# 设置种子数，进行建模\nset.seed(825)\ngbmFit2 &lt;- train(Class ~ ., \n                 data = training, \n                 method = \"gbm\", \n                 trControl = fitControl, \n                 verbose = FALSE, \n                 tuneGrid = gbmGrid # 设定网格范围\n                 )\ngbmFit2\n## Stochastic Gradient Boosting \n## \n## 157 samples\n##  60 predictor\n##   2 classes: 'M', 'R' \n## \n## No pre-processing\n## Resampling: Cross-Validated (10 fold, repeated 10 times) \n## Summary of sample sizes: 141, 142, 141, 142, 141, 142, ... \n## Resampling results across tuning parameters:\n## \n##   interaction.depth  n.trees  Accuracy   Kappa    \n##   1                    50     0.7828554  0.5576364\n##   1                   100     0.8050417  0.6052511\n##   1                   150     0.8197598  0.6347029\n##   1                   200     0.8267647  0.6490980\n##   1                   250     0.8248162  0.6457087\n##   1                   300     0.8285662  0.6530017\n##   1                   350     0.8268064  0.6501107\n##   1                   400     0.8312279  0.6589083\n##   1                   450     0.8299412  0.6562300\n##   1                   500     0.8287696  0.6541824\n##   1                   550     0.8268529  0.6507834\n##   1                   600     0.8242696  0.6451827\n##   1                   650     0.8266446  0.6499982\n##   1                   700     0.8242696  0.6453552\n##   1                   750     0.8256765  0.6479240\n##   1                   800     0.8281495  0.6527784\n##   1                   850     0.8300662  0.6569414\n##   1                   900     0.8256446  0.6481923\n##   1                   950     0.8244363  0.6453829\n##   1                  1000     0.8262328  0.6491364\n##   1                  1050     0.8249044  0.6463384\n##   1                  1100     0.8267794  0.6500107\n##   1                  1150     0.8249363  0.6462861\n##   1                  1200     0.8241961  0.6448228\n##   1                  1250     0.8293627  0.6552775\n##   1                  1300     0.8268578  0.6501556\n##   1                  1350     0.8274412  0.6512506\n##   1                  1400     0.8236078  0.6435469\n##   1                  1450     0.8241495  0.6446909\n##   1                  1500     0.8248578  0.6461121\n##   5                    50     0.8050490  0.6052726\n##   5                   100     0.8308676  0.6581887\n##   5                   150     0.8383260  0.6731821\n##   5                   200     0.8402426  0.6767836\n##   5                   250     0.8429730  0.6827616\n##   5                   300     0.8384314  0.6740014\n##   5                   350     0.8428113  0.6821387\n##   5                   400     0.8389730  0.6748263\n##   5                   450     0.8376446  0.6721719\n##   5                   500     0.8378015  0.6721643\n##   5                   550     0.8415564  0.6796774\n##   5                   600     0.8421446  0.6805756\n##   5                   650     0.8408113  0.6779880\n##   5                   700     0.8420613  0.6806978\n##   5                   750     0.8433529  0.6832899\n##   5                   800     0.8434363  0.6833891\n##   5                   850     0.8421397  0.6806647\n##   5                   900     0.8433897  0.6833137\n##   5                   950     0.8471863  0.6909153\n##   5                  1000     0.8448015  0.6863164\n##   5                  1050     0.8422598  0.6811117\n##   5                  1100     0.8442230  0.6850606\n##   5                  1150     0.8441495  0.6847852\n##   5                  1200     0.8448064  0.6860621\n##   5                  1250     0.8435147  0.6833321\n##   5                  1300     0.8440613  0.6844760\n##   5                  1350     0.8445711  0.6854801\n##   5                  1400     0.8471544  0.6910026\n##   5                  1450     0.8477843  0.6922575\n##   5                  1500     0.8452377  0.6871235\n##   9                    50     0.8069632  0.6085066\n##   9                   100     0.8370564  0.6703042\n##   9                   150     0.8388578  0.6736906\n##   9                   200     0.8433995  0.6831895\n##   9                   250     0.8431593  0.6823051\n##   9                   300     0.8433578  0.6829580\n##   9                   350     0.8446912  0.6855602\n##   9                   400     0.8441078  0.6842397\n##   9                   450     0.8408162  0.6779033\n##   9                   500     0.8399877  0.6764543\n##   9                   550     0.8427279  0.6814919\n##   9                   600     0.8421029  0.6803304\n##   9                   650     0.8415564  0.6791854\n##   9                   700     0.8432279  0.6824711\n##   9                   750     0.8424779  0.6810777\n##   9                   800     0.8444730  0.6853931\n##   9                   850     0.8470980  0.6906261\n##   9                   900     0.8433799  0.6831660\n##   9                   950     0.8427549  0.6816389\n##   9                  1000     0.8440098  0.6843843\n##   9                  1050     0.8432230  0.6828880\n##   9                  1100     0.8433480  0.6832230\n##   9                  1150     0.8438848  0.6841742\n##   9                  1200     0.8483064  0.6931893\n##   9                  1250     0.8444730  0.6855370\n##   9                  1300     0.8458015  0.6879868\n##   9                  1350     0.8476863  0.6919423\n##   9                  1400     0.8445931  0.6854858\n##   9                  1450     0.8463897  0.6893495\n##   9                  1500     0.8451814  0.6868250\n## \n## Tuning parameter 'shrinkage' was held constant at a value of 0.1\n## \n## Tuning parameter 'n.minobsinnode' was held constant at a value of 20\n## Accuracy was used to select the optimal model using the largest value.\n## The final values used for the model were n.trees = 1200, interaction.depth =\n##  9, shrinkage = 0.1 and n.minobsinnode = 20.\n\n上面这个结果非常详细。\n除了网格搜索，还提供常见的其他方法，大家感兴趣的自己探索即可，我这里只是简单演示基本用法。\n在探索这个结果之前，让我们先看看caret强大的模型结果的可视化功能。\n\n# 展示不同参数下的模型性能\ntrellis.par.set(caretTheme())\nplot(gbmFit2)  \n\n\n\n\n\n# 更改性能指标\ntrellis.par.set(caretTheme())\nplot(gbmFit2, metric = \"Kappa\")\n\n\n\n\n\n#?plot.train 获取更多细节！\ntrellis.par.set(caretTheme())\nplot(gbmFit2, metric = \"Kappa\", plotType = \"level\",\n     scales = list(x = list(rot = 90)))\n\n\n\n\n\n# 支持ggplot2\nggplot(gbmFit2)+theme_bw()  # ?xyplot.train\n\n\n\n\ntrainControl()可用来选择重抽样方法，选择是否需要计算概率（分类数据）等，这个函数非常重要，可以使用?trainControl查看细节。\n\n# trainControl函数用来设置非常多的东西，很重要\nfitControl &lt;- trainControl(method = \"repeatedcv\",\n                           number = 10,\n                           repeats = 10,\n                           classProbs = TRUE, # 计算概率\n                           summaryFunction = twoClassSummary # 二分类变量指标\n                           )\n# 选择好之后开始调优\nset.seed(825)\ngbmFit3 &lt;- train(Class ~ ., \n                 data = training, \n                 method = \"gbm\", \n                 trControl = fitControl, \n                 verbose = FALSE, \n                 tuneGrid = gbmGrid,\n                 metric = \"ROC\" # 选择指标\n                 )\ngbmFit3\n## Stochastic Gradient Boosting \n## \n## 157 samples\n##  60 predictor\n##   2 classes: 'M', 'R' \n## \n## No pre-processing\n## Resampling: Cross-Validated (10 fold, repeated 10 times) \n## Summary of sample sizes: 141, 142, 141, 142, 141, 142, ... \n## Resampling results across tuning parameters:\n## \n##   interaction.depth  n.trees  ROC        Sens       Spec     \n##   1                    50     0.8634003  0.8631944  0.6905357\n##   1                   100     0.8844097  0.8486111  0.7544643\n##   1                   150     0.8932440  0.8640278  0.7683929\n##   1                   200     0.8965625  0.8687500  0.7780357\n##   1                   250     0.8981275  0.8629167  0.7810714\n##   1                   300     0.8979836  0.8725000  0.7780357\n##   1                   350     0.8975000  0.8647222  0.7837500\n##   1                   400     0.8968155  0.8716667  0.7853571\n##   1                   450     0.8956473  0.8641667  0.7905357\n##   1                   500     0.8961186  0.8620833  0.7907143\n##   1                   550     0.8984152  0.8586111  0.7910714\n##   1                   600     0.8980159  0.8619444  0.7816071\n##   1                   650     0.8962872  0.8604167  0.7878571\n##   1                   700     0.8975670  0.8595833  0.7842857\n##   1                   750     0.8979415  0.8608333  0.7853571\n##   1                   800     0.8978770  0.8644444  0.7864286\n##   1                   850     0.8962078  0.8645833  0.7908929\n##   1                   900     0.8968651  0.8586111  0.7883929\n##   1                   950     0.8963244  0.8586111  0.7853571\n##   1                  1000     0.8964211  0.8570833  0.7908929\n##   1                  1050     0.8966791  0.8584722  0.7864286\n##   1                  1100     0.8964757  0.8631944  0.7850000\n##   1                  1150     0.8943800  0.8608333  0.7835714\n##   1                  1200     0.8948338  0.8594444  0.7835714\n##   1                  1250     0.8953646  0.8630556  0.7905357\n##   1                  1300     0.8950521  0.8631944  0.7851786\n##   1                  1350     0.8957391  0.8618056  0.7878571\n##   1                  1400     0.8940600  0.8593056  0.7826786\n##   1                  1450     0.8931126  0.8608333  0.7823214\n##   1                  1500     0.8937227  0.8633333  0.7810714\n##   5                    50     0.8905407  0.8490278  0.7535714\n##   5                   100     0.9139707  0.8645833  0.7921429\n##   5                   150     0.9168552  0.8652778  0.8069643\n##   5                   200     0.9173785  0.8697222  0.8055357\n##   5                   250     0.9201711  0.8713889  0.8096429\n##   5                   300     0.9200918  0.8643056  0.8085714\n##   5                   350     0.9213616  0.8712500  0.8094643\n##   5                   400     0.9182713  0.8688889  0.8042857\n##   5                   450     0.9208234  0.8663889  0.8042857\n##   5                   500     0.9193155  0.8704167  0.8001786\n##   5                   550     0.9187996  0.8716667  0.8066071\n##   5                   600     0.9172024  0.8775000  0.8010714\n##   5                   650     0.9173487  0.8777778  0.7980357\n##   5                   700     0.9172693  0.8763889  0.8023214\n##   5                   750     0.9187401  0.8787500  0.8026786\n##   5                   800     0.9187574  0.8787500  0.8025000\n##   5                   850     0.9190724  0.8765278  0.8023214\n##   5                   900     0.9192584  0.8776389  0.8035714\n##   5                   950     0.9185441  0.8798611  0.8091071\n##   5                  1000     0.9208011  0.8765278  0.8078571\n##   5                  1050     0.9205630  0.8740278  0.8053571\n##   5                  1100     0.9208780  0.8788889  0.8041071\n##   5                  1150     0.9201811  0.8798611  0.8028571\n##   5                  1200     0.9207168  0.8800000  0.8041071\n##   5                  1250     0.9209325  0.8800000  0.8014286\n##   5                  1300     0.9207540  0.8800000  0.8025000\n##   5                  1350     0.9193725  0.8798611  0.8037500\n##   5                  1400     0.9188542  0.8787500  0.8107143\n##   5                  1450     0.9216468  0.8787500  0.8119643\n##   5                  1500     0.9208234  0.8763889  0.8091071\n##   9                    50     0.8941369  0.8529167  0.7535714\n##   9                   100     0.9117237  0.8693056  0.7996429\n##   9                   150     0.9185913  0.8716667  0.8005357\n##   9                   200     0.9173636  0.8790278  0.8023214\n##   9                   250     0.9175744  0.8830556  0.7967857\n##   9                   300     0.9193775  0.8844444  0.7957143\n##   9                   350     0.9208904  0.8834722  0.7996429\n##   9                   400     0.9188492  0.8844444  0.7969643\n##   9                   450     0.9169048  0.8783333  0.7969643\n##   9                   500     0.9176935  0.8780556  0.7957143\n##   9                   550     0.9167684  0.8829167  0.7953571\n##   9                   600     0.9146429  0.8843056  0.7926786\n##   9                   650     0.9151736  0.8809722  0.7955357\n##   9                   700     0.9165055  0.8841667  0.7955357\n##   9                   750     0.9178472  0.8804167  0.7982143\n##   9                   800     0.9172495  0.8805556  0.8026786\n##   9                   850     0.9174926  0.8843056  0.8041071\n##   9                   900     0.9178547  0.8805556  0.8001786\n##   9                   950     0.9178348  0.8816667  0.7971429\n##   9                  1000     0.9177753  0.8816667  0.8000000\n##   9                  1050     0.9166022  0.8793056  0.8010714\n##   9                  1100     0.9173760  0.8783333  0.8025000\n##   9                  1150     0.9181275  0.8780556  0.8037500\n##   9                  1200     0.9184921  0.8841667  0.8066071\n##   9                  1250     0.9185144  0.8791667  0.8039286\n##   9                  1300     0.9177207  0.8802778  0.8053571\n##   9                  1350     0.9172991  0.8815278  0.8080357\n##   9                  1400     0.9179688  0.8804167  0.8026786\n##   9                  1450     0.9188666  0.8791667  0.8080357\n##   9                  1500     0.9181721  0.8805556  0.8039286\n## \n## Tuning parameter 'shrinkage' was held constant at a value of 0.1\n## \n## Tuning parameter 'n.minobsinnode' was held constant at a value of 20\n## ROC was used to select the optimal model using the largest value.\n## The final values used for the model were n.trees = 1450, interaction.depth =\n##  5, shrinkage = 0.1 and n.minobsinnode = 20.\n\ntrain()函数中的metric参数可以指定调优的指标，默认分类模型是accuracy和Kappa，回归模型是RMSE/R^2/MAE。\ntrainControl()中的summaryFunction参数还提供了额外的调优指标选项，比如上面这个twoClassSummary，内含3种指标：敏感度、特异度、ROC。"
  },
  {
    "objectID": "model-compare_caret.html#选择最终模型",
    "href": "model-compare_caret.html#选择最终模型",
    "title": "45  caret实现多模型比较",
    "section": "45.4 选择最终模型",
    "text": "45.4 选择最终模型\n其实经过上面的train()训练后得到的gbmFit3就已经包含了我们最终的模型，如果你不需要额外的操作，那现在这个gbmFit3就可以直接用于测试集了。\n\npredict(gbmFit3, newdata = head(testing), type = \"prob\")\n##              M            R\n## 1 3.215213e-02 9.678479e-01\n## 2 1.000000e+00 3.965815e-08\n## 3 6.996088e-13 1.000000e+00\n## 4 9.070652e-01 9.293483e-02\n## 5 2.029754e-03 9.979702e-01\n## 6 9.999662e-01 3.377548e-05\npredict(gbmFit3, newdata = head(testing))\n## [1] R M R M R M\n## Levels: M R\n\n同时你也可以用$符号查看各种结果，比如：\n\ngbmFit3$finalModel # 最终模型\ngbmFit3$bestTune # 选择的超参数\ngbmFit3$results # 包含各种指标的详细结果\n\n除此之外，caret还提供了另外3个函数帮助你自定义选择最终的模型： - best:根据某一指标选择，选择使某个指标最大或最小的模型 - oneSE:使用1倍标准差法选择最终模型 - tolerance:根据某一指标选择最简单的模型\n下面是一个tolerance的演示，其他两个也是一样的使用方法：\n\nwhichTwoPct &lt;- tolerance(gbmFit3$results, \n                         metric = \"ROC\", \n                         tol = 2, # 这个参数是tolerance函数特有的\n                         maximize = TRUE) \n\ngbmFit3$results[whichTwoPct,1:6]\n##    shrinkage interaction.depth n.minobsinnode n.trees       ROC      Sens\n## 32       0.1                 5             20     100 0.9139707 0.8645833"
  },
  {
    "objectID": "model-compare_caret.html#应用于测试集",
    "href": "model-compare_caret.html#应用于测试集",
    "title": "45  caret实现多模型比较",
    "section": "45.5 应用于测试集",
    "text": "45.5 应用于测试集\n上面已经介绍过了，直接使用即可。\ncaret对predict()函数进行了优化，type=prob计算概率，type=class计算类别。tidymodels完整继承了这个优点。\n\npredict(gbmFit3, newdata = head(testing))\n## [1] R M R M R M\n## Levels: M R\npredict(gbmFit3, newdata = head(testing), type = \"prob\")\n##              M            R\n## 1 3.215213e-02 9.678479e-01\n## 2 1.000000e+00 3.965815e-08\n## 3 6.996088e-13 1.000000e+00\n## 4 9.070652e-01 9.293483e-02\n## 5 2.029754e-03 9.979702e-01\n## 6 9.999662e-01 3.377548e-05"
  },
  {
    "objectID": "model-compare_caret.html#多个模型的比较",
    "href": "model-compare_caret.html#多个模型的比较",
    "title": "45  caret实现多模型比较",
    "section": "45.6 多个模型的比较",
    "text": "45.6 多个模型的比较\n\n45.6.1 多建立几个模型\n\n\nset.seed(825)\nsvmFit &lt;- train(Class ~ ., \n                data = training, \n                method = \"svmRadial\", \n                trControl = fitControl, \n                preProc = c(\"center\", \"scale\"),\n                tuneLength = 8,\n                metric = \"ROC\")\n\nset.seed(825)\nrdaFit &lt;- train(Class ~ ., \n                data = training, \n                method = \"rda\", \n                trControl = fitControl, \n                tuneLength = 4,\n                metric = \"ROC\")\n\n一起放入resamples()函数里面：\n\nresamps &lt;- resamples(list(GBM = gbmFit3,\n                          SVM = svmFit,\n                          RDA = rdaFit))\nresamps\n## \n## Call:\n## resamples.default(x = list(GBM = gbmFit3, SVM = svmFit, RDA = rdaFit))\n## \n## Models: GBM, SVM, RDA \n## Number of resamples: 100 \n## Performance metrics: ROC, Sens, Spec \n## Time estimates for: everything, final model fit\nsummary(resamps)\n## \n## Call:\n## summary.resamples(object = resamps)\n## \n## Models: GBM, SVM, RDA \n## Number of resamples: 100 \n## \n## ROC \n##          Min.  1st Qu.    Median      Mean   3rd Qu. Max. NA's\n## GBM 0.6964286 0.874504 0.9454365 0.9216468 0.9821429    1    0\n## SVM 0.7321429 0.905878 0.9464286 0.9339658 0.9821429    1    0\n## RDA 0.5625000 0.812500 0.8750000 0.8698115 0.9392361    1    0\n## \n## Sens \n##          Min.   1st Qu.    Median      Mean 3rd Qu. Max. NA's\n## GBM 0.5555556 0.7777778 0.8750000 0.8787500       1    1    0\n## SVM 0.5000000 0.7777778 0.8888889 0.8730556       1    1    0\n## RDA 0.4444444 0.7777778 0.8750000 0.8604167       1    1    0\n## \n## Spec \n##          Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA's\n## GBM 0.4285714 0.7142857 0.8571429 0.8119643 1.0000000    1    0\n## SVM 0.4285714 0.7142857 0.8571429 0.8205357 0.9062500    1    0\n## RDA 0.1428571 0.5714286 0.7142857 0.6941071 0.8571429    1    0\n\n结果就很强！分别给出了3种指标下的每种模型的统计值。\n\n\n45.6.2 多个模型可视化\n喜闻乐见的结果可视化也是必不可少的。主要包括以下几种：density plots, box-whisker plots, scatterplot matrices and scatterplots\n\n# 设主题\ntheme1 &lt;- trellis.par.get()\ntheme1$plot.symbol$col = rgb(.2, .2, .2, .4)\ntheme1$plot.symbol$pch = 16\ntheme1$plot.line$col = rgb(1, 0, 0, .7)\ntheme1$plot.line$lwd &lt;- 2\n\n# 画图，箱线图\ntrellis.par.set(theme1)\nbwplot(resamps, layout = c(3, 1))\n\n\n\n\n\n# 密度图\ntrellis.par.set(theme1)\ndensityplot(resamps)\n\n\n\n\n\n# 换个指标，点线图\ntrellis.par.set(caretTheme())\ndotplot(resamps, metric = \"ROC\")\n\n\n\n\n\n# 散点图\ntrellis.par.set(theme1)\nxyplot(resamps, what = \"BlandAltman\")\n\n\n\n\n\n# 散点图矩阵\nsplom(resamps)\n\n\n\n\n\n\n45.6.3 多个模型的显著性检验\n除此之外，我们还可以对不同模型之间的差异进行显著性检验，比如t检验。\n\ndifValues &lt;- diff(resamps)\ndifValues\n## \n## Call:\n## diff.resamples(x = resamps)\n## \n## Models: GBM, SVM, RDA \n## Metrics: ROC, Sens, Spec \n## Number of differences: 3 \n## p-value adjustment: bonferroni\nsummary(difValues)\n## \n## Call:\n## summary.diff.resamples(object = difValues)\n## \n## p-value adjustment: bonferroni \n## Upper diagonal: estimates of the difference\n## Lower diagonal: p-value for H0: difference = 0\n## \n## ROC \n##     GBM       SVM       RDA     \n## GBM           -0.01232   0.05184\n## SVM 0.3408               0.06415\n## RDA 5.356e-07 2.638e-10         \n## \n## Sens \n##     GBM    SVM      RDA     \n## GBM        0.005694 0.018333\n## SVM 1.0000          0.012639\n## RDA 0.4253 1.0000           \n## \n## Spec \n##     GBM       SVM       RDA      \n## GBM           -0.008571  0.117857\n## SVM 1                    0.126429\n## RDA 8.230e-07 1.921e-10\n\n结果的可视化：\n\ntrellis.par.set(theme1)\nbwplot(difValues, layout = c(3, 1))\n\n\n\n\n\ntrellis.par.set(caretTheme())\ndotplot(difValues)\n\n\n\n\n是不是很强！"
  },
  {
    "objectID": "model-compare_caret.html#使用默认超参数",
    "href": "model-compare_caret.html#使用默认超参数",
    "title": "45  caret实现多模型比较",
    "section": "45.7 使用默认超参数",
    "text": "45.7 使用默认超参数\n直接提供超参数的值，这种情况不能进行重抽样，把超参数的值直接提供给tuneGrid参数即可。\n\nfitControl &lt;- trainControl(method = \"none\", classProbs = TRUE)\n\nset.seed(825)\ngbmFit4 &lt;- train(Class ~ ., \n                 data = training, \n                 method = \"gbm\", \n                 trControl = fitControl, \n                 verbose = FALSE, \n                 # 直接提供超参数的值\n                 tuneGrid = data.frame(interaction.depth = 4,\n                                       n.trees = 100,\n                                       shrinkage = .1,\n                                       n.minobsinnode = 20),\n                 metric = \"ROC\")\ngbmFit4\n## Stochastic Gradient Boosting \n## \n## 157 samples\n##  60 predictor\n##   2 classes: 'M', 'R' \n## \n## No pre-processing\n## Resampling: None\n\npredict(gbmFit4, newdata = head(testing))\n## [1] R M R R M M\n## Levels: M R\npredict(gbmFit4, newdata = head(testing), type = \"prob\")\n##             M          R\n## 1 0.264671996 0.73532800\n## 2 0.960445979 0.03955402\n## 3 0.005731862 0.99426814\n## 4 0.298628996 0.70137100\n## 5 0.503935367 0.49606463\n## 6 0.813716635 0.18628336\n\n以上就是caret典型使用的演示，更多的例子我们慢慢介绍，逐渐深入。"
  },
  {
    "objectID": "data-preprocess.html#加载r包和数据",
    "href": "data-preprocess.html#加载r包和数据",
    "title": "附录 A — 常见的数据预处理方法",
    "section": "A.1 加载R包和数据",
    "text": "A.1 加载R包和数据\n\nlibrary(AppliedPredictiveModeling)\n## Warning: package 'AppliedPredictiveModeling' was built under R version 4.2.3\nlibrary(caret)\n## Loading required package: ggplot2\n## Warning: package 'ggplot2' was built under R version 4.2.3\n## Loading required package: lattice\n\ndata(\"segmentationOriginal\")\n\nsegData &lt;- subset(segmentationOriginal, Case == \"Train\")\ncellID &lt;- segData$Cell\ncalss &lt;- segData$Class\ncase &lt;- segData$Case\nsegData &lt;- segData[ ,  -(1:3)]\nstatusColNum &lt;- grep(\"Status\", names(segData))\nstatusColNum\n##  [1]   2   4   9  10  11  12  14  16  20  21  22  26  27  28  30  32  34  36  38\n## [20]  40  43  44  46  48  51  52  55  56  59  60  63  64  68  69  70  72  73  74\n## [39]  76  78  80  82  84  86  88  92  93  94  97  98 103 104 105 106 110 111 112\n## [58] 114\n\nsegData &lt;- segData[ , -statusColNum]\n\nstr(segData)\n## 'data.frame':    1009 obs. of  58 variables:\n##  $ AngleCh1               : num  133.8 106.6 69.2 109.4 104.3 ...\n##  $ AreaCh1                : int  819 431 298 256 258 358 158 315 246 223 ...\n##  $ AvgIntenCh1            : num  31.9 28 19.5 18.8 17.6 ...\n##  $ AvgIntenCh2            : num  206 115 101 126 124 ...\n##  $ AvgIntenCh3            : num  69.9 63.9 28.2 13.6 22.5 ...\n##  $ AvgIntenCh4            : num  164.2 106.7 31 46.8 71.2 ...\n##  $ ConvexHullAreaRatioCh1 : num  1.26 1.05 1.2 1.08 1.08 ...\n##  $ ConvexHullPerimRatioCh1: num  0.797 0.935 0.866 0.92 0.931 ...\n##  $ DiffIntenDensityCh1    : num  31.9 32.5 26.7 28 27.9 ...\n##  $ DiffIntenDensityCh3    : num  43.1 36 22.9 14.9 16.1 ...\n##  $ DiffIntenDensityCh4    : num  79.3 51.4 26.4 32.7 36.2 ...\n##  $ EntropyIntenCh1        : num  6.09 5.88 5.42 5.38 5.18 ...\n##  $ EntropyIntenCh3        : num  6.64 6.68 5.44 4.15 5.49 ...\n##  $ EntropyIntenCh4        : num  7.88 7.14 5.78 6.19 6.62 ...\n##  $ EqCircDiamCh1          : num  32.3 23.4 19.5 18.1 18.2 ...\n##  $ EqEllipseLWRCh1        : num  1.56 1.38 3.39 1.38 1.62 ...\n##  $ EqEllipseOblateVolCh1  : num  2233 802 725 368 404 ...\n##  $ EqEllipseProlateVolCh1 : num  1433 583 214 267 250 ...\n##  $ EqSphereAreaCh1        : num  3279 1727 1195 1027 1036 ...\n##  $ EqSphereVolCh1         : num  17654 6751 3884 3096 3134 ...\n##  $ FiberAlign2Ch3         : num  0.488 0.301 0.22 0.364 0.359 ...\n##  $ FiberAlign2Ch4         : num  0.352 0.522 0.733 0.481 0.244 ...\n##  $ FiberLengthCh1         : num  64.3 21.1 43.1 22.3 26.5 ...\n##  $ FiberWidthCh1          : num  13.2 21.1 7.4 12.1 10.2 ...\n##  $ IntenCoocASMCh3        : num  0.02805 0.00686 0.03096 0.10816 0.01303 ...\n##  $ IntenCoocASMCh4        : num  0.01259 0.00614 0.01103 0.00995 0.00896 ...\n##  $ IntenCoocContrastCh3   : num  8.23 14.45 7.3 6.16 9.4 ...\n##  $ IntenCoocContrastCh4   : num  6.98 16.7 13.39 10.59 10.3 ...\n##  $ IntenCoocEntropyCh3    : num  6.82 7.58 6.31 5.04 6.96 ...\n##  $ IntenCoocEntropyCh4    : num  7.1 7.67 7.2 7.13 7.14 ...\n##  $ IntenCoocMaxCh3        : num  0.1532 0.0284 0.1628 0.3153 0.0739 ...\n##  $ IntenCoocMaxCh4        : num  0.0739 0.0232 0.0775 0.0586 0.0348 ...\n##  $ KurtIntenCh1           : num  -0.249 -0.293 0.626 -0.365 -0.556 ...\n##  $ KurtIntenCh3           : num  -0.331 1.051 0.128 1.083 -0.512 ...\n##  $ KurtIntenCh4           : num  -0.265 0.151 -0.347 -0.626 -0.647 ...\n##  $ LengthCh1              : num  47.2 28.1 37.9 23.1 26.3 ...\n##  $ NeighborAvgDistCh1     : num  174 158 206 264 231 ...\n##  $ NeighborMinDistCh1     : num  30.1 34.9 33.1 38.4 29.8 ...\n##  $ NeighborVarDistCh1     : num  81.4 90.4 116.9 88.5 103.5 ...\n##  $ PerimCh1               : num  154.9 84.6 101.1 68.7 73.4 ...\n##  $ ShapeBFRCh1            : num  0.54 0.724 0.589 0.635 0.557 ...\n##  $ ShapeLWRCh1            : num  1.47 1.33 2.83 1.31 1.49 ...\n##  $ ShapeP2ACh1            : num  2.26 1.27 2.55 1.4 1.59 ...\n##  $ SkewIntenCh1           : num  0.399 0.472 0.882 0.547 0.443 ...\n##  $ SkewIntenCh3           : num  0.62 0.971 1 1.432 0.556 ...\n##  $ SkewIntenCh4           : num  0.527 0.325 0.604 0.704 0.137 ...\n##  $ SpotFiberCountCh3      : int  4 2 4 0 1 1 4 2 2 2 ...\n##  $ SpotFiberCountCh4      : int  11 6 7 5 4 5 4 2 5 1 ...\n##  $ TotalIntenCh1          : int  24964 11552 5545 4613 4340 14461 4743 88725 136957 79885 ...\n##  $ TotalIntenCh2          : int  160997 47510 28869 30855 30719 74259 15434 148012 57421 62235 ...\n##  $ TotalIntenCh3          : int  54675 26344 8042 3332 5548 14474 6265 58224 20304 23878 ...\n##  $ TotalIntenCh4          : int  128368 43959 8843 11466 17588 23099 17534 120536 15482 98948 ...\n##  $ VarIntenCh1            : num  18.8 17.3 13.8 13.9 12.3 ...\n##  $ VarIntenCh3            : num  56.7 37.7 30 18.6 17.7 ...\n##  $ VarIntenCh4            : num  118.4 49.5 24.7 40.3 41.9 ...\n##  $ WidthCh1               : num  32.2 21.2 13.4 17.5 17.7 ...\n##  $ XCentroid              : int  215 371 487 211 172 276 239 95 438 386 ...\n##  $ YCentroid              : int  347 252 295 495 207 385 404 95 16 14 ..."
  },
  {
    "objectID": "data-preprocess.html#中心化和标准化",
    "href": "data-preprocess.html#中心化和标准化",
    "title": "附录 A — 常见的数据预处理方法",
    "section": "A.2 中心化和标准化",
    "text": "A.2 中心化和标准化\n某些算法对预测变量是有要求的，比如需要预测变量具有相同的尺度，如果有的预测变量范围是0.10.2，但是有的却是1000020000，这种变量间的绝大差距会影像某些模型的稳定性，所以需要想办法把它们变成差不多的范围（有个专有名词：无量纲化）。\n中心化和标准化可以解决这样的问题。\n中心化是将所有变量减去其均值，其结果是变换后的变量均值为0；标准化是将每个变量除以其自身的标准差，标准化迫使变量的标准差为1。\nR语言中scale()函数可实现中心化和标准化，就不多做介绍了。"
  },
  {
    "objectID": "data-preprocess.html#偏度问题",
    "href": "data-preprocess.html#偏度问题",
    "title": "附录 A — 常见的数据预处理方法",
    "section": "A.3 偏度问题",
    "text": "A.3 偏度问题\n无偏分布类似我们常说的正态分布，有偏分布又分为右偏和左偏，分别类似正偏态分布和负偏态分布。\n一个判断数据有偏的黄金标准：如果最大值与最小值的比例超过20，那么我们认为数据有偏。\n可以通过计算偏度统计量来衡量偏度。如果预测变量分布是大致对称的，那么偏度将接近于0，右偏分布偏度大于0，越大说明偏的越厉害；左偏分布偏度小于0，越小说明偏的越厉害。\n计算偏度的包很多。\n使用e1071包查看变量的偏度\n\nlibrary(e1071)\n# 查看偏度\nskewness(segData$AngleCh1)\n## [1] -0.02426252\n## [1] -0.02426252\n\n# 查看每一列的偏度\nskewValues &lt;- apply(segData, 2, skewness)\nhead(skewValues)\n##    AngleCh1     AreaCh1 AvgIntenCh1 AvgIntenCh2 AvgIntenCh3 AvgIntenCh4 \n## -0.02426252  3.52510745  2.95918524  0.84816033  2.20234214  1.90047128\n\n也可以通过psych包查看：\n\npsych::skew(segData$AngleCh1) # 偏度\n## [1] -0.02426252\n\npsych::kurtosi(segData$AngleCh1) # 峰度\n## [1] -0.8594789\n\n通过对数据进行变换可以一定程度解决偏度的问题，常用的方法有：取对数(log)，平方根，倒数，Box&Cox法等。\nlog、平方根、倒数这些很简单，就不演示了，下面演示下BoxCox变换。\n\n# 准备对数据进行BoxCox变换\nCh1AreaTrans &lt;- BoxCoxTrans(segData$AreaCh1)\nCh1AreaTrans\n## Box-Cox Transformation\n## \n## 1009 data points used to estimate Lambda\n## \n## Input data summary:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   150.0   194.0   256.0   325.1   376.0  2186.0 \n## \n## Largest/Smallest: 14.6 \n## Sample Skewness: 3.53 \n## \n## Estimated Lambda: -0.9\n\n# 进行变换\nAreaCh1_transed &lt;- predict(Ch1AreaTrans, segData$AreaCh1)\n\n# 查看变换前、后的数据\nhead(segData$AreaCh1)\n## [1] 819 431 298 256 258 358\nhead(AreaCh1_transed)\n## [1] 1.108458 1.106383 1.104520 1.103554 1.103607 1.105523\n\n这里可以看到caret对数据预处理的方式，首先是选择方法，然后使用predict()函数把变换应用到具体的变量上。这是caret的基本操作，大家一定要记住！\n对于变换前后的数据变化，只看数字没有直观的感受，下面给大家画图演示。\n\n# 画图看变换前后\nopar &lt;- par(mfrow=c(1,2))\nhist(segData$AreaCh1)\nhist(AreaCh1_transed)\n\n\n\npar(opar)\n\n可以明显看到变换前是右偏分布，变换后基本接近无偏，可以再次计算偏度看看：\n\npsych::skew(AreaCh1_transed)\n## [1] 0.0976087\n\n下面是BoxCox变换的一点点扩展，不看也影响不大。\nBoxCox变换需要一个参数lambda，这个参数需要我们计算并指定，如上使用caret进行变换时，它会自动帮我们处理好，其中一句代码显示Estimated Lambda: -0.9，也就是lambda=0.9。\n还有很多R包可以实现BoxCox变换，其中比较简单的是forecast，简单演示如下：\n\nlibrary(forecast)\n## Warning: package 'forecast' was built under R version 4.2.3\n## Registered S3 method overwritten by 'quantmod':\n##   method            from\n##   as.zoo.data.frame zoo\n\nbest.lambda &lt;- BoxCox.lambda(segData$AreaCh1) # 计算lambda\nbest.lambda\n## [1] -0.9999264\n\nAreaCh1.transformed &lt;- BoxCox(segData$AreaCh1, lambda = best.lambda) # 变换\nhead(AreaCh1.transformed)\n## [1] 0.9988519 0.9977522 0.9967163 0.9961655 0.9961958 0.9972789\n\ny0 &lt;- InvBoxCox(AreaCh1.transformed,lambda=best.lambda) # 还原"
  },
  {
    "objectID": "data-preprocess.html#解决离群值",
    "href": "data-preprocess.html#解决离群值",
    "title": "附录 A — 常见的数据预处理方法",
    "section": "A.4 解决离群值",
    "text": "A.4 解决离群值\n离群值其实是有明确定义的，通常我们会选择直接删除离群值，但是还是要根据实际情况来看，有的离群值是非常有意义的，这样的离群值不能直接删除。\n\n有的离群值可能是数据录入时不小心输错了，比如错把收缩压132mmHg录成了 -132mmHg，只需要改正即可；\n在样本量较小时，不宜直接删除离群值，有的离群值可能是因为数据来自一个明显有偏的分布，只是因为我们的样本量太小无法观测到这个偏度；\n有些离群值可能来自一个特殊的子集，只是这个子集才刚开始被收集到。\n\n有些模型对离群值很敏感，比如线性模型，这样是需要处理的，一个常见的方法是空间表示变换，该变换将预测变量取值映射到高纬的球上，它会把所有样本变换到离球心相等的球面上。在caret中可以实现。关于它的具体数学运算过程，感兴趣的自己了解即可，我不太感兴趣。\n在进行空间表示变换前，最好先进行中心化和标准化，这也和它的数学计算有关，我也不太感兴趣。\n\n# 变换前的图形\ndata(mdrr)\ntransparentTheme(trans = .4)\n\nplotSubset &lt;- data.frame(scale(mdrrDescr[, c(\"nC\", \"X4v\")])) \nxyplot(nC ~ X4v,\n       data = plotSubset,\n       groups = mdrrClass, \n       auto.key = list(columns = 2))\n\n\n\n\n\n# 变换后的图形\ntransformed &lt;- spatialSign(plotSubset)\ntransformed &lt;- as.data.frame(transformed)\nxyplot(nC ~ X4v, \n       data = transformed, \n       groups = mdrrClass, \n       auto.key = list(columns = 2)) \n\n\n\n\n是不是很神奇？"
  },
  {
    "objectID": "data-preprocess.html#降维和特征提取",
    "href": "data-preprocess.html#降维和特征提取",
    "title": "附录 A — 常见的数据预处理方法",
    "section": "A.5 降维和特征提取",
    "text": "A.5 降维和特征提取\n有很多方法，比如PCA, ICA, PLS, UMAP等，最流行的还是PCA，主要是它给出的主成分是彼此不相关的，这恰好符合一些模型的需求。\n对数据进行PCA变换之前，最好先解决偏度问题，然后进行中心化和标准化，和它的数学计算过程有关，感兴趣的自己了解。\n可视化前后不同：\n\n# 主成分分析，可参考我之前的推文\npr &lt;- prcomp(~ AvgIntenCh1 + EntropyIntenCh1, \n             data = segData, \n             scale. = TRUE)\n\n# 可视化前后图形\nlibrary(ggplot2)\n\np1 &lt;- ggplot(segData, aes(AvgIntenCh1,EntropyIntenCh1))+\n  geom_point()+\n  labs(x=\"Channel 1 Fiber Width\",y=\"Intensity Entropy Channel 1\")+\n  theme_bw()\np2 &lt;- ggplot(as.data.frame(pr$x), aes(PC1,PC2))+\n  geom_point()+\n  theme_bw()\ncowplot::plot_grid(p1,p2)"
  },
  {
    "objectID": "data-preprocess.html#处理缺失值",
    "href": "data-preprocess.html#处理缺失值",
    "title": "附录 A — 常见的数据预处理方法",
    "section": "A.6 处理缺失值",
    "text": "A.6 处理缺失值\n处理缺失值主要有两种方法，直接删除或者进行插补，使用哪种方法应取决于对数据的理解！\n一些常见的缺失值处理方法可以参考我之前的推文：我常用的缺失值插补方法"
  },
  {
    "objectID": "data-preprocess.html#过滤",
    "href": "data-preprocess.html#过滤",
    "title": "附录 A — 常见的数据预处理方法",
    "section": "A.7 过滤",
    "text": "A.7 过滤\n这里的过滤和解决共线性，其实部分属于特征选择的范围，就是大家常见的自变量选择问题，这个问题在以后的推文中还会详细介绍。\n\n冗余的变量通常增加了模型的复杂度而非信息量\n\n主要是过滤两种变量：(近)零方差变量和高度相关变量。\n如果一个变量只有1个值，那么这个变量的方差为0；如果一个变量只有少量不重复的取值，这种变量称为近零方差变量；这2种变量包含的信息太少了，应当过滤；\n检测近零方差变量的准则是：\n\n不重复取值的数目与样本量的比值低（比如10%）；\n最高频数和次高频数的比值高（比如20%）\n\n如果两个变量相关性太高，那么它们携带的信息可能很多是重叠的，会对某些模型产生较大的影响，应当解决。\n移除共线变量的方法如下：\n\n计算预测变量的相关系数矩阵\n找出相关系数绝对值最大的那对预测变量（记为变量A和B）\n分别计算A和B和其他预测变量的相关系数\n如果A的平均相关系数更大，移除A，否则移除B\n重复步骤2-4，直至所有相关系数的绝对值都低于设定的阈值\n\ncaret可以轻松实现以上过程。\n使用mdrr数据集演示。其中一列nR11大部分都是501，这种变量方差是很小的！\n\ndata(mdrr)\ntable(mdrrDescr$nR11) # 大部分值都是0\n## \n##   0   1   2 \n## 501   4  23\n\nsd(mdrrDescr$nR11)^2 # 方差很小！\n## [1] 0.1731787\n\n使用nearZeroVar()找出零方差和近零方差变量，结果中会给出zeroVar和nzv两列，用逻辑值表示是不是近零方差变量或者零方差变量。\n\nnzv &lt;- nearZeroVar(mdrrDescr, saveMetrics= TRUE)\nnzv[nzv$nzv,][1:10,]\n##        freqRatio percentUnique zeroVar  nzv\n## nTB     23.00000     0.3787879   FALSE TRUE\n## nBR    131.00000     0.3787879   FALSE TRUE\n## nI     527.00000     0.3787879   FALSE TRUE\n## nR03   527.00000     0.3787879   FALSE TRUE\n## nR08   527.00000     0.3787879   FALSE TRUE\n## nR11    21.78261     0.5681818   FALSE TRUE\n## nR12    57.66667     0.3787879   FALSE TRUE\n## D.Dr03 527.00000     0.3787879   FALSE TRUE\n## D.Dr07 123.50000     5.8712121   FALSE TRUE\n## D.Dr08 527.00000     0.3787879   FALSE TRUE\n\n去掉近零方差变量：\n\ndim(mdrrDescr)\n## [1] 528 342\n\nnzv &lt;- nearZeroVar(mdrrDescr)\nfilteredDescr &lt;- mdrrDescr[, -nzv]\ndim(filteredDescr)\n## [1] 528 297\n\n下面是处理高度相关的变量。\n\n# 相关系数矩阵\ncorrelations &lt;- cor(segData)\ndim(correlations)\n## [1] 58 58\n\n# 可视化相关系数矩阵，中间几个颜色深的就是高度相关的变量\nlibrary(corrplot)\n## corrplot 0.92 loaded\ncorrplot(correlations, order = \"hclust\",tl.col = \"black\")\n\n\n\n\n去掉高度相关的变量：\n\n# 阈值设为0.75\nhighCorr &lt;- findCorrelation(correlations, cutoff = 0.75)\nlength(highCorr)\n## [1] 32\nhead(highCorr)\n## [1] 23 40 43 36  7 15\n\n# 去掉高度相关的变量\nfilteredSegData &lt;- segData[, -highCorr]"
  },
  {
    "objectID": "data-preprocess.html#共线性",
    "href": "data-preprocess.html#共线性",
    "title": "附录 A — 常见的数据预处理方法",
    "section": "A.8 共线性",
    "text": "A.8 共线性\n假设一个下面这种的数据，其中第2列和第3列的值加起来和第1列一样，第4,5,6列的值起来也和第1列一样。这种数据的某些变量间是有高度共线性的。\n\nltfrDesign &lt;- matrix(0, nrow=6, ncol=6)\nltfrDesign[,1] &lt;- c(1, 1, 1, 1, 1, 1)\nltfrDesign[,2] &lt;- c(1, 1, 1, 0, 0, 0)\nltfrDesign[,3] &lt;- c(0, 0, 0, 1, 1, 1)\nltfrDesign[,4] &lt;- c(1, 0, 0, 1, 0, 0)\nltfrDesign[,5] &lt;- c(0, 1, 0, 0, 1, 0)\nltfrDesign[,6] &lt;- c(0, 0, 1, 0, 0, 1)\n\nltfrDesign\n##      [,1] [,2] [,3] [,4] [,5] [,6]\n## [1,]    1    1    0    1    0    0\n## [2,]    1    1    0    0    1    0\n## [3,]    1    1    0    0    0    1\n## [4,]    1    0    1    1    0    0\n## [5,]    1    0    1    0    1    0\n## [6,]    1    0    1    0    0    1\n\nfindLinearCombos()可以通过算法给出需要去除的变量，关于具体的方法可以官网查看。\n\ncomboInfo &lt;- findLinearCombos(ltfrDesign)\ncomboInfo\n## $linearCombos\n## $linearCombos[[1]]\n## [1] 3 1 2\n## \n## $linearCombos[[2]]\n## [1] 6 1 4 5\n## \n## \n## $remove\n## [1] 3 6\n\n结果给出了需要去除的变量是第3列和第6列。\n\n# 去除第3列和第6列\nltfrDesign[, -comboInfo$remove]\n##      [,1] [,2] [,3] [,4]\n## [1,]    1    1    1    0\n## [2,]    1    1    0    1\n## [3,]    1    1    0    0\n## [4,]    1    0    1    0\n## [5,]    1    0    0    1\n## [6,]    1    0    0    0"
  },
  {
    "objectID": "data-preprocess.html#构建虚拟变量",
    "href": "data-preprocess.html#构建虚拟变量",
    "title": "附录 A — 常见的数据预处理方法",
    "section": "A.9 构建虚拟变量",
    "text": "A.9 构建虚拟变量\n最常见的回归分析中的哑变量设置，可以参考之前的推文，详细介绍了常见的分类变量的编码方式：分类变量进行回归分析时的编码方案\n这里介绍下独热编码（one-hot encoding），和哑变量编码稍有不同，哑变量是变成k-1个变量，独热编码是变成k个变量。\n使用以下数据进行演示\n\ndata(\"cars\", package = \"caret\")\nhead(cars)\n##      Price Mileage Cylinder Doors Cruise Sound Leather Buick Cadillac Chevy\n## 1 22661.05   20105        6     4      1     0       0     1        0     0\n## 2 21725.01   13457        6     2      1     1       0     0        0     1\n## 3 29142.71   31655        4     2      1     1       1     0        0     0\n## 4 30731.94   22479        4     2      1     0       0     0        0     0\n## 5 33358.77   17590        4     2      1     1       1     0        0     0\n## 6 30315.17   23635        4     2      1     0       0     0        0     0\n##   Pontiac Saab Saturn convertible coupe hatchback sedan wagon\n## 1       0    0      0           0     0         0     1     0\n## 2       0    0      0           0     1         0     0     0\n## 3       0    1      0           1     0         0     0     0\n## 4       0    1      0           1     0         0     0     0\n## 5       0    1      0           1     0         0     0     0\n## 6       0    1      0           1     0         0     0     0\n\ntype &lt;- c(\"convertible\", \"coupe\", \"hatchback\", \"sedan\", \"wagon\")\ncars$Type &lt;- factor(apply(cars[, 14:18], 1, function(x) type[which(x == 1)]))\n\ncarSubset &lt;- cars[sample(1:nrow(cars), 20), c(1, 2, 19)]\n\n# 上面是数据生成过程，不重要，记住下面这个数据的样子即可！！\nhead(carSubset)\n##        Price Mileage        Type\n## 439 32038.34   35326       sedan\n## 200 69133.73    7892 convertible\n## 709 16803.12   25874   hatchback\n## 21  28416.46   14613       sedan\n## 666 17685.20   15898       coupe\n## 185 19448.23   27721       sedan\nlevels(carSubset$Type) # Type是一个因子型变量\n## [1] \"convertible\" \"coupe\"       \"hatchback\"   \"sedan\"       \"wagon\"\n\n现在把Type这个变量进行独热编码。\n使用dummyVars构建虚拟变量：\n\nsimpleMod &lt;- dummyVars(~Mileage + Type, # 用mileage和Type对价格进行预测\n                       data = carSubset,\n                       levelsOnly = TRUE) # 从列名中移除因子变量的名称\nsimpleMod\n## Dummy Variable Object\n## \n## Formula: ~Mileage + Type\n## 2 variables, 1 factors\n## Factor variable names will be removed\n## A less than full rank encoding is used\n\n接下来就可以使用predict和simpleMod对训练集进行生成虚拟变量的操作了：\n\npredict(simpleMod, head(carSubset))\n##     Mileage convertible coupe hatchback sedan wagon\n## 439   35326           0     0         0     1     0\n## 200    7892           1     0         0     0     0\n## 709   25874           0     0         1     0     0\n## 21    14613           0     0         0     1     0\n## 666   15898           0     1         0     0     0\n## 185   27721           0     0         0     1     0\n\n可以看到Type变量没有了，完成了虚拟变量的转换。\n假如你认为车型和里程有交互影响，则可以使用:表示：\n\nwithInteraction &lt;- dummyVars(~Mileage + Type + Mileage:Type,\n                             data = carSubset,\n                             levelsOnly = TRUE)\nwithInteraction\n## Dummy Variable Object\n## \n## Formula: ~Mileage + Type + Mileage:Type\n## 2 variables, 1 factors\n## Factor variable names will be removed\n## A less than full rank encoding is used\n\n应用于新的数据集：\n\npredict(withInteraction, head(carSubset))\n##     Mileage convertible coupe hatchback sedan wagon Mileage:Typeconvertible\n## 439   35326           0     0         0     1     0                       0\n## 200    7892           1     0         0     0     0                    7892\n## 709   25874           0     0         1     0     0                       0\n## 21    14613           0     0         0     1     0                       0\n## 666   15898           0     1         0     0     0                       0\n## 185   27721           0     0         0     1     0                       0\n##     Mileage:Typecoupe Mileage:Typehatchback Mileage:Typesedan Mileage:Typewagon\n## 439                 0                     0             35326                 0\n## 200                 0                     0                 0                 0\n## 709                 0                 25874                 0                 0\n## 21                  0                     0             14613                 0\n## 666             15898                     0                 0                 0\n## 185                 0                     0             27721                 0"
  },
  {
    "objectID": "data-preprocess.html#区间化预测变量",
    "href": "data-preprocess.html#区间化预测变量",
    "title": "附录 A — 常见的数据预处理方法",
    "section": "A.10 区间化预测变量",
    "text": "A.10 区间化预测变量\n主要是为了好解释结果，比如把血压分为高血压1级、2级、3级，把贫血分为轻中重极重等，这样比如你做logistic回归，可以说血压每增高一个等级，因变量的风险增加多少，但是你如果说血压值每增加1mmHg，因变量增加多少倍，这就有点扯了。"
  },
  {
    "objectID": "data-preprocess.html#多个预处理步骤放一起",
    "href": "data-preprocess.html#多个预处理步骤放一起",
    "title": "附录 A — 常见的数据预处理方法",
    "section": "A.11 多个预处理步骤放一起",
    "text": "A.11 多个预处理步骤放一起\n在caret中是通过preProcess()函数里面的method参数实现的，把不同的预处理步骤按照顺序写好即可。\n\nlibrary(AppliedPredictiveModeling)\ndata(schedulingData)\nstr(schedulingData)\n## 'data.frame':    4331 obs. of  8 variables:\n##  $ Protocol   : Factor w/ 14 levels \"A\",\"C\",\"D\",\"E\",..: 4 4 4 4 4 4 4 4 4 4 ...\n##  $ Compounds  : num  997 97 101 93 100 100 105 98 101 95 ...\n##  $ InputFields: num  137 103 75 76 82 82 88 95 91 92 ...\n##  $ Iterations : num  20 20 10 20 20 20 20 20 20 20 ...\n##  $ NumPending : num  0 0 0 0 0 0 0 0 0 0 ...\n##  $ Hour       : num  14 13.8 13.8 10.1 10.4 ...\n##  $ Day        : Factor w/ 7 levels \"Mon\",\"Tue\",\"Wed\",..: 2 2 4 5 5 3 5 5 5 3 ...\n##  $ Class      : Factor w/ 4 levels \"VF\",\"F\",\"M\",\"L\": 2 1 1 1 1 1 1 1 1 1 ...\n\n# 中心化、标准化、YeoJohnson变换\npp_hpc &lt;- preProcess(schedulingData[, -8], \n                     method = c(\"center\", \"scale\", \"YeoJohnson\"))\npp_hpc\n## Created from 4331 samples and 7 variables\n## \n## Pre-processing:\n##   - centered (5)\n##   - ignored (2)\n##   - scaled (5)\n##   - Yeo-Johnson transformation (5)\n## \n## Lambda estimates for Yeo-Johnson transformation:\n## -0.08, -0.03, -1.05, -1.1, 1.44\n\n# 应用于数据\ntransformed &lt;- predict(pp_hpc, newdata = schedulingData[, -8])\nhead(transformed)\n##   Protocol  Compounds InputFields Iterations NumPending         Hour Day\n## 1        E  1.2289592  -0.6324580 -0.0615593  -0.554123  0.004586516 Tue\n## 2        E -0.6065826  -0.8120473 -0.0615593  -0.554123 -0.043733201 Tue\n## 3        E -0.5719534  -1.0131504 -2.7894869  -0.554123 -0.034967177 Thu\n## 4        E -0.6427737  -1.0047277 -0.0615593  -0.554123 -0.964170752 Fri\n## 5        E -0.5804713  -0.9564504 -0.0615593  -0.554123 -0.902085020 Fri\n## 6        E -0.5804713  -0.9564504 -0.0615593  -0.554123  0.698108782 Wed\n\nmean(schedulingData$NumPending == 0)\n## [1] 0.7561764\n\n# 进行中心化、标准化、YeoJohnson、nzv\npp_no_nzv &lt;- preProcess(schedulingData[, -8], \n                        method = c(\"center\", \"scale\", \"YeoJohnson\", \"nzv\"))\npp_no_nzv\n## Created from 4331 samples and 7 variables\n## \n## Pre-processing:\n##   - centered (4)\n##   - ignored (2)\n##   - removed (1)\n##   - scaled (4)\n##   - Yeo-Johnson transformation (4)\n## \n## Lambda estimates for Yeo-Johnson transformation:\n## -0.08, -0.03, -1.05, 1.44\n\npredict(pp_no_nzv, newdata = schedulingData[1:6, -8])\n##   Protocol  Compounds InputFields Iterations         Hour Day\n## 1        E  1.2289592  -0.6324580 -0.0615593  0.004586516 Tue\n## 2        E -0.6065826  -0.8120473 -0.0615593 -0.043733201 Tue\n## 3        E -0.5719534  -1.0131504 -2.7894869 -0.034967177 Thu\n## 4        E -0.6427737  -1.0047277 -0.0615593 -0.964170752 Fri\n## 5        E -0.5804713  -0.9564504 -0.0615593 -0.902085020 Fri\n## 6        E -0.5804713  -0.9564504 -0.0615593  0.698108782 Wed\n\n如果你用过tidymodels，那你应该知道里面的数据预处理步骤是通过recipes包完成的，每一步都是step_xx，说实话我觉得caret的这种方式更加简洁易懂！\n以上就是数据预处理的一般过程，一个caret包可以解决上面所有的问题，有兴趣的小伙伴可以自行学习。\n数据预处理是一个非常系统且专业的过程，如同开头说的那样：最有效的编码数据的方法来自于建模者对数据的理解，而不是通过任何数学方法，在对数据进行预处理之前，一定要仔细理解自己的数据哦，结果导向的思维是不对的哦！"
  },
  {
    "objectID": "data-split.html#留出法holdout",
    "href": "data-split.html#留出法holdout",
    "title": "附录 B — 常见的数据划分方法",
    "section": "B.1 留出法(holdout)",
    "text": "B.1 留出法(holdout)\n大家最常使用的，把数据集随机划分为训练集(train)/测试集(test)的做法就是holdout，其中训练集用于建模，测试集用于评估模型表现。\n有时还会把数据划分为训练集(train)/测试集(test)/验证集(validation)，训练集用来训练模型，测试集查看模型表现，不断进行调整，然后训练集和测试集一起训练出一个模型，最后用验证集评估模型表现。"
  },
  {
    "objectID": "data-split.html#交叉验证cross-validation",
    "href": "data-split.html#交叉验证cross-validation",
    "title": "附录 B — 常见的数据划分方法",
    "section": "B.2 交叉验证(cross validation)",
    "text": "B.2 交叉验证(cross validation)\n交叉验证，意思就是一份数据既用作训练，也用作验证，互相交叉，主要有以下几种：\nK折交叉验证(K fold cross validation)，就是把数据集随机分为K个样本量基本相同的子数据集。比如5折交叉验证，就是把数据集分为5个子集（比如分成A,B,C,D,E,5份），在建模时，首先会使用其中A,B,C,D,4份数据进行建模，然后用剩下的E数据评估模型表现，接下来使用A,B,C,E，4份数据建模，用剩下的D评估模型表现。这样依次进行5个循环，每份数据都会用来评估模型表现。最后将得到的5个模型表现结果进行汇总。\n下面是一个10折交叉验证的示意图：\n\n留一交叉验证(LOOCV, leave one out cross validation)，是K折交叉验证的特例。每次都只留1个样本用于评估模型表现，所以这里的K其实就等于样本量，每一个样本都会被用来评估模型表现。\n重复交叉验证(repeated cross validation)，也是K折交叉验证的扩展版本，比如，重复10次的5折交叉验证，就是把5折交叉验证这个过程重复10遍。\n蒙特卡洛交叉验证(Monte Carlo cross validation)，也是交叉验证的一个变种。留出法是将数据集划分1次，而蒙特卡洛交叉验证就是将留出法进行多次。"
  },
  {
    "objectID": "data-split.html#bootstrap",
    "href": "data-split.html#bootstrap",
    "title": "附录 B — 常见的数据划分方法",
    "section": "B.3 bootstrap",
    "text": "B.3 bootstrap\n自助法，即有放回的随机抽样法。具体做法如下：\n比如，一个数据集有100个样本，每次随机抽取1个，然后放回，再随机抽取1个，这样的过程重复100次，就得到了一个和原数据集样本量相等的抽样数据集，这个抽样数据集就叫做自助集。\n由于每次都是有放回然后再随机抽取，所以一个自助集中可能有多个同一样本！所以就有可能在100次随机抽取中，有一些没被抽中过的样本，这些样本就被称为袋外样本(out of bag)，其中被抽中的样本(也就是自助集)用于训练模型，袋外样本用来评估模型表现。随机森林算法就是使用这种方法的！"
  },
  {
    "objectID": "data-split.html#其他方法",
    "href": "data-split.html#其他方法",
    "title": "附录 B — 常见的数据划分方法",
    "section": "B.4 其他方法",
    "text": "B.4 其他方法\n除了以上方法，其实还有非常多没有介绍，比如在mlr3中经常使用的嵌套重抽样，这些大家感兴趣可以自行了解。"
  },
  {
    "objectID": "data-split.html#重抽样的目的",
    "href": "data-split.html#重抽样的目的",
    "title": "附录 B — 常见的数据划分方法",
    "section": "B.5 重抽样的目的",
    "text": "B.5 重抽样的目的\n经常有粉丝问我：为什么我用了各种方法，10折交叉验证、10折重复交叉验证、自助法，都用过了，为什么最后模型的表现还是很差？\n看到类似的问题，我想这部分朋友可能把重抽样的目的搞错了，重抽样的目的不是为了提高模型表现，重抽样也确实不能提高模型表现！开头我已说过，重抽样技术是为了让模型更好的认识数据而已，这样能够得到更加稳健、无偏的结果，但是对于提高模型表现没有直接的影响哦~\n你可以这么理解，如果你不重抽样，可能某次结果的AUC是0.8，再做一次可能就变成0.5了，而你重抽样10次，得到的结果是10次的平均，这样的结果很明显是更加稳健的。\n模型表现好不好首先是数据原因，一个牛逼的数据不需要复杂的模型也能有很好的结果，数据预处理对数据影响很大，大家可以参考上面的推文。另外还和模型本身的性质有关，比如模型的超参数、模型本身的上限等，这些会在以后陆续介绍。"
  },
  {
    "objectID": "data-split.html#为什么要单独划分出一部分数据",
    "href": "data-split.html#为什么要单独划分出一部分数据",
    "title": "附录 B — 常见的数据划分方法",
    "section": "B.6 为什么要单独划分出一部分数据",
    "text": "B.6 为什么要单独划分出一部分数据\n通常我们建立模型时，会把数据集A划分为A1和A2两份，A1用来训练模型，A2用来测试模型，在训练模型的过程中，完全不用使用到A2这部分数据。有些人不理解，把这种方法和嵌套重抽样混为一谈。其实这两个有着本质的区别。\n嵌套重抽样是在训练模型时使用的，把两份数据集全都用到了，而且两份数据集都会再叠加其他重抽样方法。\n但我们划分数据的目的是什么呢？我们是为了测试最终的模型表现。临床问题数据很珍贵，通常都只有1份，这种情况下我把这份数据全都用于训练模型，那我用什么测试训练出来的模型好坏呢？有的人喜欢把训练好的模型作用于用来训练模型的数据上，发现结果竟然很好，这样是不对的，这叫数据泄露，你的数据模型已经学习过了，这不是作弊吗？这样的模型结果能说明什么问题呢？\n所以一开始把数据就划分为2份是一个很好的解决方法。如果你有很多个数据集，你完全可以在其中1个数据集中使用各种方法建模。"
  },
  {
    "objectID": "data-split.html#方法选择建议",
    "href": "data-split.html#方法选择建议",
    "title": "附录 B — 常见的数据划分方法",
    "section": "B.7 方法选择建议",
    "text": "B.7 方法选择建议\n以上就是一些常见的重抽样方法，可以看到每种方法都强调一个问题，那就是随机！，只有随机，才能保证模型学习到这个数据集中的更多信息，才能获得稳健的模型表现！\n以下是一些方法选择建议：\n\n没有哪一种方法好，哪一种方法不好！！只有合不合适，没有好不好！\n如果样本量较小，建议选择重复10折交叉验证；\n如果样本量足够大，比如几万，几十万这种，随便选，都可以；\n如果目的不是得到最好的模型表现，而是为了在不同模型间进行选择，建议使用bootstrap；\n如果还不知道怎么选，建议都试一试，喜欢哪个选哪个"
  },
  {
    "objectID": "9999-appendix.html#r语言rtoolsrstudio的安装",
    "href": "9999-appendix.html#r语言rtoolsrstudio的安装",
    "title": "附录 C — 软件安装及其他合集",
    "section": "C.1 R语言、Rtools、Rstudio的安装",
    "text": "C.1 R语言、Rtools、Rstudio的安装\n请参考公众号推文：可能是最适合小白的R语言和R包安装教程\n或者b站视频：适合小白的R语言和Rstudio安装教程"
  },
  {
    "objectID": "9999-appendix.html#r包安装",
    "href": "9999-appendix.html#r包安装",
    "title": "附录 C — 软件安装及其他合集",
    "section": "C.2 R包安装",
    "text": "C.2 R包安装\n请参考公众号推文：可能是最好的R包安装教程\n或者b站视频：可能是最好用的R包安装教程"
  },
  {
    "objectID": "9999-appendix.html#临床预测模型",
    "href": "9999-appendix.html#临床预测模型",
    "title": "附录 C — 软件安装及其他合集",
    "section": "C.3 临床预测模型",
    "text": "C.3 临床预测模型\nR语言实战医学统计合集：R语言实战医学统计"
  },
  {
    "objectID": "9999-appendix.html#机器学习",
    "href": "9999-appendix.html#机器学习",
    "title": "附录 C — 软件安装及其他合集",
    "section": "C.4 机器学习",
    "text": "C.4 机器学习\nR语言机器学习合集：R语言机器学习"
  },
  {
    "objectID": "9999-appendix.html#生信数据挖掘",
    "href": "9999-appendix.html#生信数据挖掘",
    "title": "附录 C — 软件安装及其他合集",
    "section": "C.5 生信数据挖掘",
    "text": "C.5 生信数据挖掘\n生信数据挖掘合集：生信数据挖掘"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R语言实战临床预测模型",
    "section": "",
    "text": "前言\n谨以此书献给我不务正业的研究生生涯。"
  },
  {
    "objectID": "index.html#本书缘起",
    "href": "index.html#本书缘起",
    "title": "R语言实战临床预测模型",
    "section": "本书缘起",
    "text": "本书缘起\n我在2019年接触到R语言和临床预测模型，彼时还是“简单的纯生信也能随便发SCI的上古时代”，当时的临床预测模型并不像现在这么火爆，连培训班也只有零星的几个，收费不过1000块左右。\n然而随着大家愈加内卷，各种各样的培训班也越来越多，价格也是水涨船高，竟然都要3000+，甚至5000+了，真是离谱！但是内容并没有什么新意，无非就是列线图/ROC曲线/C-index/NRI/IDI/校准曲线/决策曲线等等。\n回想自己的学习经历，这些东西无非就是各种R语言操作而已，本人的公众号也一直向大家免费提供这些教程。这部分内容已经积累了几十篇推文，是时候做个总结了，我把这些内容整理在一起，方便有需要的人学习。\n本书github地址：https://github.com/ayueme/R_clinical_model"
  },
  {
    "objectID": "index.html#书籍简介",
    "href": "index.html#书籍简介",
    "title": "R语言实战临床预测模型",
    "section": "书籍简介",
    "text": "书籍简介\n本书主要介绍R语言在临床预测模型中的应用，重实践，少理论，全书只有少量内容是理论，其余部分都是R语言实操。\n临床预测模型和统计学以及机器学习交叉很多，本书虽然是R语言实现临床预测模型的入门书籍，但在阅读本书前，还需要你已经对临床预测模型、统计学、机器学习具有一定的了解。\n\n\n\n\n\n\n提醒\n\n\n\n本书不适合R语言零基础的人。\n如果你是刚入门的小白，我首先推荐你了解下R语言的基础知识，比如R语言和R包安装（初学者可参考附录）、Rstudio的界面、R语言中数据类型（向量、矩阵、数据框、列表等）、R语言中的数据导入导出、R语言的基础数据操作等。\n\n\n本书内容主要涉及模型建立、模型评价、模型比较3部分内容，其中模型建立和模型评价内容占比较多，模型比较部分主要是几个综合性R包的使用，简化多模型比较的流程。对于临床预测模型中常见的列线图、C-index、ROC曲线、校准曲线、决策曲线、临床影响曲线、NRI、IDI等内容，皆进行了详细的操作演示，同时提供多种实现方法。\n对于一些比较火爆的机器学习方法，如随机生存森林、生存支持向量机、deepsurv、Coxboost等内容，本书并未进行介绍，公众号会逐步更新这部分内容（随机生存森林已完结），需要的朋友可关注公众号：医学和生信笔记。\n限于本人水平等问题，难免会有一些错误，欢迎大家以各种方式批评指正，比如公众号留言、粉丝QQ群、github、个人微信等。\n本书会不定期更新，内容和格式都会不断完善。\n更新日志：\n\n20231015：首次上传\n\n\n\n\n\n\n\n注意\n\n\n\n本书实际上是我公众号历史推文的汇总，书中涉及的所有数据都可以在相关历史推文中免费获取！推文合集链接：临床预测模型\n我也准备了一个PDF版合集，内容和网页版一致，只是打包了所有的数据，付费获取（10元），介意勿扰！PDF版合集获取链接：R语言临床预测模型合集"
  },
  {
    "objectID": "index.html#作者简介",
    "href": "index.html#作者简介",
    "title": "R语言实战临床预测模型",
    "section": "作者简介",
    "text": "作者简介\n\n阿越，外科医生，R语言爱好者，长期分享R语言和医学统计学、临床预测模型、生信数据挖掘、R语言机器学习等知识。\n公众号：医学和生信笔记\n知乎：医学和生信笔记\nCSDN：医学和生信笔记\n哔哩哔哩：阿越就是我\nGithub：ayueme\nGitee：ayue2019"
  },
  {
    "objectID": "feature-selection_stepwise.html#加载数据",
    "href": "feature-selection_stepwise.html#加载数据",
    "title": "11  筛选变量逐步回归",
    "section": "11.1 加载数据",
    "text": "11.1 加载数据\n我们使用TCGA-BLCA的lncRNA数据，其中包括408个样本，time_months是生存时间，event是生存状态，1代表死亡，0代表生存，其余变量都是自变量。\n\nrm(list = ls())\nload(file = \"datasets/lnc_expr_clin.RData\")\n#去掉没有生存信息的样本\nlnc_expr_clin1 &lt;- lnc_expr_clin[!is.na(lnc_expr_clin$time_months),]\nlnc_expr_clin1 &lt;- lnc_expr_clin1[lnc_expr_clin1$time_months&gt;0,]\n\n#选择其中一部分数据\ndat.cox &lt;- lnc_expr_clin1[,c(72:73,1:59)]\ndim(dat.cox)\n## [1] 297  61\ndat.cox[1:4,1:6]\n##   event time_months   PGM5-AS1 LINC01082 AC005180.2 AC005180.1\n## 1     0       36.33 0.15064007 0.2642238  0.0000000  0.1547768\n## 2     0       13.87 0.06309362 0.1666554  0.3105983  0.2436603\n## 3     1       21.83 2.16399508 3.5662920  2.2454129  2.0073496\n## 4     0       18.20 2.73075081 1.7314314  0.8609916  0.7323014\n\n现在这个数据一共59个自变量，我们先使用所有自变量建立cox回归模型。"
  },
  {
    "objectID": "feature-selection_stepwise.html#建立模型",
    "href": "feature-selection_stepwise.html#建立模型",
    "title": "11  筛选变量逐步回归",
    "section": "11.2 建立模型",
    "text": "11.2 建立模型\n我们这个是生存数据，使用cox回归。如果你的数据是其他类型，使用逻辑回归或者线性回归都是可以的。\n\nlibrary(survival)\n\nfit.cox &lt;- coxph(Surv(time_months,event)~.,data = dat.cox)\nfit.cox\n## Call:\n## coxph(formula = Surv(time_months, event) ~ ., data = dat.cox)\n## \n##                     coef exp(coef)  se(coef)      z       p\n## `PGM5-AS1`     -0.008183  0.991850  0.222738 -0.037 0.97069\n## LINC01082       0.345614  1.412858  0.403674  0.856 0.39190\n## AC005180.2      0.977584  2.658027  0.906672  1.078 0.28094\n## AC005180.1      0.846348  2.331118  1.193460  0.709 0.47823\n## FENDRR         -0.653451  0.520247  0.548215 -1.192 0.23328\n## AC053503.3     -0.589548  0.554578  0.553104 -1.066 0.28647\n## MIR100HG        0.902471  2.465687  0.386229  2.337 0.01946\n## AP001107.5     -0.812922  0.443560  0.677700 -1.200 0.23032\n## `C5orf66-AS1`   0.094286  1.098873  0.295767  0.319 0.74989\n## NR4A1AS         0.874631  2.397990  0.336703  2.598 0.00939\n## AL162424.1      0.049223  1.050455  0.324490  0.152 0.87943\n## AF001548.1      0.949594  2.584659  0.788709  1.204 0.22860\n## AC099850.4      0.205430  1.228053  0.252745  0.813 0.41634\n## `MBNL1-AS1`    -0.798659  0.449932  0.675864 -1.182 0.23733\n## `ADAMTS9-AS1`  -0.065160  0.936917  1.776167 -0.037 0.97074\n## MIR22HG         0.108393  1.114486  0.228433  0.475 0.63514\n## MIR200CHG      -0.070914  0.931542  0.215534 -0.329 0.74214\n## AC093010.3     -0.658117  0.517825  0.347044 -1.896 0.05791\n## LINC00865      -0.282616  0.753809  0.284716 -0.993 0.32089\n## AP003071.4     -0.506228  0.602765  0.675734 -0.749 0.45377\n## PCAT6           0.347869  1.416047  0.199663  1.742 0.08146\n## LINC02657      -0.175082  0.839388  0.122482 -1.429 0.15287\n## `PPP1R14B-AS1`  0.144657  1.155643  0.238269  0.607 0.54377\n## AC012085.2     -2.267686  0.103552  1.671128 -1.357 0.17479\n## `ACTA2-AS1`    -0.084816  0.918681  0.760755 -0.111 0.91123\n## AC036108.3      1.405644  4.078154  1.413552  0.994 0.32003\n## AC079313.2      0.167743  1.182633  1.020173  0.164 0.86940\n## AC020916.1      0.037921  1.038649  0.201470  0.188 0.85070\n## SNHG25         -0.151295  0.859594  0.330536 -0.458 0.64715\n## AL049555.1      0.398962  1.490277  0.207738  1.921 0.05479\n## `MIR1-1HG-AS1` -1.851131  0.157059  1.991975 -0.929 0.35274\n## AC018904.1      0.026484  1.026838  0.233038  0.114 0.90952\n## SNHG12          0.144329  1.155264  0.344430  0.419 0.67519\n## `SPINT1-AS1`    0.676775  1.967522  0.374980  1.805 0.07110\n## `KRT7-AS`      -0.137828  0.871248  0.129775 -1.062 0.28821\n## MIR205HG       -0.076826  0.926051  0.161261 -0.476 0.63378\n## `HAND2-AS1`     1.853233  6.380415  1.742430  1.064 0.28751\n## AL445524.1     -0.255737  0.774345  0.220099 -1.162 0.24527\n## LINC01980      -0.171282  0.842584  0.128515 -1.333 0.18260\n## `ZNF710-AS1`   -0.959290  0.383165  0.459985 -2.085 0.03703\n## AC092718.4      0.010577  1.010633  0.272577  0.039 0.96905\n## AC008735.2     -0.002696  0.997308  0.291545 -0.009 0.99262\n## LINC01133       0.122659  1.130499  0.120170  1.021 0.30739\n## AC025575.2      0.158544  1.171804  0.135523  1.170 0.24205\n## `MAFG-DT`       0.343519  1.409901  0.242305  1.418 0.15627\n## CASC9          -0.118071  0.888633  0.154923 -0.762 0.44598\n## AL390719.2      0.177187  1.193854  0.225404  0.786 0.43182\n## AC002398.2     -1.089318  0.336446  1.662224 -0.655 0.51225\n## AC008736.1     -0.117863  0.888818  0.163847 -0.719 0.47193\n## AL161431.1      0.158805  1.172110  0.112004  1.418 0.15623\n## `PCCA-DT`      -0.456381  0.633572  0.254320 -1.795 0.07273\n## AC245041.2      0.243686  1.275944  0.200371  1.216 0.22392\n## U62317.1       -0.162513  0.850005  0.205601 -0.790 0.42928\n## U62317.2       -0.131903  0.876426  0.315579 -0.418 0.67597\n## `VPS9D1-AS1`   -0.044547  0.956431  0.174172 -0.256 0.79813\n## AL023284.4     -0.335339  0.715095  0.245641 -1.365 0.17220\n## AATBC           0.136654  1.146432  0.180919  0.755 0.45005\n## LINC00641       0.383262  1.467062  0.474750  0.807 0.41950\n## AC015912.3     -0.562875  0.569569  0.296322 -1.900 0.05749\n## \n## Likelihood ratio test=78.86  on 59 df, p=0.04311\n## n= 297, number of events= 71\n\n下面就是用逐步法选择变量。"
  },
  {
    "objectID": "feature-selection_stepwise.html#逐步选择",
    "href": "feature-selection_stepwise.html#逐步选择",
    "title": "11  筛选变量逐步回归",
    "section": "11.3 逐步选择",
    "text": "11.3 逐步选择\n我们使用逐步选择法进行变量筛选：\n\nfit.step &lt;- step(fit.cox,direction = \"both\")\n## Start:  AIC=794.12\n## Surv(time_months, event) ~ `PGM5-AS1` + LINC01082 + AC005180.2 + \n##     AC005180.1 + FENDRR + AC053503.3 + MIR100HG + AP001107.5 + \n##     `C5orf66-AS1` + NR4A1AS + AL162424.1 + AF001548.1 + AC099850.4 + \n##     `MBNL1-AS1` + `ADAMTS9-AS1` + MIR22HG + MIR200CHG + AC093010.3 + \n##     LINC00865 + AP003071.4 + PCAT6 + LINC02657 + `PPP1R14B-AS1` + \n##     AC012085.2 + `ACTA2-AS1` + AC036108.3 + AC079313.2 + AC020916.1 + \n##     SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + AC018904.1 + SNHG12 + \n##     `SPINT1-AS1` + `KRT7-AS` + MIR205HG + `HAND2-AS1` + AL445524.1 + \n##     LINC01980 + `ZNF710-AS1` + AC092718.4 + AC008735.2 + LINC01133 + \n##     AC025575.2 + `MAFG-DT` + CASC9 + AL390719.2 + AC002398.2 + \n##     AC008736.1 + AL161431.1 + `PCCA-DT` + AC245041.2 + U62317.1 + \n##     U62317.2 + `VPS9D1-AS1` + AL023284.4 + AATBC + LINC00641 + \n##     AC015912.3\n## \n##                  Df    AIC\n## - AC008735.2      1 792.12\n## - `ADAMTS9-AS1`   1 792.12\n## - `PGM5-AS1`      1 792.12\n## - AC092718.4      1 792.12\n## - `ACTA2-AS1`     1 792.13\n## - AC018904.1      1 792.13\n## - AL162424.1      1 792.14\n## - AC079313.2      1 792.15\n## - AC020916.1      1 792.15\n## - `VPS9D1-AS1`    1 792.18\n## - `C5orf66-AS1`   1 792.22\n## - MIR200CHG       1 792.23\n## - U62317.2        1 792.29\n## - SNHG12          1 792.29\n## - SNHG25          1 792.33\n## - MIR22HG         1 792.34\n## - MIR205HG        1 792.35\n## - `PPP1R14B-AS1`  1 792.49\n## - AC002398.2      1 792.56\n## - AC005180.1      1 792.63\n## - AC008736.1      1 792.65\n## - AATBC           1 792.69\n## - AP003071.4      1 792.69\n## - CASC9           1 792.70\n## - AL390719.2      1 792.74\n## - U62317.1        1 792.75\n## - LINC00641       1 792.76\n## - AC099850.4      1 792.79\n## - LINC01082       1 792.86\n## - `MIR1-1HG-AS1`  1 793.03\n## - AC036108.3      1 793.10\n## - LINC00865       1 793.13\n## - LINC01133       1 793.13\n## - `HAND2-AS1`     1 793.23\n## - `KRT7-AS`       1 793.25\n## - AC005180.2      1 793.25\n## - AC053503.3      1 793.29\n## - AL445524.1      1 793.49\n## - AC025575.2      1 793.50\n## - AF001548.1      1 793.55\n## - FENDRR          1 793.61\n## - AC245041.2      1 793.61\n## - `MBNL1-AS1`     1 793.62\n## - AP001107.5      1 793.84\n## - LINC01980       1 793.87\n## - AL023284.4      1 794.01\n## - AL161431.1      1 794.11\n## &lt;none&gt;              794.12\n## - `MAFG-DT`       1 794.13\n## - AC012085.2      1 794.14\n## - LINC02657       1 794.20\n## - PCAT6           1 795.17\n## - `PCCA-DT`       1 795.43\n## - `SPINT1-AS1`    1 795.45\n## - AC093010.3      1 795.84\n## - AL049555.1      1 795.88\n## - AC015912.3      1 795.94\n## - `ZNF710-AS1`    1 796.86\n## - MIR100HG        1 797.13\n## - NR4A1AS         1 798.62\n## \n## Step:  AIC=792.12\n## Surv(time_months, event) ~ `PGM5-AS1` + LINC01082 + AC005180.2 + \n##     AC005180.1 + FENDRR + AC053503.3 + MIR100HG + AP001107.5 + \n##     `C5orf66-AS1` + NR4A1AS + AL162424.1 + AF001548.1 + AC099850.4 + \n##     `MBNL1-AS1` + `ADAMTS9-AS1` + MIR22HG + MIR200CHG + AC093010.3 + \n##     LINC00865 + AP003071.4 + PCAT6 + LINC02657 + `PPP1R14B-AS1` + \n##     AC012085.2 + `ACTA2-AS1` + AC036108.3 + AC079313.2 + AC020916.1 + \n##     SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + AC018904.1 + SNHG12 + \n##     `SPINT1-AS1` + `KRT7-AS` + MIR205HG + `HAND2-AS1` + AL445524.1 + \n##     LINC01980 + `ZNF710-AS1` + AC092718.4 + LINC01133 + AC025575.2 + \n##     `MAFG-DT` + CASC9 + AL390719.2 + AC002398.2 + AC008736.1 + \n##     AL161431.1 + `PCCA-DT` + AC245041.2 + U62317.1 + U62317.2 + \n##     `VPS9D1-AS1` + AL023284.4 + AATBC + LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - `PGM5-AS1`      1 790.12\n## - `ADAMTS9-AS1`   1 790.12\n## - AC092718.4      1 790.12\n## - `ACTA2-AS1`     1 790.13\n## - AC018904.1      1 790.13\n## - AL162424.1      1 790.14\n## - AC079313.2      1 790.15\n## - AC020916.1      1 790.15\n## - `VPS9D1-AS1`    1 790.18\n## - `C5orf66-AS1`   1 790.22\n## - MIR200CHG       1 790.23\n## - SNHG12          1 790.31\n## - U62317.2        1 790.32\n## - SNHG25          1 790.33\n## - MIR22HG         1 790.34\n## - MIR205HG        1 790.35\n## - `PPP1R14B-AS1`  1 790.49\n## - AC002398.2      1 790.56\n## - AC005180.1      1 790.63\n## - AC008736.1      1 790.66\n## - AATBC           1 790.69\n## - AP003071.4      1 790.70\n## - CASC9           1 790.71\n## - AL390719.2      1 790.76\n## - U62317.1        1 790.76\n## - LINC00641       1 790.79\n## - AC099850.4      1 790.80\n## - LINC01082       1 790.86\n## - `MIR1-1HG-AS1`  1 791.05\n## - AC036108.3      1 791.10\n## - LINC01133       1 791.13\n## - LINC00865       1 791.14\n## - `HAND2-AS1`     1 791.23\n## - AC005180.2      1 791.25\n## - `KRT7-AS`       1 791.26\n## - AC053503.3      1 791.29\n## - AL445524.1      1 791.49\n## - AC025575.2      1 791.51\n## - AF001548.1      1 791.56\n## - FENDRR          1 791.61\n## - `MBNL1-AS1`     1 791.62\n## - AC245041.2      1 791.66\n## - AP001107.5      1 791.86\n## - LINC01980       1 791.90\n## - AL023284.4      1 792.01\n## &lt;none&gt;              792.12\n## - AL161431.1      1 792.12\n## - `MAFG-DT`       1 792.14\n## - AC012085.2      1 792.16\n## - LINC02657       1 792.20\n## - PCAT6           1 793.22\n## - `PCCA-DT`       1 793.43\n## - `SPINT1-AS1`    1 793.45\n## - AL049555.1      1 793.88\n## - AC093010.3      1 793.93\n## - AC015912.3      1 793.94\n## + AC008735.2      1 794.12\n## - `ZNF710-AS1`    1 794.86\n## - MIR100HG        1 795.13\n## - NR4A1AS         1 796.62\n## \n## Step:  AIC=790.12\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + `C5orf66-AS1` + \n##     NR4A1AS + AL162424.1 + AF001548.1 + AC099850.4 + `MBNL1-AS1` + \n##     `ADAMTS9-AS1` + MIR22HG + MIR200CHG + AC093010.3 + LINC00865 + \n##     AP003071.4 + PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + \n##     `ACTA2-AS1` + AC036108.3 + AC079313.2 + AC020916.1 + SNHG25 + \n##     AL049555.1 + `MIR1-1HG-AS1` + AC018904.1 + SNHG12 + `SPINT1-AS1` + \n##     `KRT7-AS` + MIR205HG + `HAND2-AS1` + AL445524.1 + LINC01980 + \n##     `ZNF710-AS1` + AC092718.4 + LINC01133 + AC025575.2 + `MAFG-DT` + \n##     CASC9 + AL390719.2 + AC002398.2 + AC008736.1 + AL161431.1 + \n##     `PCCA-DT` + AC245041.2 + U62317.1 + U62317.2 + `VPS9D1-AS1` + \n##     AL023284.4 + AATBC + LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - `ADAMTS9-AS1`   1 788.12\n## - AC092718.4      1 788.12\n## - `ACTA2-AS1`     1 788.13\n## - AC018904.1      1 788.13\n## - AL162424.1      1 788.14\n## - AC079313.2      1 788.15\n## - AC020916.1      1 788.16\n## - `VPS9D1-AS1`    1 788.19\n## - `C5orf66-AS1`   1 788.22\n## - MIR200CHG       1 788.23\n## - SNHG12          1 788.32\n## - U62317.2        1 788.32\n## - SNHG25          1 788.34\n## - MIR22HG         1 788.34\n## - MIR205HG        1 788.36\n## - `PPP1R14B-AS1`  1 788.49\n## - AC002398.2      1 788.56\n## - AC005180.1      1 788.64\n## - AC008736.1      1 788.66\n## - AATBC           1 788.70\n## - AP003071.4      1 788.70\n## - CASC9           1 788.71\n## - AL390719.2      1 788.76\n## - U62317.1        1 788.76\n## - LINC00641       1 788.79\n## - AC099850.4      1 788.80\n## - LINC01082       1 788.87\n## - `MIR1-1HG-AS1`  1 789.06\n## - LINC01133       1 789.14\n## - AC036108.3      1 789.14\n## - LINC00865       1 789.17\n## - `HAND2-AS1`     1 789.24\n## - `KRT7-AS`       1 789.26\n## - AC053503.3      1 789.32\n## - AC005180.2      1 789.34\n## - AL445524.1      1 789.51\n## - AC025575.2      1 789.51\n## - AF001548.1      1 789.58\n## - FENDRR          1 789.67\n## - `MBNL1-AS1`     1 789.67\n## - AC245041.2      1 789.67\n## - LINC01980       1 789.90\n## - AP001107.5      1 789.90\n## - AL023284.4      1 790.01\n## &lt;none&gt;              790.12\n## - AL161431.1      1 790.12\n## - `MAFG-DT`       1 790.20\n## - LINC02657       1 790.21\n## - AC012085.2      1 790.25\n## - PCAT6           1 791.23\n## - `SPINT1-AS1`    1 791.45\n## - `PCCA-DT`       1 791.45\n## - AL049555.1      1 791.88\n## - AC015912.3      1 791.99\n## - AC093010.3      1 791.99\n## + `PGM5-AS1`      1 792.12\n## + AC008735.2      1 792.12\n## - `ZNF710-AS1`    1 792.87\n## - MIR100HG        1 793.16\n## - NR4A1AS         1 794.70\n## \n## Step:  AIC=788.12\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + `C5orf66-AS1` + \n##     NR4A1AS + AL162424.1 + AF001548.1 + AC099850.4 + `MBNL1-AS1` + \n##     MIR22HG + MIR200CHG + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + `ACTA2-AS1` + \n##     AC036108.3 + AC079313.2 + AC020916.1 + SNHG25 + AL049555.1 + \n##     `MIR1-1HG-AS1` + AC018904.1 + SNHG12 + `SPINT1-AS1` + `KRT7-AS` + \n##     MIR205HG + `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + \n##     AC092718.4 + LINC01133 + AC025575.2 + `MAFG-DT` + CASC9 + \n##     AL390719.2 + AC002398.2 + AC008736.1 + AL161431.1 + `PCCA-DT` + \n##     AC245041.2 + U62317.1 + U62317.2 + `VPS9D1-AS1` + AL023284.4 + \n##     AATBC + LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - AC092718.4      1 786.12\n## - `ACTA2-AS1`     1 786.13\n## - AC018904.1      1 786.14\n## - AL162424.1      1 786.14\n## - AC079313.2      1 786.15\n## - AC020916.1      1 786.16\n## - `VPS9D1-AS1`    1 786.19\n## - `C5orf66-AS1`   1 786.23\n## - MIR200CHG       1 786.23\n## - SNHG12          1 786.32\n## - U62317.2        1 786.32\n## - SNHG25          1 786.34\n## - MIR22HG         1 786.35\n## - MIR205HG        1 786.36\n## - `PPP1R14B-AS1`  1 786.52\n## - AC002398.2      1 786.63\n## - AC005180.1      1 786.64\n## - AC008736.1      1 786.66\n## - AATBC           1 786.70\n## - CASC9           1 786.71\n## - AP003071.4      1 786.75\n## - U62317.1        1 786.77\n## - AL390719.2      1 786.79\n## - LINC00641       1 786.81\n## - AC099850.4      1 786.82\n## - LINC01082       1 786.91\n## - LINC01133       1 787.14\n## - LINC00865       1 787.18\n## - AC036108.3      1 787.19\n## - `KRT7-AS`       1 787.27\n## - `HAND2-AS1`     1 787.29\n## - AC005180.2      1 787.37\n## - AC053503.3      1 787.38\n## - `MIR1-1HG-AS1`  1 787.43\n## - AL445524.1      1 787.51\n## - AC025575.2      1 787.52\n## - AF001548.1      1 787.59\n## - `MBNL1-AS1`     1 787.72\n## - AC245041.2      1 787.74\n## - FENDRR          1 787.80\n## - AP001107.5      1 787.91\n## - LINC01980       1 787.95\n## - AL023284.4      1 788.01\n## &lt;none&gt;              788.12\n## - AL161431.1      1 788.12\n## - `MAFG-DT`       1 788.20\n## - LINC02657       1 788.22\n## - AC012085.2      1 788.29\n## - PCAT6           1 789.28\n## - `PCCA-DT`       1 789.47\n## - `SPINT1-AS1`    1 789.52\n## - AL049555.1      1 789.89\n## - AC015912.3      1 789.99\n## - AC093010.3      1 790.06\n## + `ADAMTS9-AS1`   1 790.12\n## + `PGM5-AS1`      1 790.12\n## + AC008735.2      1 790.12\n## - `ZNF710-AS1`    1 790.96\n## - MIR100HG        1 791.22\n## - NR4A1AS         1 792.73\n## \n## Step:  AIC=786.12\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + `C5orf66-AS1` + \n##     NR4A1AS + AL162424.1 + AF001548.1 + AC099850.4 + `MBNL1-AS1` + \n##     MIR22HG + MIR200CHG + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + `ACTA2-AS1` + \n##     AC036108.3 + AC079313.2 + AC020916.1 + SNHG25 + AL049555.1 + \n##     `MIR1-1HG-AS1` + AC018904.1 + SNHG12 + `SPINT1-AS1` + `KRT7-AS` + \n##     MIR205HG + `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + \n##     LINC01133 + AC025575.2 + `MAFG-DT` + CASC9 + AL390719.2 + \n##     AC002398.2 + AC008736.1 + AL161431.1 + `PCCA-DT` + AC245041.2 + \n##     U62317.1 + U62317.2 + `VPS9D1-AS1` + AL023284.4 + AATBC + \n##     LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - `ACTA2-AS1`     1 784.13\n## - AC018904.1      1 784.14\n## - AL162424.1      1 784.15\n## - AC079313.2      1 784.15\n## - AC020916.1      1 784.16\n## - `VPS9D1-AS1`    1 784.19\n## - `C5orf66-AS1`   1 784.23\n## - MIR200CHG       1 784.25\n## - SNHG12          1 784.32\n## - U62317.2        1 784.33\n## - SNHG25          1 784.35\n## - MIR22HG         1 784.35\n## - MIR205HG        1 784.36\n## - `PPP1R14B-AS1`  1 784.54\n## - AC002398.2      1 784.63\n## - AC005180.1      1 784.65\n## - AC008736.1      1 784.66\n## - AATBC           1 784.70\n## - CASC9           1 784.74\n## - AP003071.4      1 784.75\n## - AL390719.2      1 784.79\n## - U62317.1        1 784.79\n## - LINC00641       1 784.81\n## - AC099850.4      1 784.86\n## - LINC01082       1 784.91\n## - LINC01133       1 785.14\n## - LINC00865       1 785.20\n## - AC036108.3      1 785.21\n## - `KRT7-AS`       1 785.28\n## - `HAND2-AS1`     1 785.29\n## - AC053503.3      1 785.40\n## - AC005180.2      1 785.42\n## - `MIR1-1HG-AS1`  1 785.50\n## - AL445524.1      1 785.51\n## - AC025575.2      1 785.56\n## - AF001548.1      1 785.59\n## - `MBNL1-AS1`     1 785.72\n## - AC245041.2      1 785.77\n## - FENDRR          1 785.84\n## - AP001107.5      1 785.93\n## - LINC01980       1 785.95\n## &lt;none&gt;              786.12\n## - AL161431.1      1 786.13\n## - AL023284.4      1 786.17\n## - `MAFG-DT`       1 786.20\n## - LINC02657       1 786.22\n## - AC012085.2      1 786.30\n## - PCAT6           1 787.28\n## - `PCCA-DT`       1 787.48\n## - `SPINT1-AS1`    1 787.70\n## - AL049555.1      1 787.89\n## - AC015912.3      1 788.00\n## - AC093010.3      1 788.06\n## + AC092718.4      1 788.12\n## + `ADAMTS9-AS1`   1 788.12\n## + `PGM5-AS1`      1 788.12\n## + AC008735.2      1 788.12\n## - `ZNF710-AS1`    1 788.96\n## - MIR100HG        1 789.24\n## - NR4A1AS         1 790.86\n## \n## Step:  AIC=784.13\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + `C5orf66-AS1` + \n##     NR4A1AS + AL162424.1 + AF001548.1 + AC099850.4 + `MBNL1-AS1` + \n##     MIR22HG + MIR200CHG + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + \n##     AC079313.2 + AC020916.1 + SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + \n##     AC018904.1 + SNHG12 + `SPINT1-AS1` + `KRT7-AS` + MIR205HG + \n##     `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + LINC01133 + \n##     AC025575.2 + `MAFG-DT` + CASC9 + AL390719.2 + AC002398.2 + \n##     AC008736.1 + AL161431.1 + `PCCA-DT` + AC245041.2 + U62317.1 + \n##     U62317.2 + `VPS9D1-AS1` + AL023284.4 + AATBC + LINC00641 + \n##     AC015912.3\n## \n##                  Df    AIC\n## - AC018904.1      1 782.15\n## - AL162424.1      1 782.16\n## - AC079313.2      1 782.16\n## - AC020916.1      1 782.17\n## - `VPS9D1-AS1`    1 782.21\n## - `C5orf66-AS1`   1 782.24\n## - MIR200CHG       1 782.25\n## - SNHG12          1 782.33\n## - U62317.2        1 782.33\n## - MIR22HG         1 782.35\n## - SNHG25          1 782.36\n## - MIR205HG        1 782.38\n## - `PPP1R14B-AS1`  1 782.54\n## - AC002398.2      1 782.66\n## - AC005180.1      1 782.67\n## - AC008736.1      1 782.71\n## - CASC9           1 782.76\n## - U62317.1        1 782.79\n## - AL390719.2      1 782.80\n## - AATBC           1 782.82\n## - LINC00641       1 782.83\n## - AC099850.4      1 782.89\n## - AP003071.4      1 782.96\n## - LINC01082       1 783.00\n## - LINC01133       1 783.20\n## - AC036108.3      1 783.22\n## - LINC00865       1 783.22\n## - `KRT7-AS`       1 783.33\n## - `HAND2-AS1`     1 783.38\n## - AC005180.2      1 783.43\n## - AL445524.1      1 783.51\n## - `MIR1-1HG-AS1`  1 783.53\n## - AC025575.2      1 783.57\n## - AC053503.3      1 783.60\n## - AF001548.1      1 783.72\n## - `MBNL1-AS1`     1 783.72\n## - FENDRR          1 783.90\n## - AC245041.2      1 783.94\n## - LINC01980       1 783.96\n## - AP001107.5      1 783.96\n## &lt;none&gt;              784.13\n## - AL161431.1      1 784.16\n## - `MAFG-DT`       1 784.20\n## - AL023284.4      1 784.24\n## - LINC02657       1 784.27\n## - AC012085.2      1 784.32\n## - PCAT6           1 785.39\n## - `PCCA-DT`       1 785.49\n## - `SPINT1-AS1`    1 785.73\n## - AL049555.1      1 785.93\n## - AC015912.3      1 786.07\n## - AC093010.3      1 786.10\n## + `ACTA2-AS1`     1 786.12\n## + AC092718.4      1 786.13\n## + `PGM5-AS1`      1 786.13\n## + `ADAMTS9-AS1`   1 786.13\n## + AC008735.2      1 786.13\n## - `ZNF710-AS1`    1 786.97\n## - MIR100HG        1 787.30\n## - NR4A1AS         1 789.00\n## \n## Step:  AIC=782.15\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + `C5orf66-AS1` + \n##     NR4A1AS + AL162424.1 + AF001548.1 + AC099850.4 + `MBNL1-AS1` + \n##     MIR22HG + MIR200CHG + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + \n##     AC079313.2 + AC020916.1 + SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + \n##     SNHG12 + `SPINT1-AS1` + `KRT7-AS` + MIR205HG + `HAND2-AS1` + \n##     AL445524.1 + LINC01980 + `ZNF710-AS1` + LINC01133 + AC025575.2 + \n##     `MAFG-DT` + CASC9 + AL390719.2 + AC002398.2 + AC008736.1 + \n##     AL161431.1 + `PCCA-DT` + AC245041.2 + U62317.1 + U62317.2 + \n##     `VPS9D1-AS1` + AL023284.4 + AATBC + LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - AC079313.2      1 780.17\n## - AL162424.1      1 780.17\n## - AC020916.1      1 780.18\n## - `VPS9D1-AS1`    1 780.23\n## - MIR200CHG       1 780.26\n## - `C5orf66-AS1`   1 780.26\n## - SNHG12          1 780.35\n## - U62317.2        1 780.35\n## - SNHG25          1 780.37\n## - MIR22HG         1 780.37\n## - MIR205HG        1 780.44\n## - `PPP1R14B-AS1`  1 780.57\n## - AC002398.2      1 780.68\n## - AC005180.1      1 780.71\n## - AC008736.1      1 780.72\n## - CASC9           1 780.78\n## - AL390719.2      1 780.81\n## - U62317.1        1 780.82\n## - AATBC           1 780.83\n## - LINC00641       1 780.86\n## - AC099850.4      1 780.89\n## - AP003071.4      1 780.96\n## - LINC01082       1 781.04\n## - LINC01133       1 781.20\n## - LINC00865       1 781.22\n## - AC036108.3      1 781.22\n## - `KRT7-AS`       1 781.36\n## - `HAND2-AS1`     1 781.38\n## - AC005180.2      1 781.44\n## - AL445524.1      1 781.53\n## - `MIR1-1HG-AS1`  1 781.56\n## - AC053503.3      1 781.60\n## - AC025575.2      1 781.69\n## - `MBNL1-AS1`     1 781.73\n## - AF001548.1      1 781.73\n## - FENDRR          1 781.91\n## - LINC01980       1 781.98\n## - AP001107.5      1 781.98\n## - AC245041.2      1 781.99\n## &lt;none&gt;              782.15\n## - AL161431.1      1 782.18\n## - `MAFG-DT`       1 782.21\n## - LINC02657       1 782.28\n## - AC012085.2      1 782.33\n## - AL023284.4      1 782.38\n## - PCAT6           1 783.40\n## - `PCCA-DT`       1 783.56\n## - `SPINT1-AS1`    1 783.79\n## - AL049555.1      1 784.05\n## + AC018904.1      1 784.13\n## + `ACTA2-AS1`     1 784.14\n## + `PGM5-AS1`      1 784.15\n## + `ADAMTS9-AS1`   1 784.15\n## + AC092718.4      1 784.15\n## + AC008735.2      1 784.15\n## - AC093010.3      1 784.16\n## - AC015912.3      1 784.16\n## - `ZNF710-AS1`    1 785.01\n## - MIR100HG        1 785.30\n## - NR4A1AS         1 787.05\n## \n## Step:  AIC=780.17\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + `C5orf66-AS1` + \n##     NR4A1AS + AL162424.1 + AF001548.1 + AC099850.4 + `MBNL1-AS1` + \n##     MIR22HG + MIR200CHG + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + \n##     AC020916.1 + SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + SNHG12 + \n##     `SPINT1-AS1` + `KRT7-AS` + MIR205HG + `HAND2-AS1` + AL445524.1 + \n##     LINC01980 + `ZNF710-AS1` + LINC01133 + AC025575.2 + `MAFG-DT` + \n##     CASC9 + AL390719.2 + AC002398.2 + AC008736.1 + AL161431.1 + \n##     `PCCA-DT` + AC245041.2 + U62317.1 + U62317.2 + `VPS9D1-AS1` + \n##     AL023284.4 + AATBC + LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - AL162424.1      1 778.20\n## - AC020916.1      1 778.20\n## - `VPS9D1-AS1`    1 778.24\n## - `C5orf66-AS1`   1 778.29\n## - MIR200CHG       1 778.30\n## - U62317.2        1 778.37\n## - SNHG12          1 778.39\n## - SNHG25          1 778.39\n## - MIR22HG         1 778.40\n## - MIR205HG        1 778.45\n## - `PPP1R14B-AS1`  1 778.61\n## - AC002398.2      1 778.68\n## - AC008736.1      1 778.72\n## - CASC9           1 778.80\n## - AL390719.2      1 778.83\n## - AATBC           1 778.83\n## - U62317.1        1 778.84\n## - AC099850.4      1 778.91\n## - AC005180.1      1 778.92\n## - LINC00641       1 778.92\n## - AP003071.4      1 779.01\n## - LINC01082       1 779.05\n## - AC036108.3      1 779.23\n## - LINC00865       1 779.24\n## - LINC01133       1 779.24\n## - `KRT7-AS`       1 779.38\n## - AC005180.2      1 779.47\n## - AL445524.1      1 779.53\n## - `MIR1-1HG-AS1`  1 779.58\n## - AC053503.3      1 779.60\n## - AC025575.2      1 779.69\n## - `HAND2-AS1`     1 779.72\n## - `MBNL1-AS1`     1 779.74\n## - AF001548.1      1 779.74\n## - FENDRR          1 779.95\n## - LINC01980       1 779.99\n## - AP001107.5      1 780.01\n## - AC245041.2      1 780.02\n## &lt;none&gt;              780.17\n## - AL161431.1      1 780.21\n## - `MAFG-DT`       1 780.21\n## - LINC02657       1 780.28\n## - AL023284.4      1 780.39\n## - AC012085.2      1 780.46\n## - PCAT6           1 781.40\n## - `PCCA-DT`       1 781.60\n## - `SPINT1-AS1`    1 781.81\n## - AL049555.1      1 782.06\n## + AC079313.2      1 782.15\n## + `ACTA2-AS1`     1 782.16\n## - AC093010.3      1 782.16\n## + AC018904.1      1 782.16\n## + AC092718.4      1 782.17\n## + AC008735.2      1 782.17\n## + `PGM5-AS1`      1 782.17\n## + `ADAMTS9-AS1`   1 782.17\n## - AC015912.3      1 782.18\n## - `ZNF710-AS1`    1 783.08\n## - MIR100HG        1 783.31\n## - NR4A1AS         1 785.07\n## \n## Step:  AIC=778.2\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + `C5orf66-AS1` + \n##     NR4A1AS + AF001548.1 + AC099850.4 + `MBNL1-AS1` + MIR22HG + \n##     MIR200CHG + AC093010.3 + LINC00865 + AP003071.4 + PCAT6 + \n##     LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + AC020916.1 + \n##     SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + SNHG12 + `SPINT1-AS1` + \n##     `KRT7-AS` + MIR205HG + `HAND2-AS1` + AL445524.1 + LINC01980 + \n##     `ZNF710-AS1` + LINC01133 + AC025575.2 + `MAFG-DT` + CASC9 + \n##     AL390719.2 + AC002398.2 + AC008736.1 + AL161431.1 + `PCCA-DT` + \n##     AC245041.2 + U62317.1 + U62317.2 + `VPS9D1-AS1` + AL023284.4 + \n##     AATBC + LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - AC020916.1      1 776.23\n## - `VPS9D1-AS1`    1 776.28\n## - `C5orf66-AS1`   1 776.33\n## - MIR200CHG       1 776.35\n## - SNHG12          1 776.41\n## - MIR22HG         1 776.42\n## - U62317.2        1 776.42\n## - SNHG25          1 776.43\n## - MIR205HG        1 776.46\n## - `PPP1R14B-AS1`  1 776.63\n## - AC002398.2      1 776.69\n## - AC008736.1      1 776.79\n## - U62317.1        1 776.84\n## - AL390719.2      1 776.85\n## - CASC9           1 776.89\n## - AC099850.4      1 776.93\n## - AC005180.1      1 776.93\n## - LINC00641       1 776.94\n## - AATBC           1 776.95\n## - AP003071.4      1 777.03\n## - LINC01082       1 777.08\n## - LINC00865       1 777.29\n## - LINC01133       1 777.30\n## - AC036108.3      1 777.31\n## - `KRT7-AS`       1 777.47\n## - AC005180.2      1 777.51\n## - AL445524.1      1 777.53\n## - AC053503.3      1 777.61\n## - `MIR1-1HG-AS1`  1 777.63\n## - AC025575.2      1 777.69\n## - `HAND2-AS1`     1 777.74\n## - AF001548.1      1 777.77\n## - `MBNL1-AS1`     1 777.78\n## - FENDRR          1 777.99\n## - LINC01980       1 778.00\n## - AP001107.5      1 778.03\n## - AC245041.2      1 778.05\n## &lt;none&gt;              778.20\n## - `MAFG-DT`       1 778.25\n## - AL161431.1      1 778.35\n## - LINC02657       1 778.37\n## - AL023284.4      1 778.40\n## - AC012085.2      1 778.49\n## - PCAT6           1 779.41\n## - `PCCA-DT`       1 779.60\n## - `SPINT1-AS1`    1 779.82\n## - AL049555.1      1 780.06\n## + AL162424.1      1 780.17\n## + AC079313.2      1 780.17\n## - AC015912.3      1 780.18\n## + `ACTA2-AS1`     1 780.19\n## + AC018904.1      1 780.19\n## + AC092718.4      1 780.20\n## + AC008735.2      1 780.20\n## + `ADAMTS9-AS1`   1 780.20\n## + `PGM5-AS1`      1 780.20\n## - AC093010.3      1 780.43\n## - `ZNF710-AS1`    1 781.08\n## - MIR100HG        1 781.40\n## - NR4A1AS         1 783.46\n## \n## Step:  AIC=776.23\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + `C5orf66-AS1` + \n##     NR4A1AS + AF001548.1 + AC099850.4 + `MBNL1-AS1` + MIR22HG + \n##     MIR200CHG + AC093010.3 + LINC00865 + AP003071.4 + PCAT6 + \n##     LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + SNHG25 + \n##     AL049555.1 + `MIR1-1HG-AS1` + SNHG12 + `SPINT1-AS1` + `KRT7-AS` + \n##     MIR205HG + `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + \n##     LINC01133 + AC025575.2 + `MAFG-DT` + CASC9 + AL390719.2 + \n##     AC002398.2 + AC008736.1 + AL161431.1 + `PCCA-DT` + AC245041.2 + \n##     U62317.1 + U62317.2 + `VPS9D1-AS1` + AL023284.4 + AATBC + \n##     LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - `VPS9D1-AS1`    1 774.30\n## - `C5orf66-AS1`   1 774.35\n## - MIR200CHG       1 774.40\n## - U62317.2        1 774.44\n## - SNHG25          1 774.45\n## - MIR205HG        1 774.46\n## - SNHG12          1 774.46\n## - MIR22HG         1 774.49\n## - `PPP1R14B-AS1`  1 774.67\n## - AC002398.2      1 774.72\n## - U62317.1        1 774.85\n## - AL390719.2      1 774.86\n## - AC008736.1      1 774.87\n## - CASC9           1 774.90\n## - AC005180.1      1 774.93\n## - AC099850.4      1 774.93\n## - LINC00641       1 774.97\n## - AATBC           1 775.02\n## - AP003071.4      1 775.09\n## - LINC01082       1 775.11\n## - LINC00865       1 775.30\n## - AC036108.3      1 775.33\n## - LINC01133       1 775.38\n## - `KRT7-AS`       1 775.51\n## - AC005180.2      1 775.56\n## - AL445524.1      1 775.57\n## - AC053503.3      1 775.61\n## - `MIR1-1HG-AS1`  1 775.63\n## - AC025575.2      1 775.71\n## - `HAND2-AS1`     1 775.75\n## - AF001548.1      1 775.80\n## - `MBNL1-AS1`     1 775.80\n## - FENDRR          1 776.00\n## - AP001107.5      1 776.03\n## - AC245041.2      1 776.05\n## - LINC01980       1 776.09\n## &lt;none&gt;              776.23\n## - `MAFG-DT`       1 776.25\n## - LINC02657       1 776.37\n## - AL023284.4      1 776.40\n## - AL161431.1      1 776.50\n## - AC012085.2      1 776.53\n## - PCAT6           1 777.44\n## - `PCCA-DT`       1 777.60\n## - `SPINT1-AS1`    1 777.85\n## - AL049555.1      1 778.06\n## - AC015912.3      1 778.18\n## + AC020916.1      1 778.20\n## + AL162424.1      1 778.20\n## + AC079313.2      1 778.20\n## + `ACTA2-AS1`     1 778.21\n## + AC018904.1      1 778.22\n## + AC008735.2      1 778.22\n## + AC092718.4      1 778.22\n## + `ADAMTS9-AS1`   1 778.22\n## + `PGM5-AS1`      1 778.23\n## - AC093010.3      1 778.43\n## - `ZNF710-AS1`    1 779.19\n## - MIR100HG        1 779.58\n## - NR4A1AS         1 782.52\n## \n## Step:  AIC=774.3\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + `C5orf66-AS1` + \n##     NR4A1AS + AF001548.1 + AC099850.4 + `MBNL1-AS1` + MIR22HG + \n##     MIR200CHG + AC093010.3 + LINC00865 + AP003071.4 + PCAT6 + \n##     LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + SNHG25 + \n##     AL049555.1 + `MIR1-1HG-AS1` + SNHG12 + `SPINT1-AS1` + `KRT7-AS` + \n##     MIR205HG + `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + \n##     LINC01133 + AC025575.2 + `MAFG-DT` + CASC9 + AL390719.2 + \n##     AC002398.2 + AC008736.1 + AL161431.1 + `PCCA-DT` + AC245041.2 + \n##     U62317.1 + U62317.2 + AL023284.4 + AATBC + LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - `C5orf66-AS1`   1 772.43\n## - MIR200CHG       1 772.46\n## - SNHG12          1 772.51\n## - MIR205HG        1 772.55\n## - MIR22HG         1 772.56\n## - SNHG25          1 772.57\n## - U62317.2        1 772.57\n## - `PPP1R14B-AS1`  1 772.69\n## - AC002398.2      1 772.76\n## - U62317.1        1 772.87\n## - AC008736.1      1 772.88\n## - AL390719.2      1 772.89\n## - CASC9           1 772.96\n## - LINC00641       1 773.00\n## - AC005180.1      1 773.01\n## - AC099850.4      1 773.03\n## - AP003071.4      1 773.13\n## - AATBC           1 773.17\n## - LINC01082       1 773.22\n## - AC036108.3      1 773.45\n## - LINC00865       1 773.47\n## - LINC01133       1 773.49\n## - `KRT7-AS`       1 773.53\n## - AL445524.1      1 773.58\n## - AC005180.2      1 773.62\n## - AC053503.3      1 773.65\n## - AC025575.2      1 773.77\n## - AF001548.1      1 773.82\n## - `MIR1-1HG-AS1`  1 773.83\n## - `MBNL1-AS1`     1 773.92\n## - `HAND2-AS1`     1 773.93\n## - AP001107.5      1 774.09\n## - AC245041.2      1 774.17\n## - `MAFG-DT`       1 774.26\n## - LINC01980       1 774.27\n## - FENDRR          1 774.29\n## &lt;none&gt;              774.30\n## - LINC02657       1 774.38\n## - AL023284.4      1 774.40\n## - AC012085.2      1 774.62\n## - AL161431.1      1 774.65\n## - PCAT6           1 775.49\n## - `PCCA-DT`       1 775.66\n## - AL049555.1      1 776.12\n## - `SPINT1-AS1`    1 776.16\n## - AC015912.3      1 776.21\n## + `VPS9D1-AS1`    1 776.23\n## + AL162424.1      1 776.27\n## + `ACTA2-AS1`     1 776.28\n## + AC020916.1      1 776.28\n## + AC079313.2      1 776.28\n## + AC018904.1      1 776.29\n## + `ADAMTS9-AS1`   1 776.30\n## + `PGM5-AS1`      1 776.30\n## + AC008735.2      1 776.30\n## + AC092718.4      1 776.30\n## - AC093010.3      1 776.45\n## - `ZNF710-AS1`    1 777.21\n## - MIR100HG        1 777.77\n## - NR4A1AS         1 780.57\n## \n## Step:  AIC=772.43\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + \n##     AC099850.4 + `MBNL1-AS1` + MIR22HG + MIR200CHG + AC093010.3 + \n##     LINC00865 + AP003071.4 + PCAT6 + LINC02657 + `PPP1R14B-AS1` + \n##     AC012085.2 + AC036108.3 + SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + \n##     SNHG12 + `SPINT1-AS1` + `KRT7-AS` + MIR205HG + `HAND2-AS1` + \n##     AL445524.1 + LINC01980 + `ZNF710-AS1` + LINC01133 + AC025575.2 + \n##     `MAFG-DT` + CASC9 + AL390719.2 + AC002398.2 + AC008736.1 + \n##     AL161431.1 + `PCCA-DT` + AC245041.2 + U62317.1 + U62317.2 + \n##     AL023284.4 + AATBC + LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - MIR200CHG       1 770.61\n## - MIR205HG        1 770.63\n## - SNHG25          1 770.64\n## - SNHG12          1 770.67\n## - MIR22HG         1 770.68\n## - U62317.2        1 770.71\n## - `PPP1R14B-AS1`  1 770.84\n## - AC002398.2      1 770.85\n## - U62317.1        1 771.01\n## - AC008736.1      1 771.05\n## - LINC00641       1 771.06\n## - AC005180.1      1 771.08\n## - AL390719.2      1 771.12\n## - CASC9           1 771.13\n## - AC099850.4      1 771.18\n## - AP003071.4      1 771.28\n## - LINC01082       1 771.47\n## - AATBC           1 771.49\n## - LINC00865       1 771.60\n## - AC036108.3      1 771.61\n## - AC053503.3      1 771.86\n## - `KRT7-AS`       1 771.87\n## - AL445524.1      1 771.89\n## - AC025575.2      1 771.90\n## - `MIR1-1HG-AS1`  1 771.92\n## - LINC01133       1 771.92\n## - AC005180.2      1 771.93\n## - `MBNL1-AS1`     1 772.03\n## - `HAND2-AS1`     1 772.09\n## - AP001107.5      1 772.17\n## - AF001548.1      1 772.25\n## - AC245041.2      1 772.26\n## - FENDRR          1 772.42\n## - LINC02657       1 772.42\n## &lt;none&gt;              772.43\n## - `MAFG-DT`       1 772.45\n## - LINC01980       1 772.49\n## - AL023284.4      1 772.71\n## - AC012085.2      1 772.90\n## - AL161431.1      1 773.04\n## - PCAT6           1 773.69\n## - `PCCA-DT`       1 773.93\n## - AL049555.1      1 774.16\n## + `C5orf66-AS1`   1 774.30\n## + `VPS9D1-AS1`    1 774.35\n## - `SPINT1-AS1`    1 774.37\n## + AL162424.1      1 774.38\n## + AC079313.2      1 774.41\n## + `ACTA2-AS1`     1 774.41\n## + AC018904.1      1 774.41\n## + AC020916.1      1 774.41\n## + AC008735.2      1 774.42\n## + `PGM5-AS1`      1 774.43\n## + `ADAMTS9-AS1`   1 774.43\n## + AC092718.4      1 774.43\n## - AC015912.3      1 774.55\n## - AC093010.3      1 774.57\n## - `ZNF710-AS1`    1 775.45\n## - MIR100HG        1 775.83\n## - NR4A1AS         1 778.68\n## \n## Step:  AIC=770.61\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + \n##     AC099850.4 + `MBNL1-AS1` + MIR22HG + AC093010.3 + LINC00865 + \n##     AP003071.4 + PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + \n##     AC036108.3 + SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + SNHG12 + \n##     `SPINT1-AS1` + `KRT7-AS` + MIR205HG + `HAND2-AS1` + AL445524.1 + \n##     LINC01980 + `ZNF710-AS1` + LINC01133 + AC025575.2 + `MAFG-DT` + \n##     CASC9 + AL390719.2 + AC002398.2 + AC008736.1 + AL161431.1 + \n##     `PCCA-DT` + AC245041.2 + U62317.1 + U62317.2 + AL023284.4 + \n##     AATBC + LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - U62317.2        1 768.79\n## - MIR22HG         1 768.80\n## - SNHG12          1 768.84\n## - SNHG25          1 768.87\n## - MIR205HG        1 768.91\n## - AC002398.2      1 769.07\n## - `PPP1R14B-AS1`  1 769.07\n## - AC008736.1      1 769.21\n## - LINC00641       1 769.21\n## - AL390719.2      1 769.24\n## - AC005180.1      1 769.25\n## - CASC9           1 769.31\n## - AP003071.4      1 769.41\n## - U62317.1        1 769.43\n## - AC099850.4      1 769.47\n## - AATBC           1 769.62\n## - LINC01082       1 769.68\n## - LINC00865       1 769.75\n## - AC036108.3      1 769.84\n## - AL445524.1      1 769.96\n## - LINC01133       1 769.99\n## - `KRT7-AS`       1 770.00\n## - AC005180.2      1 770.08\n## - AC053503.3      1 770.11\n## - `MIR1-1HG-AS1`  1 770.13\n## - AC025575.2      1 770.16\n## - `MBNL1-AS1`     1 770.27\n## - AP001107.5      1 770.29\n## - `HAND2-AS1`     1 770.29\n## - AF001548.1      1 770.53\n## - `MAFG-DT`       1 770.57\n## - FENDRR          1 770.60\n## &lt;none&gt;              770.61\n## - AC245041.2      1 770.68\n## - LINC01980       1 770.79\n## - LINC02657       1 770.81\n## - AL023284.4      1 771.08\n## - AC012085.2      1 771.12\n## - AL161431.1      1 771.16\n## - PCAT6           1 771.71\n## - `PCCA-DT`       1 772.16\n## - AL049555.1      1 772.39\n## + MIR200CHG       1 772.43\n## + `C5orf66-AS1`   1 772.46\n## - `SPINT1-AS1`    1 772.51\n## + `VPS9D1-AS1`    1 772.54\n## + AL162424.1      1 772.54\n## + AC020916.1      1 772.57\n## + AC079313.2      1 772.58\n## + AC092718.4      1 772.60\n## + `ACTA2-AS1`     1 772.60\n## + `ADAMTS9-AS1`   1 772.61\n## + AC018904.1      1 772.61\n## + AC008735.2      1 772.61\n## + `PGM5-AS1`      1 772.61\n## - AC093010.3      1 772.74\n## - AC015912.3      1 772.87\n## - `ZNF710-AS1`    1 773.54\n## - MIR100HG        1 774.09\n## - NR4A1AS         1 776.80\n## \n## Step:  AIC=768.79\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + \n##     AC099850.4 + `MBNL1-AS1` + MIR22HG + AC093010.3 + LINC00865 + \n##     AP003071.4 + PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + \n##     AC036108.3 + SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + SNHG12 + \n##     `SPINT1-AS1` + `KRT7-AS` + MIR205HG + `HAND2-AS1` + AL445524.1 + \n##     LINC01980 + `ZNF710-AS1` + LINC01133 + AC025575.2 + `MAFG-DT` + \n##     CASC9 + AL390719.2 + AC002398.2 + AC008736.1 + AL161431.1 + \n##     `PCCA-DT` + AC245041.2 + U62317.1 + AL023284.4 + AATBC + \n##     LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - MIR22HG         1 766.99\n## - SNHG12          1 767.06\n## - MIR205HG        1 767.10\n## - AC002398.2      1 767.17\n## - AC008736.1      1 767.29\n## - SNHG25          1 767.32\n## - LINC00641       1 767.35\n## - `PPP1R14B-AS1`  1 767.36\n## - AL390719.2      1 767.38\n## - AC005180.1      1 767.41\n## - CASC9           1 767.44\n## - AP003071.4      1 767.59\n## - AC099850.4      1 767.65\n## - AATBC           1 767.81\n## - AC036108.3      1 767.90\n## - LINC00865       1 767.95\n## - LINC01082       1 768.11\n## - AC005180.2      1 768.16\n## - AL445524.1      1 768.17\n## - LINC01133       1 768.19\n## - AC053503.3      1 768.19\n## - `KRT7-AS`       1 768.23\n## - AC025575.2      1 768.31\n## - `MBNL1-AS1`     1 768.45\n## - `MIR1-1HG-AS1`  1 768.52\n## - `HAND2-AS1`     1 768.52\n## - AP001107.5      1 768.53\n## - `MAFG-DT`       1 768.71\n## &lt;none&gt;              768.79\n## - FENDRR          1 768.81\n## - U62317.1        1 768.92\n## - AC245041.2      1 768.98\n## - AF001548.1      1 769.03\n## - AC012085.2      1 769.14\n## - LINC02657       1 769.15\n## - AL023284.4      1 769.18\n## - LINC01980       1 769.20\n## - AL161431.1      1 769.47\n## - PCAT6           1 770.07\n## - `PCCA-DT`       1 770.36\n## - AL049555.1      1 770.41\n## + U62317.2        1 770.61\n## + `C5orf66-AS1`   1 770.64\n## + `VPS9D1-AS1`    1 770.66\n## - `SPINT1-AS1`    1 770.67\n## + AL162424.1      1 770.68\n## + MIR200CHG       1 770.71\n## + AC008735.2      1 770.76\n## + AC079313.2      1 770.76\n## + AC020916.1      1 770.77\n## + AC018904.1      1 770.77\n## + `ACTA2-AS1`     1 770.78\n## + `ADAMTS9-AS1`   1 770.78\n## + AC092718.4      1 770.78\n## + `PGM5-AS1`      1 770.79\n## - AC015912.3      1 770.88\n## - AC093010.3      1 771.17\n## - `ZNF710-AS1`    1 771.92\n## - MIR100HG        1 772.23\n## - NR4A1AS         1 774.81\n## \n## Step:  AIC=766.99\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + \n##     AC099850.4 + `MBNL1-AS1` + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + \n##     SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + SNHG12 + `SPINT1-AS1` + \n##     `KRT7-AS` + MIR205HG + `HAND2-AS1` + AL445524.1 + LINC01980 + \n##     `ZNF710-AS1` + LINC01133 + AC025575.2 + `MAFG-DT` + CASC9 + \n##     AL390719.2 + AC002398.2 + AC008736.1 + AL161431.1 + `PCCA-DT` + \n##     AC245041.2 + U62317.1 + AL023284.4 + AATBC + LINC00641 + \n##     AC015912.3\n## \n##                  Df    AIC\n## - SNHG12          1 765.21\n## - MIR205HG        1 765.23\n## - AC002398.2      1 765.31\n## - AC008736.1      1 765.51\n## - `PPP1R14B-AS1`  1 765.56\n## - AC005180.1      1 765.58\n## - LINC00641       1 765.63\n## - CASC9           1 765.67\n## - AL390719.2      1 765.68\n## - SNHG25          1 765.73\n## - AC099850.4      1 765.77\n## - AP003071.4      1 765.86\n## - AATBC           1 766.07\n## - AC036108.3      1 766.12\n## - LINC00865       1 766.20\n## - LINC01082       1 766.22\n## - `KRT7-AS`       1 766.30\n## - LINC01133       1 766.31\n## - AL445524.1      1 766.39\n## - AC053503.3      1 766.42\n## - AC005180.2      1 766.45\n## - AP001107.5      1 766.58\n## - AC025575.2      1 766.59\n## - `HAND2-AS1`     1 766.60\n## - `MBNL1-AS1`     1 766.70\n## - `MIR1-1HG-AS1`  1 766.89\n## - FENDRR          1 766.91\n## - `MAFG-DT`       1 766.92\n## &lt;none&gt;              766.99\n## - U62317.1        1 767.04\n## - AC012085.2      1 767.29\n## - AF001548.1      1 767.31\n## - AC245041.2      1 767.32\n## - AL023284.4      1 767.49\n## - LINC02657       1 767.50\n## - LINC01980       1 767.60\n## - AL161431.1      1 767.71\n## - PCAT6           1 768.11\n## - AL049555.1      1 768.68\n## + MIR22HG         1 768.79\n## + U62317.2        1 768.80\n## + `C5orf66-AS1`   1 768.85\n## + `VPS9D1-AS1`    1 768.86\n## - `PCCA-DT`       1 768.87\n## - `SPINT1-AS1`    1 768.89\n## + AL162424.1      1 768.92\n## + AC020916.1      1 768.95\n## + MIR200CHG       1 768.95\n## - AC015912.3      1 768.95\n## + AC008735.2      1 768.96\n## + AC079313.2      1 768.96\n## + AC018904.1      1 768.97\n## + `ADAMTS9-AS1`   1 768.97\n## + AC092718.4      1 768.99\n## + `PGM5-AS1`      1 768.99\n## + `ACTA2-AS1`     1 768.99\n## - AC093010.3      1 769.32\n## - `ZNF710-AS1`    1 770.25\n## - MIR100HG        1 770.74\n## - NR4A1AS         1 774.02\n## \n## Step:  AIC=765.21\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + \n##     AC099850.4 + `MBNL1-AS1` + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + \n##     SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + `KRT7-AS` + \n##     MIR205HG + `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + \n##     LINC01133 + AC025575.2 + `MAFG-DT` + CASC9 + AL390719.2 + \n##     AC002398.2 + AC008736.1 + AL161431.1 + `PCCA-DT` + AC245041.2 + \n##     U62317.1 + AL023284.4 + AATBC + LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - MIR205HG        1 763.38\n## - AC002398.2      1 763.52\n## - AC008736.1      1 763.73\n## - AC005180.1      1 763.74\n## - `PPP1R14B-AS1`  1 763.76\n## - SNHG25          1 763.77\n## - CASC9           1 763.99\n## - LINC00641       1 764.01\n## - AC099850.4      1 764.10\n## - AL390719.2      1 764.11\n## - AP003071.4      1 764.25\n## - AC036108.3      1 764.29\n## - AATBC           1 764.34\n## - `KRT7-AS`       1 764.35\n## - LINC01082       1 764.48\n## - LINC00865       1 764.49\n## - LINC01133       1 764.55\n## - AL445524.1      1 764.55\n## - AC053503.3      1 764.59\n## - AP001107.5      1 764.72\n## - AC005180.2      1 764.79\n## - `HAND2-AS1`     1 764.84\n## - `MBNL1-AS1`     1 764.99\n## - AC025575.2      1 765.00\n## - `MIR1-1HG-AS1`  1 765.03\n## - U62317.1        1 765.18\n## &lt;none&gt;              765.21\n## - FENDRR          1 765.25\n## - `MAFG-DT`       1 765.45\n## - AC012085.2      1 765.46\n## - AF001548.1      1 765.52\n## - LINC02657       1 765.54\n## - AL023284.4      1 765.57\n## - AC245041.2      1 765.61\n## - AL161431.1      1 765.85\n## - LINC01980       1 765.91\n## - PCAT6           1 766.15\n## - AL049555.1      1 766.82\n## + U62317.2        1 766.99\n## + SNHG12          1 766.99\n## + `C5orf66-AS1`   1 767.04\n## + MIR22HG         1 767.06\n## + `VPS9D1-AS1`    1 767.11\n## + AL162424.1      1 767.14\n## - AC015912.3      1 767.14\n## + AC020916.1      1 767.16\n## + AC079313.2      1 767.17\n## + MIR200CHG       1 767.18\n## + `ADAMTS9-AS1`   1 767.18\n## + AC018904.1      1 767.19\n## + `PGM5-AS1`      1 767.21\n## + AC092718.4      1 767.21\n## + AC008735.2      1 767.21\n## + `ACTA2-AS1`     1 767.21\n## - `SPINT1-AS1`    1 767.34\n## - AC093010.3      1 767.36\n## - `PCCA-DT`       1 767.65\n## - `ZNF710-AS1`    1 768.51\n## - MIR100HG        1 769.31\n## - NR4A1AS         1 772.45\n## \n## Step:  AIC=763.38\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + \n##     AC099850.4 + `MBNL1-AS1` + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + \n##     SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + `KRT7-AS` + \n##     `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + LINC01133 + \n##     AC025575.2 + `MAFG-DT` + CASC9 + AL390719.2 + AC002398.2 + \n##     AC008736.1 + AL161431.1 + `PCCA-DT` + AC245041.2 + U62317.1 + \n##     AL023284.4 + AATBC + LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - AC002398.2      1 761.61\n## - AC008736.1      1 761.87\n## - AC005180.1      1 761.92\n## - SNHG25          1 762.03\n## - `PPP1R14B-AS1`  1 762.04\n## - AL390719.2      1 762.20\n## - CASC9           1 762.22\n## - AC036108.3      1 762.31\n## - LINC00641       1 762.33\n## - `KRT7-AS`       1 762.45\n## - AC099850.4      1 762.50\n## - AP003071.4      1 762.52\n## - AATBC           1 762.53\n## - LINC01082       1 762.59\n## - LINC00865       1 762.74\n## - LINC01133       1 762.77\n## - AL445524.1      1 762.80\n## - AP001107.5      1 762.82\n## - AC005180.2      1 763.01\n## - AC025575.2      1 763.04\n## - AC053503.3      1 763.09\n## - `MIR1-1HG-AS1`  1 763.15\n## - `HAND2-AS1`     1 763.18\n## - `MBNL1-AS1`     1 763.21\n## &lt;none&gt;              763.38\n## - FENDRR          1 763.44\n## - U62317.1        1 763.54\n## - AC012085.2      1 763.56\n## - AC245041.2      1 763.65\n## - AL023284.4      1 763.70\n## - AF001548.1      1 763.81\n## - LINC02657       1 763.97\n## - AL161431.1      1 764.07\n## - LINC01980       1 764.14\n## - `MAFG-DT`       1 764.14\n## - PCAT6           1 764.16\n## - AL049555.1      1 764.97\n## + U62317.2        1 765.15\n## + MIR205HG        1 765.21\n## + SNHG12          1 765.23\n## - AC015912.3      1 765.26\n## + `VPS9D1-AS1`    1 765.27\n## + `C5orf66-AS1`   1 765.27\n## + MIR22HG         1 765.28\n## + MIR200CHG       1 765.31\n## + AC018904.1      1 765.33\n## + AL162424.1      1 765.35\n## + AC079313.2      1 765.36\n## + `ADAMTS9-AS1`   1 765.36\n## + AC020916.1      1 765.37\n## + AC008735.2      1 765.37\n## + `PGM5-AS1`      1 765.37\n## + `ACTA2-AS1`     1 765.38\n## + AC092718.4      1 765.38\n## - AC093010.3      1 765.39\n## - `SPINT1-AS1`    1 765.90\n## - `ZNF710-AS1`    1 767.08\n## - `PCCA-DT`       1 767.12\n## - MIR100HG        1 767.52\n## - NR4A1AS         1 770.81\n## \n## Step:  AIC=761.61\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + \n##     AC099850.4 + `MBNL1-AS1` + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + \n##     SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + `KRT7-AS` + \n##     `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + LINC01133 + \n##     AC025575.2 + `MAFG-DT` + CASC9 + AL390719.2 + AC008736.1 + \n##     AL161431.1 + `PCCA-DT` + AC245041.2 + U62317.1 + AL023284.4 + \n##     AATBC + LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - AC008736.1      1 760.03\n## - `PPP1R14B-AS1`  1 760.16\n## - SNHG25          1 760.29\n## - AC005180.1      1 760.31\n## - AC036108.3      1 760.37\n## - CASC9           1 760.41\n## - LINC00641       1 760.53\n## - `KRT7-AS`       1 760.58\n## - AL390719.2      1 760.66\n## - AATBC           1 760.69\n## - AP003071.4      1 760.79\n## - LINC01082       1 760.80\n## - AC099850.4      1 760.88\n## - LINC00865       1 761.04\n## - AL445524.1      1 761.08\n## - LINC01133       1 761.17\n## - AP001107.5      1 761.18\n## - AC005180.2      1 761.21\n## - AC025575.2      1 761.22\n## - AC053503.3      1 761.54\n## &lt;none&gt;              761.61\n## - U62317.1        1 761.65\n## - `MBNL1-AS1`     1 761.65\n## - `HAND2-AS1`     1 761.73\n## - AL023284.4      1 761.74\n## - FENDRR          1 761.99\n## - AF001548.1      1 762.08\n## - AC012085.2      1 762.17\n## - AC245041.2      1 762.26\n## - `MAFG-DT`       1 762.26\n## - LINC02657       1 762.29\n## - PCAT6           1 762.43\n## - LINC01980       1 762.44\n## - AL161431.1      1 762.46\n## - `MIR1-1HG-AS1`  1 762.53\n## - AL049555.1      1 763.11\n## + AC002398.2      1 763.38\n## + U62317.2        1 763.44\n## + SNHG12          1 763.44\n## + `C5orf66-AS1`   1 763.50\n## + MIR200CHG       1 763.52\n## - AC093010.3      1 763.52\n## + MIR205HG        1 763.52\n## - AC015912.3      1 763.52\n## + MIR22HG         1 763.53\n## + `VPS9D1-AS1`    1 763.54\n## + AC018904.1      1 763.56\n## + AC020916.1      1 763.57\n## + AL162424.1      1 763.58\n## + `PGM5-AS1`      1 763.59\n## + AC092718.4      1 763.60\n## + `ACTA2-AS1`     1 763.60\n## + AC008735.2      1 763.60\n## + AC079313.2      1 763.60\n## + `ADAMTS9-AS1`   1 763.61\n## - `SPINT1-AS1`    1 764.18\n## - `PCCA-DT`       1 765.36\n## - `ZNF710-AS1`    1 765.56\n## - MIR100HG        1 765.71\n## - NR4A1AS         1 769.15\n## \n## Step:  AIC=760.03\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + AC005180.1 + \n##     FENDRR + AC053503.3 + MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + \n##     AC099850.4 + `MBNL1-AS1` + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + \n##     SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + `KRT7-AS` + \n##     `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + LINC01133 + \n##     AC025575.2 + `MAFG-DT` + CASC9 + AL390719.2 + AL161431.1 + \n##     `PCCA-DT` + AC245041.2 + U62317.1 + AL023284.4 + AATBC + \n##     LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - AC005180.1      1 758.61\n## - CASC9           1 758.74\n## - SNHG25          1 758.75\n## - `PPP1R14B-AS1`  1 758.81\n## - LINC00641       1 758.85\n## - AC036108.3      1 758.86\n## - AATBC           1 758.89\n## - `KRT7-AS`       1 759.07\n## - AL390719.2      1 759.10\n## - LINC00865       1 759.25\n## - LINC01082       1 759.39\n## - AL445524.1      1 759.40\n## - AP003071.4      1 759.43\n## - AC025575.2      1 759.49\n## - AC099850.4      1 759.52\n## - AP001107.5      1 759.59\n## - LINC01133       1 759.69\n## - AC053503.3      1 759.76\n## - AC005180.2      1 759.78\n## - AL023284.4      1 759.80\n## - `MBNL1-AS1`     1 759.83\n## - U62317.1        1 759.98\n## &lt;none&gt;              760.03\n## - AF001548.1      1 760.25\n## - `MAFG-DT`       1 760.36\n## - `HAND2-AS1`     1 760.36\n## - FENDRR          1 760.36\n## - LINC02657       1 760.59\n## - AC245041.2      1 760.61\n## - AC012085.2      1 760.64\n## - PCAT6           1 760.76\n## - `MIR1-1HG-AS1`  1 761.03\n## - LINC01980       1 761.07\n## - AL161431.1      1 761.23\n## - AL049555.1      1 761.34\n## + AC008736.1      1 761.61\n## - AC015912.3      1 761.72\n## - AC093010.3      1 761.76\n## + SNHG12          1 761.87\n## + AC002398.2      1 761.87\n## + `C5orf66-AS1`   1 761.90\n## + MIR200CHG       1 761.94\n## + U62317.2        1 761.95\n## + AC020916.1      1 761.95\n## + MIR22HG         1 761.95\n## + MIR205HG        1 761.96\n## + AL162424.1      1 761.99\n## + `PGM5-AS1`      1 762.00\n## + `ACTA2-AS1`     1 762.01\n## + AC018904.1      1 762.01\n## + `VPS9D1-AS1`    1 762.02\n## + `ADAMTS9-AS1`   1 762.03\n## + AC008735.2      1 762.03\n## + AC092718.4      1 762.03\n## + AC079313.2      1 762.03\n## - `SPINT1-AS1`    1 762.21\n## - `PCCA-DT`       1 763.61\n## - `ZNF710-AS1`    1 763.75\n## - MIR100HG        1 763.83\n## - NR4A1AS         1 767.15\n## \n## Step:  AIC=758.61\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + FENDRR + \n##     AC053503.3 + MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + \n##     AC099850.4 + `MBNL1-AS1` + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + \n##     SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + `KRT7-AS` + \n##     `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + LINC01133 + \n##     AC025575.2 + `MAFG-DT` + CASC9 + AL390719.2 + AL161431.1 + \n##     `PCCA-DT` + AC245041.2 + U62317.1 + AL023284.4 + AATBC + \n##     LINC00641 + AC015912.3\n## \n##                  Df    AIC\n## - CASC9           1 757.18\n## - LINC00641       1 757.26\n## - SNHG25          1 757.36\n## - AATBC           1 757.43\n## - `PPP1R14B-AS1`  1 757.55\n## - AC036108.3      1 757.56\n## - AL390719.2      1 757.60\n## - `KRT7-AS`       1 757.69\n## - LINC01082       1 757.78\n## - LINC00865       1 757.79\n## - AC053503.3      1 757.89\n## - AC099850.4      1 757.97\n## - AC025575.2      1 758.06\n## - AP001107.5      1 758.08\n## - LINC01133       1 758.12\n## - AP003071.4      1 758.24\n## - `MBNL1-AS1`     1 758.27\n## - AL445524.1      1 758.51\n## - AL023284.4      1 758.55\n## &lt;none&gt;              758.61\n## - `HAND2-AS1`     1 758.66\n## - FENDRR          1 758.67\n## - AC012085.2      1 758.70\n## - U62317.1        1 758.75\n## - AC245041.2      1 758.91\n## - `MAFG-DT`       1 758.93\n## - AF001548.1      1 759.32\n## - PCAT6           1 759.49\n## - `MIR1-1HG-AS1`  1 759.65\n## - AL049555.1      1 759.67\n## - LINC02657       1 759.70\n## - AL161431.1      1 759.71\n## + AC005180.1      1 760.03\n## - LINC01980       1 760.07\n## - AC015912.3      1 760.20\n## + AC002398.2      1 760.30\n## + AC008736.1      1 760.31\n## - `SPINT1-AS1`    1 760.50\n## + SNHG12          1 760.51\n## + MIR200CHG       1 760.51\n## + U62317.2        1 760.53\n## + MIR205HG        1 760.54\n## + MIR22HG         1 760.55\n## + AC079313.2      1 760.55\n## + `C5orf66-AS1`   1 760.55\n## + `ACTA2-AS1`     1 760.55\n## + AC018904.1      1 760.58\n## + AC092718.4      1 760.58\n## + AL162424.1      1 760.58\n## + AC020916.1      1 760.59\n## + `VPS9D1-AS1`    1 760.59\n## + `ADAMTS9-AS1`   1 760.59\n## + AC008735.2      1 760.60\n## + `PGM5-AS1`      1 760.60\n## - AC093010.3      1 760.81\n## - `PCCA-DT`       1 762.04\n## - MIR100HG        1 762.30\n## - `ZNF710-AS1`    1 762.34\n## - NR4A1AS         1 765.30\n## - AC005180.2      1 766.41\n## \n## Step:  AIC=757.18\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + FENDRR + \n##     AC053503.3 + MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + \n##     AC099850.4 + `MBNL1-AS1` + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + \n##     SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + `KRT7-AS` + \n##     `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + LINC01133 + \n##     AC025575.2 + `MAFG-DT` + AL390719.2 + AL161431.1 + `PCCA-DT` + \n##     AC245041.2 + U62317.1 + AL023284.4 + AATBC + LINC00641 + \n##     AC015912.3\n## \n##                  Df    AIC\n## - LINC00641       1 755.83\n## - AC036108.3      1 755.93\n## - AATBC           1 755.97\n## - SNHG25          1 756.00\n## - `PPP1R14B-AS1`  1 756.05\n## - AL390719.2      1 756.12\n## - `KRT7-AS`       1 756.13\n## - LINC01082       1 756.23\n## - AC025575.2      1 756.25\n## - AP001107.5      1 756.45\n## - LINC00865       1 756.50\n## - LINC01133       1 756.51\n## - AC053503.3      1 756.65\n## - AC099850.4      1 756.72\n## - AP003071.4      1 756.80\n## - AC012085.2      1 756.88\n## - `MBNL1-AS1`     1 756.89\n## - AL023284.4      1 756.98\n## - AL445524.1      1 757.01\n## - FENDRR          1 757.09\n## &lt;none&gt;              757.18\n## - `MAFG-DT`       1 757.41\n## - U62317.1        1 757.49\n## - `HAND2-AS1`     1 757.64\n## - AF001548.1      1 757.91\n## - AC245041.2      1 758.07\n## - AL049555.1      1 758.12\n## - PCAT6           1 758.14\n## - LINC02657       1 758.20\n## - AL161431.1      1 758.21\n## - `MIR1-1HG-AS1`  1 758.31\n## - AC015912.3      1 758.36\n## + CASC9           1 758.61\n## + AC005180.1      1 758.74\n## + AC002398.2      1 758.91\n## + AC008736.1      1 758.94\n## + SNHG12          1 759.02\n## - `SPINT1-AS1`    1 759.07\n## + MIR200CHG       1 759.07\n## + MIR205HG        1 759.08\n## + `C5orf66-AS1`   1 759.09\n## + MIR22HG         1 759.10\n## + U62317.2        1 759.11\n## + AL162424.1      1 759.12\n## + AC018904.1      1 759.13\n## + AC079313.2      1 759.13\n## + `ACTA2-AS1`     1 759.13\n## + `VPS9D1-AS1`    1 759.16\n## + `ADAMTS9-AS1`   1 759.17\n## + AC020916.1      1 759.17\n## + `PGM5-AS1`      1 759.17\n## + AC008735.2      1 759.18\n## + AC092718.4      1 759.18\n## - AC093010.3      1 759.48\n## - `PCCA-DT`       1 760.29\n## - LINC01980       1 760.93\n## - MIR100HG        1 761.11\n## - `ZNF710-AS1`    1 761.23\n## - NR4A1AS         1 763.49\n## - AC005180.2      1 764.84\n## \n## Step:  AIC=755.83\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + FENDRR + \n##     AC053503.3 + MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + \n##     AC099850.4 + `MBNL1-AS1` + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + \n##     SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + `KRT7-AS` + \n##     `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + LINC01133 + \n##     AC025575.2 + `MAFG-DT` + AL390719.2 + AL161431.1 + `PCCA-DT` + \n##     AC245041.2 + U62317.1 + AL023284.4 + AATBC + AC015912.3\n## \n##                  Df    AIC\n## - AATBC           1 754.44\n## - `KRT7-AS`       1 754.49\n## - `PPP1R14B-AS1`  1 754.82\n## - SNHG25          1 754.85\n## - LINC00865       1 754.96\n## - AC025575.2      1 755.07\n## - AP001107.5      1 755.13\n## - AC036108.3      1 755.14\n## - AL390719.2      1 755.17\n## - LINC01082       1 755.17\n## - LINC01133       1 755.22\n## - AC053503.3      1 755.24\n## - AL023284.4      1 755.52\n## - `MBNL1-AS1`     1 755.60\n## - AP003071.4      1 755.80\n## &lt;none&gt;              755.83\n## - AC012085.2      1 755.83\n## - AC099850.4      1 755.87\n## - `MAFG-DT`       1 755.93\n## - FENDRR          1 755.95\n## - AL445524.1      1 756.07\n## - `HAND2-AS1`     1 756.42\n## - U62317.1        1 756.56\n## - AL049555.1      1 756.62\n## - AC245041.2      1 756.65\n## - AF001548.1      1 756.82\n## - AL161431.1      1 756.93\n## - LINC02657       1 757.02\n## - AC015912.3      1 757.04\n## - PCAT6           1 757.11\n## - `SPINT1-AS1`    1 757.15\n## + LINC00641       1 757.18\n## + CASC9           1 757.26\n## - `MIR1-1HG-AS1`  1 757.51\n## + AC005180.1      1 757.53\n## + SNHG12          1 757.54\n## + AC002398.2      1 757.60\n## + MIR205HG        1 757.63\n## + AC008736.1      1 757.66\n## + MIR200CHG       1 757.72\n## + MIR22HG         1 757.73\n## + `ADAMTS9-AS1`   1 757.74\n## + `ACTA2-AS1`     1 757.75\n## + AC079313.2      1 757.75\n## + AC018904.1      1 757.77\n## + U62317.2        1 757.77\n## + `PGM5-AS1`      1 757.79\n## + `C5orf66-AS1`   1 757.80\n## + AC008735.2      1 757.81\n## + AL162424.1      1 757.81\n## + AC020916.1      1 757.81\n## + `VPS9D1-AS1`    1 757.83\n## + AC092718.4      1 757.83\n## - AC093010.3      1 757.99\n## - `PCCA-DT`       1 759.15\n## - MIR100HG        1 759.34\n## - `ZNF710-AS1`    1 759.56\n## - LINC01980       1 760.00\n## - NR4A1AS         1 762.64\n## - AC005180.2      1 764.00\n## \n## Step:  AIC=754.44\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + FENDRR + \n##     AC053503.3 + MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + \n##     AC099850.4 + `MBNL1-AS1` + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + \n##     SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + `KRT7-AS` + \n##     `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + LINC01133 + \n##     AC025575.2 + `MAFG-DT` + AL390719.2 + AL161431.1 + `PCCA-DT` + \n##     AC245041.2 + U62317.1 + AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - `KRT7-AS`       1 752.98\n## - LINC00865       1 753.26\n## - LINC01133       1 753.47\n## - `PPP1R14B-AS1`  1 753.56\n## - AC053503.3      1 753.70\n## - LINC01082       1 753.86\n## - SNHG25          1 753.89\n## - AP001107.5      1 753.90\n## - AL023284.4      1 753.91\n## - AC036108.3      1 754.04\n## - AL390719.2      1 754.16\n## - AC099850.4      1 754.35\n## - `MBNL1-AS1`     1 754.35\n## - FENDRR          1 754.39\n## &lt;none&gt;              754.44\n## - `MAFG-DT`       1 754.47\n## - AL445524.1      1 754.51\n## - AC025575.2      1 754.54\n## - AP003071.4      1 754.55\n## - AC012085.2      1 754.64\n## - AC245041.2      1 755.16\n## - `HAND2-AS1`     1 755.23\n## - AC015912.3      1 755.24\n## - AL049555.1      1 755.33\n## - `SPINT1-AS1`    1 755.43\n## - U62317.1        1 755.52\n## - PCAT6           1 755.55\n## - AF001548.1      1 755.60\n## - AL161431.1      1 755.75\n## + AATBC           1 755.83\n## + CASC9           1 755.90\n## - LINC02657       1 755.93\n## + LINC00641       1 755.97\n## + SNHG12          1 756.12\n## + AC005180.1      1 756.16\n## + `ACTA2-AS1`     1 756.22\n## + AC002398.2      1 756.24\n## + MIR205HG        1 756.24\n## + MIR22HG         1 756.32\n## + `C5orf66-AS1`   1 756.33\n## + `ADAMTS9-AS1`   1 756.34\n## + AL162424.1      1 756.35\n## + U62317.2        1 756.35\n## + AC018904.1      1 756.37\n## + MIR200CHG       1 756.37\n## + AC008736.1      1 756.38\n## + `PGM5-AS1`      1 756.40\n## + AC079313.2      1 756.40\n## + `VPS9D1-AS1`    1 756.41\n## + AC008735.2      1 756.41\n## + AC020916.1      1 756.41\n## + AC092718.4      1 756.44\n## - AC093010.3      1 756.54\n## - `MIR1-1HG-AS1`  1 756.78\n## - `PCCA-DT`       1 757.21\n## - MIR100HG        1 757.48\n## - `ZNF710-AS1`    1 758.09\n## - LINC01980       1 758.58\n## - NR4A1AS         1 760.75\n## - AC005180.2      1 762.37\n## \n## Step:  AIC=752.98\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + FENDRR + \n##     AC053503.3 + MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + \n##     AC099850.4 + `MBNL1-AS1` + AC093010.3 + LINC00865 + AP003071.4 + \n##     PCAT6 + LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + \n##     SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + `HAND2-AS1` + \n##     AL445524.1 + LINC01980 + `ZNF710-AS1` + LINC01133 + AC025575.2 + \n##     `MAFG-DT` + AL390719.2 + AL161431.1 + `PCCA-DT` + AC245041.2 + \n##     U62317.1 + AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - LINC00865       1 751.72\n## - `PPP1R14B-AS1`  1 752.06\n## - LINC01133       1 752.10\n## - AC053503.3      1 752.13\n## - SNHG25          1 752.14\n## - AP001107.5      1 752.42\n## - AL390719.2      1 752.49\n## - LINC01082       1 752.53\n## - AC036108.3      1 752.75\n## - AL445524.1      1 752.77\n## - `MBNL1-AS1`     1 752.83\n## - FENDRR          1 752.88\n## - AC099850.4      1 752.95\n## &lt;none&gt;              752.98\n## - `MAFG-DT`       1 752.99\n## - AP003071.4      1 753.05\n## - AC025575.2      1 753.05\n## - AL023284.4      1 753.05\n## - AC245041.2      1 753.33\n## - U62317.1        1 753.71\n## - AL049555.1      1 753.79\n## - `SPINT1-AS1`    1 753.88\n## - AF001548.1      1 753.91\n## - AC012085.2      1 753.94\n## - `HAND2-AS1`     1 753.97\n## - PCAT6           1 754.04\n## - AL161431.1      1 754.41\n## + `KRT7-AS`       1 754.44\n## + AATBC           1 754.49\n## + CASC9           1 754.52\n## + AC005180.1      1 754.61\n## - AC015912.3      1 754.65\n## + LINC00641       1 754.71\n## + `ACTA2-AS1`     1 754.74\n## + `C5orf66-AS1`   1 754.75\n## - LINC02657       1 754.79\n## + AL162424.1      1 754.82\n## + AC002398.2      1 754.83\n## + SNHG12          1 754.84\n## + MIR205HG        1 754.86\n## + U62317.2        1 754.87\n## + AC008736.1      1 754.88\n## + MIR22HG         1 754.91\n## + `ADAMTS9-AS1`   1 754.91\n## + MIR200CHG       1 754.92\n## + AC079313.2      1 754.93\n## + `PGM5-AS1`      1 754.94\n## + AC020916.1      1 754.95\n## + `VPS9D1-AS1`    1 754.97\n## + AC092718.4      1 754.97\n## + AC018904.1      1 754.98\n## + AC008735.2      1 754.98\n## - `MIR1-1HG-AS1`  1 755.36\n## - `PCCA-DT`       1 755.64\n## - AC093010.3      1 755.73\n## - MIR100HG        1 755.80\n## - `ZNF710-AS1`    1 756.48\n## - LINC01980       1 757.46\n## - NR4A1AS         1 758.89\n## - AC005180.2      1 761.16\n## \n## Step:  AIC=751.72\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + FENDRR + \n##     AC053503.3 + MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + \n##     AC099850.4 + `MBNL1-AS1` + AC093010.3 + AP003071.4 + PCAT6 + \n##     LINC02657 + `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + SNHG25 + \n##     AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + `HAND2-AS1` + \n##     AL445524.1 + LINC01980 + `ZNF710-AS1` + LINC01133 + AC025575.2 + \n##     `MAFG-DT` + AL390719.2 + AL161431.1 + `PCCA-DT` + AC245041.2 + \n##     U62317.1 + AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - AC053503.3      1 750.58\n## - LINC01133       1 750.66\n## - SNHG25          1 750.74\n## - `PPP1R14B-AS1`  1 750.79\n## - AL390719.2      1 750.80\n## - LINC01082       1 751.07\n## - AL445524.1      1 751.11\n## - AP001107.5      1 751.26\n## - AC099850.4      1 751.28\n## - AC025575.2      1 751.36\n## - AC036108.3      1 751.41\n## - FENDRR          1 751.44\n## - AC245041.2      1 751.60\n## - AP003071.4      1 751.60\n## - `MBNL1-AS1`     1 751.65\n## &lt;none&gt;              751.72\n## - AL023284.4      1 751.77\n## - `MAFG-DT`       1 751.83\n## - U62317.1        1 752.23\n## - `SPINT1-AS1`    1 752.38\n## - `HAND2-AS1`     1 752.48\n## - AF001548.1      1 752.56\n## - PCAT6           1 752.73\n## - AC012085.2      1 752.88\n## - AL049555.1      1 752.92\n## + LINC00865       1 752.98\n## - AL161431.1      1 753.05\n## + CASC9           1 753.16\n## + `KRT7-AS`       1 753.26\n## - LINC02657       1 753.32\n## + AC005180.1      1 753.36\n## - AC015912.3      1 753.38\n## + AATBC           1 753.50\n## + AC002398.2      1 753.51\n## + LINC00641       1 753.51\n## + `ACTA2-AS1`     1 753.54\n## + SNHG12          1 753.56\n## + `C5orf66-AS1`   1 753.57\n## + AL162424.1      1 753.57\n## + MIR205HG        1 753.58\n## + U62317.2        1 753.61\n## + MIR22HG         1 753.65\n## + MIR200CHG       1 753.66\n## + `VPS9D1-AS1`    1 753.67\n## + AC079313.2      1 753.68\n## + AC008736.1      1 753.69\n## + `ADAMTS9-AS1`   1 753.70\n## + AC092718.4      1 753.71\n## + AC020916.1      1 753.71\n## + AC008735.2      1 753.71\n## + `PGM5-AS1`      1 753.72\n## + AC018904.1      1 753.72\n## - `MIR1-1HG-AS1`  1 753.99\n## - MIR100HG        1 754.28\n## - `PCCA-DT`       1 754.53\n## - `ZNF710-AS1`    1 754.97\n## - AC093010.3      1 755.22\n## - LINC01980       1 756.72\n## - NR4A1AS         1 757.43\n## - AC005180.2      1 759.54\n## \n## Step:  AIC=750.58\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + FENDRR + \n##     MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + AC099850.4 + \n##     `MBNL1-AS1` + AC093010.3 + AP003071.4 + PCAT6 + LINC02657 + \n##     `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + SNHG25 + AL049555.1 + \n##     `MIR1-1HG-AS1` + `SPINT1-AS1` + `HAND2-AS1` + AL445524.1 + \n##     LINC01980 + `ZNF710-AS1` + LINC01133 + AC025575.2 + `MAFG-DT` + \n##     AL390719.2 + AL161431.1 + `PCCA-DT` + AC245041.2 + U62317.1 + \n##     AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - SNHG25          1 749.26\n## - AL390719.2      1 749.45\n## - `PPP1R14B-AS1`  1 749.53\n## - LINC01133       1 749.53\n## - LINC01082       1 750.03\n## - AL445524.1      1 750.08\n## - AC099850.4      1 750.09\n## - FENDRR          1 750.15\n## - AC025575.2      1 750.22\n## - AP001107.5      1 750.31\n## - AC245041.2      1 750.41\n## - AC036108.3      1 750.42\n## - AP003071.4      1 750.45\n## &lt;none&gt;              750.58\n## - `MAFG-DT`       1 750.70\n## - AF001548.1      1 750.89\n## - `HAND2-AS1`     1 751.08\n## - `MBNL1-AS1`     1 751.14\n## - AL023284.4      1 751.17\n## - AC012085.2      1 751.26\n## - AL049555.1      1 751.32\n## - `SPINT1-AS1`    1 751.45\n## - U62317.1        1 751.51\n## - PCAT6           1 751.57\n## + AC053503.3      1 751.72\n## + CASC9           1 751.90\n## - AL161431.1      1 752.12\n## + LINC00865       1 752.13\n## + `KRT7-AS`       1 752.19\n## + `ACTA2-AS1`     1 752.19\n## + MIR205HG        1 752.26\n## + AC002398.2      1 752.30\n## + LINC00641       1 752.35\n## + AATBC           1 752.39\n## + `C5orf66-AS1`   1 752.39\n## + MIR200CHG       1 752.42\n## - MIR100HG        1 752.45\n## + SNHG12          1 752.45\n## + `ADAMTS9-AS1`   1 752.47\n## + AC092718.4      1 752.48\n## + AC005180.1      1 752.49\n## + MIR22HG         1 752.50\n## + U62317.2        1 752.52\n## - LINC02657       1 752.53\n## + AC008736.1      1 752.56\n## + AL162424.1      1 752.56\n## + `VPS9D1-AS1`    1 752.57\n## + AC008735.2      1 752.57\n## + AC018904.1      1 752.58\n## + `PGM5-AS1`      1 752.58\n## + AC079313.2      1 752.58\n## + AC020916.1      1 752.58\n## - AC015912.3      1 752.82\n## - `PCCA-DT`       1 753.27\n## - `ZNF710-AS1`    1 753.64\n## - AC093010.3      1 753.97\n## - `MIR1-1HG-AS1`  1 754.23\n## - LINC01980       1 755.16\n## - NR4A1AS         1 756.22\n## - AC005180.2      1 757.56\n## \n## Step:  AIC=749.26\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + FENDRR + \n##     MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + AC099850.4 + \n##     `MBNL1-AS1` + AC093010.3 + AP003071.4 + PCAT6 + LINC02657 + \n##     `PPP1R14B-AS1` + AC012085.2 + AC036108.3 + AL049555.1 + `MIR1-1HG-AS1` + \n##     `SPINT1-AS1` + `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + \n##     LINC01133 + AC025575.2 + `MAFG-DT` + AL390719.2 + AL161431.1 + \n##     `PCCA-DT` + AC245041.2 + U62317.1 + AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - `PPP1R14B-AS1`  1 748.02\n## - AL390719.2      1 748.09\n## - LINC01133       1 748.13\n## - LINC01082       1 748.35\n## - FENDRR          1 748.40\n## - AC025575.2      1 748.62\n## - AL445524.1      1 748.84\n## - AC099850.4      1 749.03\n## - AC036108.3      1 749.07\n## - `MAFG-DT`       1 749.20\n## - AC245041.2      1 749.21\n## - AP003071.4      1 749.22\n## - AP001107.5      1 749.22\n## &lt;none&gt;              749.26\n## - AF001548.1      1 749.33\n## - `HAND2-AS1`     1 749.64\n## - AL049555.1      1 749.70\n## - U62317.1        1 749.96\n## - AC012085.2      1 750.03\n## - `MBNL1-AS1`     1 750.11\n## - AL023284.4      1 750.55\n## + CASC9           1 750.55\n## + SNHG25          1 750.58\n## + AC053503.3      1 750.74\n## + MIR205HG        1 750.81\n## - MIR100HG        1 750.81\n## + AATBC           1 750.85\n## + LINC00865       1 750.87\n## - AL161431.1      1 750.87\n## - `SPINT1-AS1`    1 750.88\n## + `ACTA2-AS1`     1 750.89\n## + LINC00641       1 750.94\n## + U62317.2        1 750.96\n## + AC002398.2      1 750.96\n## + MIR22HG         1 751.01\n## + `KRT7-AS`       1 751.04\n## + `VPS9D1-AS1`    1 751.13\n## + MIR200CHG       1 751.14\n## + AC005180.1      1 751.15\n## + `ADAMTS9-AS1`   1 751.16\n## + AL162424.1      1 751.21\n## + AC092718.4      1 751.22\n## + `C5orf66-AS1`   1 751.23\n## + `PGM5-AS1`      1 751.24\n## + AC008736.1      1 751.25\n## + AC008735.2      1 751.25\n## + SNHG12          1 751.25\n## - LINC02657       1 751.26\n## + AC020916.1      1 751.26\n## + AC079313.2      1 751.26\n## + AC018904.1      1 751.26\n## - PCAT6           1 751.28\n## - `ZNF710-AS1`    1 751.95\n## - `PCCA-DT`       1 752.22\n## - AC093010.3      1 752.35\n## - `MIR1-1HG-AS1`  1 752.80\n## - LINC01980       1 753.92\n## - NR4A1AS         1 754.92\n## - AC015912.3      1 756.63\n## - AC005180.2      1 757.15\n## \n## Step:  AIC=748.02\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + FENDRR + \n##     MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + AC099850.4 + \n##     `MBNL1-AS1` + AC093010.3 + AP003071.4 + PCAT6 + LINC02657 + \n##     AC012085.2 + AC036108.3 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + \n##     `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + LINC01133 + \n##     AC025575.2 + `MAFG-DT` + AL390719.2 + AL161431.1 + `PCCA-DT` + \n##     AC245041.2 + U62317.1 + AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - LINC01133       1 746.70\n## - AL390719.2      1 746.84\n## - LINC01082       1 746.85\n## - FENDRR          1 746.88\n## - AC025575.2      1 747.27\n## - AL445524.1      1 747.34\n## - AC099850.4      1 747.52\n## - AC036108.3      1 747.83\n## - `MAFG-DT`       1 747.94\n## &lt;none&gt;              748.02\n## - AP001107.5      1 748.10\n## - AP003071.4      1 748.10\n## - U62317.1        1 748.20\n## - AL049555.1      1 748.26\n## - AC245041.2      1 748.39\n## - AF001548.1      1 748.40\n## - `HAND2-AS1`     1 748.44\n## - AC012085.2      1 748.71\n## - AL023284.4      1 749.07\n## - `MBNL1-AS1`     1 749.13\n## + `PPP1R14B-AS1`  1 749.26\n## + MIR205HG        1 749.35\n## + CASC9           1 749.37\n## + SNHG25          1 749.53\n## + AATBC           1 749.54\n## + AC053503.3      1 749.55\n## - LINC02657       1 749.59\n## + LINC00865       1 749.62\n## + U62317.2        1 749.62\n## + LINC00641       1 749.64\n## + `ACTA2-AS1`     1 749.76\n## - MIR100HG        1 749.77\n## + MIR22HG         1 749.79\n## + `KRT7-AS`       1 749.81\n## + AC005180.1      1 749.82\n## + MIR200CHG       1 749.85\n## + AC002398.2      1 749.85\n## + AC092718.4      1 749.92\n## + `C5orf66-AS1`   1 749.96\n## + AC008736.1      1 749.97\n## + AC008735.2      1 749.97\n## - AL161431.1      1 749.98\n## + AL162424.1      1 749.98\n## + `ADAMTS9-AS1`   1 749.98\n## + `VPS9D1-AS1`    1 749.98\n## + AC079313.2      1 750.00\n## + `PGM5-AS1`      1 750.00\n## + SNHG12          1 750.01\n## + AC018904.1      1 750.02\n## + AC020916.1      1 750.02\n## - `SPINT1-AS1`    1 750.22\n## - PCAT6           1 750.60\n## - `PCCA-DT`       1 750.93\n## - `ZNF710-AS1`    1 750.97\n## - `MIR1-1HG-AS1`  1 751.43\n## - AC093010.3      1 752.37\n## - LINC01980       1 752.58\n## - NR4A1AS         1 753.20\n## - AC015912.3      1 754.72\n## - AC005180.2      1 755.97\n## \n## Step:  AIC=746.7\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + FENDRR + \n##     MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + AC099850.4 + \n##     `MBNL1-AS1` + AC093010.3 + AP003071.4 + PCAT6 + LINC02657 + \n##     AC012085.2 + AC036108.3 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + \n##     `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + AC025575.2 + \n##     `MAFG-DT` + AL390719.2 + AL161431.1 + `PCCA-DT` + AC245041.2 + \n##     U62317.1 + AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - AL390719.2      1 745.54\n## - LINC01082       1 745.66\n## - FENDRR          1 745.68\n## - AL445524.1      1 745.77\n## - AC025575.2      1 745.78\n## - AC099850.4      1 746.30\n## - U62317.1        1 746.46\n## &lt;none&gt;              746.70\n## - `MAFG-DT`       1 746.70\n## - AC036108.3      1 746.77\n## - AL049555.1      1 746.79\n## - AC245041.2      1 746.94\n## - AF001548.1      1 746.97\n## - AP001107.5      1 747.00\n## - AP003071.4      1 747.38\n## - `HAND2-AS1`     1 747.51\n## - `MBNL1-AS1`     1 747.51\n## - AL023284.4      1 747.57\n## - AC012085.2      1 747.76\n## + LINC01133       1 748.02\n## + MIR205HG        1 748.06\n## + `PPP1R14B-AS1`  1 748.13\n## - MIR100HG        1 748.18\n## + AC053503.3      1 748.19\n## + CASC9           1 748.19\n## + SNHG25          1 748.25\n## - LINC02657       1 748.29\n## + LINC00641       1 748.29\n## + `ACTA2-AS1`     1 748.33\n## + U62317.2        1 748.35\n## + LINC00865       1 748.42\n## + `KRT7-AS`       1 748.44\n## + AC002398.2      1 748.45\n## + AATBC           1 748.48\n## + `C5orf66-AS1`   1 748.54\n## + AC005180.1      1 748.55\n## + MIR22HG         1 748.56\n## + MIR200CHG       1 748.59\n## + AC008736.1      1 748.60\n## + `ADAMTS9-AS1`   1 748.63\n## + AL162424.1      1 748.65\n## + AC008735.2      1 748.65\n## + AC092718.4      1 748.67\n## + `VPS9D1-AS1`    1 748.67\n## + AC079313.2      1 748.69\n## + SNHG12          1 748.70\n## + AC018904.1      1 748.70\n## + AC020916.1      1 748.70\n## + `PGM5-AS1`      1 748.70\n## - PCAT6           1 749.04\n## - `PCCA-DT`       1 749.21\n## - `ZNF710-AS1`    1 749.33\n## - `SPINT1-AS1`    1 749.43\n## - AL161431.1      1 749.63\n## - `MIR1-1HG-AS1`  1 750.54\n## - AC093010.3      1 750.61\n## - LINC01980       1 750.76\n## - NR4A1AS         1 751.94\n## - AC015912.3      1 753.70\n## - AC005180.2      1 754.92\n## \n## Step:  AIC=745.54\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + FENDRR + \n##     MIR100HG + AP001107.5 + NR4A1AS + AF001548.1 + AC099850.4 + \n##     `MBNL1-AS1` + AC093010.3 + AP003071.4 + PCAT6 + LINC02657 + \n##     AC012085.2 + AC036108.3 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + \n##     `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + AC025575.2 + \n##     `MAFG-DT` + AL161431.1 + `PCCA-DT` + AC245041.2 + U62317.1 + \n##     AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - FENDRR          1 744.39\n## - LINC01082       1 744.46\n## - AC099850.4      1 744.58\n## - AC025575.2      1 744.86\n## - AL445524.1      1 744.93\n## - AF001548.1      1 745.20\n## - AC245041.2      1 745.22\n## - U62317.1        1 745.37\n## &lt;none&gt;              745.54\n## - AL049555.1      1 745.66\n## - AL023284.4      1 745.76\n## - `HAND2-AS1`     1 745.83\n## - `MBNL1-AS1`     1 745.99\n## - AP003071.4      1 746.06\n## - `MAFG-DT`       1 746.12\n## - AC036108.3      1 746.12\n## - AP001107.5      1 746.19\n## - AC012085.2      1 746.46\n## - LINC02657       1 746.67\n## + AL390719.2      1 746.70\n## + LINC01133       1 746.84\n## + LINC00641       1 746.87\n## - MIR100HG        1 746.90\n## + `PPP1R14B-AS1`  1 746.93\n## + AATBC           1 747.07\n## + MIR205HG        1 747.10\n## + CASC9           1 747.11\n## + SNHG25          1 747.12\n## + AC002398.2      1 747.12\n## + AC053503.3      1 747.15\n## + `ACTA2-AS1`     1 747.19\n## + `C5orf66-AS1`   1 747.24\n## + U62317.2        1 747.25\n## + MIR22HG         1 747.29\n## + `KRT7-AS`       1 747.38\n## - `ZNF710-AS1`    1 747.41\n## + AC005180.1      1 747.43\n## + AC008736.1      1 747.44\n## + SNHG12          1 747.44\n## + LINC00865       1 747.45\n## + MIR200CHG       1 747.49\n## + `PGM5-AS1`      1 747.50\n## + AL162424.1      1 747.51\n## + `ADAMTS9-AS1`   1 747.52\n## + AC079313.2      1 747.53\n## + AC020916.1      1 747.53\n## + AC008735.2      1 747.53\n## + AC092718.4      1 747.54\n## + `VPS9D1-AS1`    1 747.54\n## + AC018904.1      1 747.54\n## - PCAT6           1 747.84\n## - AL161431.1      1 747.85\n## - `PCCA-DT`       1 748.07\n## - `MIR1-1HG-AS1`  1 748.95\n## - `SPINT1-AS1`    1 749.27\n## - LINC01980       1 749.49\n## - AC093010.3      1 750.35\n## - NR4A1AS         1 750.54\n## - AC015912.3      1 751.83\n## - AC005180.2      1 753.28\n## \n## Step:  AIC=744.39\n## Surv(time_months, event) ~ LINC01082 + AC005180.2 + MIR100HG + \n##     AP001107.5 + NR4A1AS + AF001548.1 + AC099850.4 + `MBNL1-AS1` + \n##     AC093010.3 + AP003071.4 + PCAT6 + LINC02657 + AC012085.2 + \n##     AC036108.3 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + \n##     `HAND2-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + AC025575.2 + \n##     `MAFG-DT` + AL161431.1 + `PCCA-DT` + AC245041.2 + U62317.1 + \n##     AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - LINC01082       1 742.56\n## - AC099850.4      1 743.15\n## - AC025575.2      1 743.56\n## - AL445524.1      1 743.76\n## - U62317.1        1 743.91\n## - AC245041.2      1 743.98\n## - `HAND2-AS1`     1 744.00\n## - AF001548.1      1 744.20\n## &lt;none&gt;              744.39\n## - AP001107.5      1 744.66\n## - AC036108.3      1 744.67\n## - AP003071.4      1 744.93\n## - `MAFG-DT`       1 744.94\n## - AL023284.4      1 744.96\n## - AL049555.1      1 745.14\n## - `MBNL1-AS1`     1 745.18\n## - AC012085.2      1 745.38\n## - LINC02657       1 745.44\n## - MIR100HG        1 745.48\n## + FENDRR          1 745.54\n## + LINC01133       1 745.60\n## + LINC00641       1 745.65\n## + AL390719.2      1 745.68\n## + AC002398.2      1 745.78\n## + `ACTA2-AS1`     1 745.87\n## + AC053503.3      1 745.99\n## - `ZNF710-AS1`    1 745.99\n## + `PPP1R14B-AS1`  1 746.04\n## + MIR205HG        1 746.05\n## + `C5orf66-AS1`   1 746.06\n## + CASC9           1 746.09\n## + AATBC           1 746.10\n## + `KRT7-AS`       1 746.19\n## + U62317.2        1 746.21\n## + SNHG12          1 746.21\n## + SNHG25          1 746.23\n## + AC008736.1      1 746.29\n## - PCAT6           1 746.29\n## + MIR22HG         1 746.29\n## + LINC00865       1 746.32\n## + MIR200CHG       1 746.33\n## + AC005180.1      1 746.35\n## + AL162424.1      1 746.35\n## + AC020916.1      1 746.36\n## + AC008735.2      1 746.38\n## + AC079313.2      1 746.38\n## + `PGM5-AS1`      1 746.39\n## + AC092718.4      1 746.39\n## + `VPS9D1-AS1`    1 746.39\n## + AC018904.1      1 746.39\n## + `ADAMTS9-AS1`   1 746.39\n## - AL161431.1      1 746.55\n## - `PCCA-DT`       1 746.69\n## - `MIR1-1HG-AS1`  1 747.32\n## - LINC01980       1 748.03\n## - `SPINT1-AS1`    1 748.32\n## - NR4A1AS         1 748.73\n## - AC093010.3      1 748.88\n## - AC015912.3      1 750.41\n## - AC005180.2      1 751.57\n## \n## Step:  AIC=742.56\n## Surv(time_months, event) ~ AC005180.2 + MIR100HG + AP001107.5 + \n##     NR4A1AS + AF001548.1 + AC099850.4 + `MBNL1-AS1` + AC093010.3 + \n##     AP003071.4 + PCAT6 + LINC02657 + AC012085.2 + AC036108.3 + \n##     AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + `HAND2-AS1` + \n##     AL445524.1 + LINC01980 + `ZNF710-AS1` + AC025575.2 + `MAFG-DT` + \n##     AL161431.1 + `PCCA-DT` + AC245041.2 + U62317.1 + AL023284.4 + \n##     AC015912.3\n## \n##                  Df    AIC\n## - AC099850.4      1 741.17\n## - AC025575.2      1 741.71\n## - AL445524.1      1 742.05\n## - AC245041.2      1 742.09\n## - `HAND2-AS1`     1 742.18\n## - U62317.1        1 742.22\n## - AF001548.1      1 742.26\n## &lt;none&gt;              742.56\n## - AC036108.3      1 742.79\n## - AP003071.4      1 742.93\n## - AP001107.5      1 742.98\n## - `MAFG-DT`       1 743.22\n## - AL049555.1      1 743.37\n## - AL023284.4      1 743.39\n## - AC012085.2      1 743.46\n## - `MBNL1-AS1`     1 743.65\n## + LINC01133       1 743.74\n## + LINC00641       1 743.75\n## - LINC02657       1 743.80\n## + AL390719.2      1 743.81\n## + `ACTA2-AS1`     1 743.93\n## + AC053503.3      1 744.09\n## + AC002398.2      1 744.10\n## + `C5orf66-AS1`   1 744.11\n## + AATBC           1 744.21\n## + `PPP1R14B-AS1`  1 744.23\n## - MIR100HG        1 744.26\n## + MIR205HG        1 744.26\n## + CASC9           1 744.28\n## + U62317.2        1 744.30\n## - `ZNF710-AS1`    1 744.32\n## + `KRT7-AS`       1 744.32\n## + SNHG12          1 744.38\n## + LINC01082       1 744.39\n## + SNHG25          1 744.40\n## + AC008736.1      1 744.42\n## - PCAT6           1 744.45\n## + MIR22HG         1 744.46\n## + FENDRR          1 744.46\n## + AL162424.1      1 744.50\n## + LINC00865       1 744.51\n## + MIR200CHG       1 744.51\n## + AC020916.1      1 744.53\n## + AC005180.1      1 744.54\n## + `PGM5-AS1`      1 744.54\n## + AC008735.2      1 744.55\n## + AC018904.1      1 744.56\n## + `VPS9D1-AS1`    1 744.56\n## + AC092718.4      1 744.56\n## + AC079313.2      1 744.56\n## + `ADAMTS9-AS1`   1 744.56\n## - AL161431.1      1 744.61\n## - `PCCA-DT`       1 744.69\n## - `MIR1-1HG-AS1`  1 745.39\n## - LINC01980       1 746.26\n## - `SPINT1-AS1`    1 746.61\n## - AC093010.3      1 747.10\n## - NR4A1AS         1 747.17\n## - AC015912.3      1 748.56\n## - AC005180.2      1 749.80\n## \n## Step:  AIC=741.17\n## Surv(time_months, event) ~ AC005180.2 + MIR100HG + AP001107.5 + \n##     NR4A1AS + AF001548.1 + `MBNL1-AS1` + AC093010.3 + AP003071.4 + \n##     PCAT6 + LINC02657 + AC012085.2 + AC036108.3 + AL049555.1 + \n##     `MIR1-1HG-AS1` + `SPINT1-AS1` + `HAND2-AS1` + AL445524.1 + \n##     LINC01980 + `ZNF710-AS1` + AC025575.2 + `MAFG-DT` + AL161431.1 + \n##     `PCCA-DT` + AC245041.2 + U62317.1 + AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - AC025575.2      1 740.28\n## - AC245041.2      1 740.38\n## - `HAND2-AS1`     1 740.58\n## - AL445524.1      1 740.61\n## - U62317.1        1 740.91\n## - AF001548.1      1 741.12\n## &lt;none&gt;              741.17\n## - AC036108.3      1 741.49\n## - AP003071.4      1 741.59\n## - AP001107.5      1 741.70\n## - AL049555.1      1 741.78\n## - `MBNL1-AS1`     1 741.95\n## - AC012085.2      1 742.05\n## - LINC02657       1 742.07\n## + LINC00641       1 742.20\n## - AL023284.4      1 742.30\n## + LINC01133       1 742.31\n## + `ACTA2-AS1`     1 742.50\n## + AC099850.4      1 742.56\n## + MIR205HG        1 742.62\n## + AC002398.2      1 742.63\n## - `ZNF710-AS1`    1 742.68\n## - `MAFG-DT`       1 742.70\n## + AC053503.3      1 742.76\n## + CASC9           1 742.77\n## - PCAT6           1 742.77\n## + SNHG25          1 742.86\n## + AL390719.2      1 742.89\n## - MIR100HG        1 742.89\n## + `C5orf66-AS1`   1 742.90\n## + `KRT7-AS`       1 742.91\n## + U62317.2        1 742.93\n## + AATBC           1 742.94\n## + `PPP1R14B-AS1`  1 742.94\n## - `PCCA-DT`       1 742.95\n## + AC008736.1      1 742.96\n## + MIR200CHG       1 742.99\n## + FENDRR          1 743.02\n## + SNHG12          1 743.02\n## + AC092718.4      1 743.13\n## + AL162424.1      1 743.13\n## + `PGM5-AS1`      1 743.13\n## + LINC00865       1 743.14\n## + MIR22HG         1 743.14\n## + LINC01082       1 743.15\n## + AC008735.2      1 743.15\n## + AC005180.1      1 743.16\n## + AC018904.1      1 743.16\n## + `VPS9D1-AS1`    1 743.17\n## + AC079313.2      1 743.17\n## + AC020916.1      1 743.17\n## + `ADAMTS9-AS1`   1 743.17\n## - AL161431.1      1 743.59\n## - `MIR1-1HG-AS1`  1 744.11\n## - `SPINT1-AS1`    1 744.61\n## - LINC01980       1 744.67\n## - NR4A1AS         1 745.29\n## - AC015912.3      1 746.59\n## - AC093010.3      1 747.39\n## - AC005180.2      1 748.33\n## \n## Step:  AIC=740.28\n## Surv(time_months, event) ~ AC005180.2 + MIR100HG + AP001107.5 + \n##     NR4A1AS + AF001548.1 + `MBNL1-AS1` + AC093010.3 + AP003071.4 + \n##     PCAT6 + LINC02657 + AC012085.2 + AC036108.3 + AL049555.1 + \n##     `MIR1-1HG-AS1` + `SPINT1-AS1` + `HAND2-AS1` + AL445524.1 + \n##     LINC01980 + `ZNF710-AS1` + `MAFG-DT` + AL161431.1 + `PCCA-DT` + \n##     AC245041.2 + U62317.1 + AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - AC245041.2      1 739.30\n## - `HAND2-AS1`     1 739.66\n## - U62317.1        1 739.83\n## - AL445524.1      1 739.83\n## - AF001548.1      1 740.24\n## &lt;none&gt;              740.28\n## - AC036108.3      1 740.35\n## - `MBNL1-AS1`     1 740.38\n## - AP003071.4      1 740.42\n## - AP001107.5      1 740.55\n## - LINC02657       1 740.90\n## - AL049555.1      1 740.94\n## - AL023284.4      1 741.00\n## + AC025575.2      1 741.17\n## + LINC00641       1 741.18\n## - AC012085.2      1 741.33\n## - `PCCA-DT`       1 741.47\n## - `MAFG-DT`       1 741.51\n## + `ACTA2-AS1`     1 741.57\n## - MIR100HG        1 741.57\n## + AATBC           1 741.60\n## + LINC01133       1 741.68\n## + AC099850.4      1 741.71\n## + AC002398.2      1 741.78\n## + AL390719.2      1 741.84\n## + AC053503.3      1 741.87\n## + `C5orf66-AS1`   1 741.90\n## + SNHG12          1 741.96\n## + MIR205HG        1 741.98\n## - `ZNF710-AS1`    1 742.00\n## + `KRT7-AS`       1 742.02\n## + U62317.2        1 742.06\n## + SNHG25          1 742.11\n## + `PPP1R14B-AS1`  1 742.11\n## + MIR200CHG       1 742.14\n## + FENDRR          1 742.16\n## + AC008735.2      1 742.19\n## + CASC9           1 742.21\n## + MIR22HG         1 742.21\n## + AC008736.1      1 742.23\n## + `PGM5-AS1`      1 742.23\n## + AC092718.4      1 742.24\n## + AC005180.1      1 742.26\n## - PCAT6           1 742.27\n## + LINC01082       1 742.27\n## + AC018904.1      1 742.27\n## + AC020916.1      1 742.28\n## + AL162424.1      1 742.28\n## + `VPS9D1-AS1`    1 742.28\n## + `ADAMTS9-AS1`   1 742.28\n## + LINC00865       1 742.28\n## + AC079313.2      1 742.28\n## - AL161431.1      1 742.54\n## - LINC01980       1 742.70\n## - `MIR1-1HG-AS1`  1 742.96\n## - `SPINT1-AS1`    1 743.50\n## - NR4A1AS         1 743.83\n## - AC015912.3      1 745.43\n## - AC093010.3      1 746.09\n## - AC005180.2      1 746.76\n## \n## Step:  AIC=739.3\n## Surv(time_months, event) ~ AC005180.2 + MIR100HG + AP001107.5 + \n##     NR4A1AS + AF001548.1 + `MBNL1-AS1` + AC093010.3 + AP003071.4 + \n##     PCAT6 + LINC02657 + AC012085.2 + AC036108.3 + AL049555.1 + \n##     `MIR1-1HG-AS1` + `SPINT1-AS1` + `HAND2-AS1` + AL445524.1 + \n##     LINC01980 + `ZNF710-AS1` + `MAFG-DT` + AL161431.1 + `PCCA-DT` + \n##     U62317.1 + AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - `HAND2-AS1`     1 738.43\n## - U62317.1        1 738.75\n## - AF001548.1      1 739.01\n## - LINC02657       1 739.08\n## - AL445524.1      1 739.25\n## &lt;none&gt;              739.30\n## - `MBNL1-AS1`     1 739.35\n## - AP003071.4      1 739.38\n## - AC036108.3      1 739.40\n## - AP001107.5      1 739.82\n## - `PCCA-DT`       1 740.01\n## - `MAFG-DT`       1 740.19\n## + AC245041.2      1 740.28\n## - AL023284.4      1 740.30\n## + LINC00641       1 740.30\n## + AC025575.2      1 740.38\n## + `ACTA2-AS1`     1 740.39\n## - AC012085.2      1 740.45\n## - MIR100HG        1 740.63\n## + AC002398.2      1 740.68\n## + AATBC           1 740.69\n## + LINC01133       1 740.78\n## - AL049555.1      1 740.84\n## + AC053503.3      1 740.90\n## + SNHG12          1 740.91\n## + `PPP1R14B-AS1`  1 740.96\n## + U62317.2        1 740.97\n## + `C5orf66-AS1`   1 740.99\n## + AC099850.4      1 741.01\n## + CASC9           1 741.07\n## + MIR200CHG       1 741.09\n## + AL390719.2      1 741.11\n## + SNHG25          1 741.11\n## + MIR22HG         1 741.15\n## + MIR205HG        1 741.16\n## + FENDRR          1 741.18\n## + `KRT7-AS`       1 741.21\n## + AC092718.4      1 741.21\n## - `ZNF710-AS1`    1 741.21\n## + `PGM5-AS1`      1 741.23\n## + AC008736.1      1 741.24\n## + AC018904.1      1 741.25\n## + `ADAMTS9-AS1`   1 741.26\n## - `MIR1-1HG-AS1`  1 741.28\n## + `VPS9D1-AS1`    1 741.28\n## + LINC01082       1 741.29\n## + AC008735.2      1 741.29\n## + LINC00865       1 741.29\n## + AL162424.1      1 741.30\n## + AC020916.1      1 741.30\n## + AC005180.1      1 741.30\n## + AC079313.2      1 741.30\n## - AL161431.1      1 741.75\n## - PCAT6           1 742.01\n## - LINC01980       1 742.24\n## - `SPINT1-AS1`    1 742.58\n## - NR4A1AS         1 742.65\n## - AC093010.3      1 744.66\n## - AC015912.3      1 744.83\n## - AC005180.2      1 746.28\n## \n## Step:  AIC=738.43\n## Surv(time_months, event) ~ AC005180.2 + MIR100HG + AP001107.5 + \n##     NR4A1AS + AF001548.1 + `MBNL1-AS1` + AC093010.3 + AP003071.4 + \n##     PCAT6 + LINC02657 + AC012085.2 + AC036108.3 + AL049555.1 + \n##     `MIR1-1HG-AS1` + `SPINT1-AS1` + AL445524.1 + LINC01980 + \n##     `ZNF710-AS1` + `MAFG-DT` + AL161431.1 + `PCCA-DT` + U62317.1 + \n##     AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - LINC02657       1 737.73\n## - AP003071.4      1 737.84\n## - `MBNL1-AS1`     1 738.05\n## - U62317.1        1 738.25\n## - AL445524.1      1 738.29\n## &lt;none&gt;              738.43\n## - AP001107.5      1 738.56\n## - AC036108.3      1 738.70\n## - AF001548.1      1 738.75\n## - AC012085.2      1 738.84\n## - `MAFG-DT`       1 739.01\n## + `HAND2-AS1`     1 739.30\n## - `PCCA-DT`       1 739.31\n## + AC025575.2      1 739.51\n## + LINC00641       1 739.60\n## - `MIR1-1HG-AS1`  1 739.65\n## + AC245041.2      1 739.66\n## + AATBC           1 739.73\n## - AL023284.4      1 739.74\n## + LINC01133       1 739.76\n## - AL049555.1      1 739.84\n## + AC002398.2      1 739.95\n## + `C5orf66-AS1`   1 739.95\n## + `PPP1R14B-AS1`  1 740.00\n## + CASC9           1 740.01\n## + U62317.2        1 740.06\n## + AC053503.3      1 740.11\n## + SNHG12          1 740.13\n## + MIR205HG        1 740.20\n## - `ZNF710-AS1`    1 740.20\n## + `KRT7-AS`       1 740.21\n## + `ACTA2-AS1`     1 740.22\n## + MIR200CHG       1 740.23\n## - AL161431.1      1 740.23\n## + AC099850.4      1 740.24\n## + SNHG25          1 740.25\n## + AC079313.2      1 740.29\n## + MIR22HG         1 740.30\n## + AC008736.1      1 740.30\n## + AL390719.2      1 740.33\n## + `PGM5-AS1`      1 740.37\n## + `VPS9D1-AS1`    1 740.38\n## + `ADAMTS9-AS1`   1 740.38\n## + AC092718.4      1 740.39\n## + AL162424.1      1 740.39\n## + LINC01082       1 740.40\n## + AC018904.1      1 740.42\n## + AC020916.1      1 740.42\n## + FENDRR          1 740.42\n## + LINC00865       1 740.42\n## + AC005180.1      1 740.43\n## + AC008735.2      1 740.43\n## - MIR100HG        1 741.10\n## - `SPINT1-AS1`    1 741.10\n## - LINC01980       1 741.14\n## - PCAT6           1 741.42\n## - NR4A1AS         1 741.53\n## - AC015912.3      1 743.69\n## - AC093010.3      1 743.81\n## - AC005180.2      1 746.13\n## \n## Step:  AIC=737.73\n## Surv(time_months, event) ~ AC005180.2 + MIR100HG + AP001107.5 + \n##     NR4A1AS + AF001548.1 + `MBNL1-AS1` + AC093010.3 + AP003071.4 + \n##     PCAT6 + AC012085.2 + AC036108.3 + AL049555.1 + `MIR1-1HG-AS1` + \n##     `SPINT1-AS1` + AL445524.1 + LINC01980 + `ZNF710-AS1` + `MAFG-DT` + \n##     AL161431.1 + `PCCA-DT` + U62317.1 + AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - `MBNL1-AS1`     1 737.00\n## - AL445524.1      1 737.32\n## - AP003071.4      1 737.50\n## - `MAFG-DT`       1 737.66\n## - AF001548.1      1 737.66\n## &lt;none&gt;              737.73\n## - AP001107.5      1 737.94\n## - AC036108.3      1 737.95\n## - U62317.1        1 738.02\n## - AC012085.2      1 738.07\n## + LINC02657       1 738.43\n## - AL049555.1      1 738.76\n## - `ZNF710-AS1`    1 738.77\n## - AL023284.4      1 738.78\n## - `PCCA-DT`       1 738.78\n## - `MIR1-1HG-AS1`  1 738.89\n## + LINC00641       1 738.91\n## + AC025575.2      1 738.95\n## - AL161431.1      1 738.96\n## + AATBC           1 739.01\n## + LINC01133       1 739.05\n## + `HAND2-AS1`     1 739.08\n## + AC053503.3      1 739.19\n## + U62317.2        1 739.19\n## + AC002398.2      1 739.25\n## + `KRT7-AS`       1 739.30\n## + `ACTA2-AS1`     1 739.31\n## + MIR205HG        1 739.33\n## + `C5orf66-AS1`   1 739.38\n## + MIR200CHG       1 739.50\n## + CASC9           1 739.50\n## + SNHG25          1 739.55\n## + `PPP1R14B-AS1`  1 739.57\n## + MIR22HG         1 739.57\n## + AC245041.2      1 739.58\n## + LINC01082       1 739.60\n## + AC099850.4      1 739.62\n## + AL390719.2      1 739.63\n## + AC005180.1      1 739.66\n## + `PGM5-AS1`      1 739.67\n## + AC079313.2      1 739.69\n## + AL162424.1      1 739.69\n## + AC008736.1      1 739.69\n## + SNHG12          1 739.70\n## + AC020916.1      1 739.70\n## + `VPS9D1-AS1`    1 739.72\n## + AC008735.2      1 739.73\n## + AC018904.1      1 739.73\n## + LINC00865       1 739.73\n## + `ADAMTS9-AS1`   1 739.73\n## + AC092718.4      1 739.73\n## + FENDRR          1 739.73\n## - MIR100HG        1 739.82\n## - `SPINT1-AS1`    1 740.04\n## - LINC01980       1 740.41\n## - PCAT6           1 741.28\n## - NR4A1AS         1 741.62\n## - AC093010.3      1 742.38\n## - AC015912.3      1 742.68\n## - AC005180.2      1 745.94\n## \n## Step:  AIC=737\n## Surv(time_months, event) ~ AC005180.2 + MIR100HG + AP001107.5 + \n##     NR4A1AS + AF001548.1 + AC093010.3 + AP003071.4 + PCAT6 + \n##     AC012085.2 + AC036108.3 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + \n##     AL445524.1 + LINC01980 + `ZNF710-AS1` + `MAFG-DT` + AL161431.1 + \n##     `PCCA-DT` + U62317.1 + AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - AP003071.4      1 736.68\n## - `MAFG-DT`       1 736.68\n## - AL445524.1      1 736.69\n## - AF001548.1      1 736.72\n## - AC036108.3      1 736.88\n## - U62317.1        1 736.94\n## &lt;none&gt;              737.00\n## - AC012085.2      1 737.16\n## - `ZNF710-AS1`    1 737.51\n## + `MBNL1-AS1`     1 737.73\n## - `MIR1-1HG-AS1`  1 737.75\n## - AL049555.1      1 737.86\n## - AL023284.4      1 737.87\n## + LINC02657       1 738.05\n## + AC053503.3      1 738.15\n## - `PCCA-DT`       1 738.17\n## + LINC00641       1 738.23\n## + AATBC           1 738.37\n## + U62317.2        1 738.39\n## - AL161431.1      1 738.43\n## + AC002398.2      1 738.44\n## - AP001107.5      1 738.47\n## + MIR205HG        1 738.54\n## + LINC01133       1 738.54\n## + `HAND2-AS1`     1 738.59\n## + `C5orf66-AS1`   1 738.64\n## + `ACTA2-AS1`     1 738.65\n## + CASC9           1 738.66\n## + AC025575.2      1 738.67\n## + LINC01082       1 738.67\n## + MIR200CHG       1 738.67\n## + `KRT7-AS`       1 738.68\n## + `PPP1R14B-AS1`  1 738.75\n## + SNHG25          1 738.78\n## + AC245041.2      1 738.81\n## + MIR22HG         1 738.83\n## + `PGM5-AS1`      1 738.84\n## + AL390719.2      1 738.94\n## + AL162424.1      1 738.94\n## + SNHG12          1 738.94\n## + AC099850.4      1 738.95\n## + `VPS9D1-AS1`    1 738.96\n## + AC020916.1      1 738.97\n## + AC005180.1      1 738.98\n## + `ADAMTS9-AS1`   1 738.99\n## + AC092718.4      1 739.00\n## + AC079313.2      1 739.00\n## + LINC00865       1 739.00\n## + AC008736.1      1 739.00\n## + FENDRR          1 739.00\n## + AC018904.1      1 739.00\n## + AC008735.2      1 739.00\n## - MIR100HG        1 739.18\n## - `SPINT1-AS1`    1 739.36\n## - LINC01980       1 739.45\n## - NR4A1AS         1 740.38\n## - PCAT6           1 740.60\n## - AC093010.3      1 741.07\n## - AC015912.3      1 741.46\n## - AC005180.2      1 744.15\n## \n## Step:  AIC=736.68\n## Surv(time_months, event) ~ AC005180.2 + MIR100HG + AP001107.5 + \n##     NR4A1AS + AF001548.1 + AC093010.3 + PCAT6 + AC012085.2 + \n##     AC036108.3 + AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + \n##     AL445524.1 + LINC01980 + `ZNF710-AS1` + `MAFG-DT` + AL161431.1 + \n##     `PCCA-DT` + U62317.1 + AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - AF001548.1      1 735.87\n## - AL445524.1      1 736.16\n## - `MAFG-DT`       1 736.33\n## - AC012085.2      1 736.38\n## - AC036108.3      1 736.60\n## &lt;none&gt;              736.68\n## - U62317.1        1 736.68\n## + AP003071.4      1 737.00\n## - `MIR1-1HG-AS1`  1 737.32\n## - AL023284.4      1 737.36\n## + LINC02657       1 737.38\n## - `ZNF710-AS1`    1 737.41\n## + `MBNL1-AS1`     1 737.50\n## + `ACTA2-AS1`     1 737.52\n## - AL049555.1      1 737.54\n## - MIR100HG        1 737.56\n## - `PCCA-DT`       1 737.57\n## + LINC00641       1 737.69\n## + AC002398.2      1 737.84\n## + AC053503.3      1 737.89\n## + LINC01133       1 737.93\n## + MIR205HG        1 737.99\n## - AL161431.1      1 738.09\n## + U62317.2        1 738.13\n## + `PGM5-AS1`      1 738.21\n## + AATBC           1 738.24\n## + CASC9           1 738.36\n## + SNHG25          1 738.40\n## + MIR200CHG       1 738.42\n## + `C5orf66-AS1`   1 738.43\n## + `KRT7-AS`       1 738.44\n## + `PPP1R14B-AS1`  1 738.44\n## + MIR22HG         1 738.45\n## + AC025575.2      1 738.47\n## + AC245041.2      1 738.49\n## + SNHG12          1 738.54\n## + FENDRR          1 738.58\n## + AC005180.1      1 738.58\n## - `SPINT1-AS1`    1 738.59\n## + AC099850.4      1 738.62\n## + LINC01082       1 738.62\n## + `HAND2-AS1`     1 738.62\n## + AC008735.2      1 738.63\n## + AL390719.2      1 738.63\n## + AC020916.1      1 738.64\n## + AL162424.1      1 738.66\n## + `VPS9D1-AS1`    1 738.67\n## + AC008736.1      1 738.67\n## + AC092718.4      1 738.67\n## + AC018904.1      1 738.67\n## + AC079313.2      1 738.68\n## + LINC00865       1 738.68\n## + `ADAMTS9-AS1`   1 738.68\n## - LINC01980       1 738.91\n## - PCAT6           1 739.10\n## - AP001107.5      1 739.39\n## - NR4A1AS         1 739.58\n## - AC015912.3      1 740.49\n## - AC093010.3      1 741.04\n## - AC005180.2      1 742.44\n## \n## Step:  AIC=735.87\n## Surv(time_months, event) ~ AC005180.2 + MIR100HG + AP001107.5 + \n##     NR4A1AS + AC093010.3 + PCAT6 + AC012085.2 + AC036108.3 + \n##     AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + AL445524.1 + \n##     LINC01980 + `ZNF710-AS1` + `MAFG-DT` + AL161431.1 + `PCCA-DT` + \n##     U62317.1 + AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - AC012085.2      1 735.36\n## - U62317.1        1 735.45\n## - AL445524.1      1 735.55\n## - `MAFG-DT`       1 735.77\n## &lt;none&gt;              735.87\n## - AL049555.1      1 736.28\n## - `MIR1-1HG-AS1`  1 736.36\n## - `PCCA-DT`       1 736.52\n## - AL023284.4      1 736.52\n## + AF001548.1      1 736.68\n## + AP003071.4      1 736.72\n## - `ZNF710-AS1`    1 736.81\n## + `MBNL1-AS1`     1 736.83\n## + AC002398.2      1 736.84\n## + LINC00641       1 736.87\n## - AL161431.1      1 736.96\n## - MIR100HG        1 736.99\n## + LINC02657       1 737.00\n## + MIR205HG        1 737.07\n## + `ACTA2-AS1`     1 737.09\n## + U62317.2        1 737.09\n## + LINC01133       1 737.25\n## - AC036108.3      1 737.29\n## + `PPP1R14B-AS1`  1 737.44\n## + AATBC           1 737.47\n## + `PGM5-AS1`      1 737.47\n## + MIR200CHG       1 737.50\n## + CASC9           1 737.51\n## + AC005180.1      1 737.53\n## + `C5orf66-AS1`   1 737.55\n## + AC053503.3      1 737.55\n## + `HAND2-AS1`     1 737.55\n## + AC025575.2      1 737.62\n## + `KRT7-AS`       1 737.68\n## + FENDRR          1 737.72\n## + AC245041.2      1 737.73\n## + SNHG25          1 737.74\n## + AC099850.4      1 737.75\n## + MIR22HG         1 737.76\n## + SNHG12          1 737.78\n## + AC079313.2      1 737.80\n## + AC020916.1      1 737.82\n## + `VPS9D1-AS1`    1 737.84\n## + LINC00865       1 737.84\n## + AL390719.2      1 737.85\n## + AC008735.2      1 737.86\n## + AL162424.1      1 737.86\n## + AC008736.1      1 737.86\n## + AC092718.4      1 737.86\n## + LINC01082       1 737.87\n## + `ADAMTS9-AS1`   1 737.87\n## + AC018904.1      1 737.87\n## - LINC01980       1 737.97\n## - PCAT6           1 738.24\n## - AP001107.5      1 738.24\n## - NR4A1AS         1 738.43\n## - `SPINT1-AS1`    1 738.64\n## - AC093010.3      1 740.42\n## - AC015912.3      1 740.55\n## - AC005180.2      1 742.67\n## \n## Step:  AIC=735.36\n## Surv(time_months, event) ~ AC005180.2 + MIR100HG + AP001107.5 + \n##     NR4A1AS + AC093010.3 + PCAT6 + AC036108.3 + AL049555.1 + \n##     `MIR1-1HG-AS1` + `SPINT1-AS1` + AL445524.1 + LINC01980 + \n##     `ZNF710-AS1` + `MAFG-DT` + AL161431.1 + `PCCA-DT` + U62317.1 + \n##     AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## - AL445524.1      1 735.17\n## &lt;none&gt;              735.36\n## - `MAFG-DT`       1 735.44\n## - U62317.1        1 735.50\n## - AC036108.3      1 735.68\n## + AC012085.2      1 735.87\n## + AC002398.2      1 735.99\n## - `PCCA-DT`       1 736.07\n## - AL049555.1      1 736.22\n## + LINC00641       1 736.36\n## - `MIR1-1HG-AS1`  1 736.36\n## + AF001548.1      1 736.38\n## + LINC02657       1 736.44\n## - `ZNF710-AS1`    1 736.44\n## + AP003071.4      1 736.47\n## + `MBNL1-AS1`     1 736.47\n## + LINC01133       1 736.64\n## - MIR100HG        1 736.64\n## + `C5orf66-AS1`   1 736.79\n## - AL161431.1      1 736.83\n## + MIR200CHG       1 736.87\n## + `KRT7-AS`       1 736.89\n## + AATBC           1 736.90\n## + AC025575.2      1 736.98\n## + `ACTA2-AS1`     1 736.98\n## + MIR205HG        1 736.98\n## + `PPP1R14B-AS1`  1 737.05\n## + FENDRR          1 737.13\n## - AL023284.4      1 737.13\n## + AC245041.2      1 737.16\n## + MIR22HG         1 737.19\n## + AC053503.3      1 737.20\n## + SNHG25          1 737.22\n## + U62317.2        1 737.22\n## + `PGM5-AS1`      1 737.25\n## + AC099850.4      1 737.26\n## + `ADAMTS9-AS1`   1 737.26\n## + `HAND2-AS1`     1 737.26\n## + AC008735.2      1 737.27\n## + SNHG12          1 737.30\n## + LINC00865       1 737.30\n## + CASC9           1 737.31\n## + AC018904.1      1 737.32\n## + AC005180.1      1 737.32\n## + AL162424.1      1 737.32\n## + AC079313.2      1 737.34\n## + AL390719.2      1 737.35\n## + AC020916.1      1 737.35\n## + `VPS9D1-AS1`    1 737.35\n## + LINC01082       1 737.35\n## + AC008736.1      1 737.35\n## + AC092718.4      1 737.36\n## - PCAT6           1 737.68\n## - LINC01980       1 737.91\n## - `SPINT1-AS1`    1 738.30\n## - AP001107.5      1 738.37\n## - NR4A1AS         1 738.49\n## - AC015912.3      1 739.63\n## - AC093010.3      1 739.80\n## - AC005180.2      1 741.02\n## \n## Step:  AIC=735.17\n## Surv(time_months, event) ~ AC005180.2 + MIR100HG + AP001107.5 + \n##     NR4A1AS + AC093010.3 + PCAT6 + AC036108.3 + AL049555.1 + \n##     `MIR1-1HG-AS1` + `SPINT1-AS1` + LINC01980 + `ZNF710-AS1` + \n##     `MAFG-DT` + AL161431.1 + `PCCA-DT` + U62317.1 + AL023284.4 + \n##     AC015912.3\n## \n##                  Df    AIC\n## - `MAFG-DT`       1 734.72\n## &lt;none&gt;              735.17\n## + AL445524.1      1 735.36\n## + LINC00641       1 735.38\n## + AC002398.2      1 735.47\n## + AC012085.2      1 735.55\n## - AC036108.3      1 735.64\n## - `ZNF710-AS1`    1 735.71\n## - U62317.1        1 735.94\n## - AL049555.1      1 736.03\n## - `MIR1-1HG-AS1`  1 736.03\n## + AF001548.1      1 736.08\n## + `MBNL1-AS1`     1 736.22\n## + AP003071.4      1 736.45\n## + AATBC           1 736.46\n## + `C5orf66-AS1`   1 736.48\n## - MIR100HG        1 736.55\n## + LINC02657       1 736.57\n## + AC245041.2      1 736.69\n## + AC025575.2      1 736.74\n## + LINC01133       1 736.78\n## + MIR205HG        1 736.83\n## - `PCCA-DT`       1 736.83\n## + MIR200CHG       1 736.89\n## + SNHG25          1 736.89\n## + MIR22HG         1 736.89\n## - AL023284.4      1 736.90\n## + `ACTA2-AS1`     1 736.97\n## + U62317.2        1 736.98\n## + `PPP1R14B-AS1`  1 736.99\n## + `KRT7-AS`       1 736.99\n## + AC008735.2      1 736.99\n## + FENDRR          1 737.01\n## - AL161431.1      1 737.02\n## + `ADAMTS9-AS1`   1 737.02\n## + `PGM5-AS1`      1 737.05\n## + SNHG12          1 737.06\n## + AC099850.4      1 737.06\n## + `HAND2-AS1`     1 737.07\n## + AC053503.3      1 737.09\n## + AC005180.1      1 737.09\n## + CASC9           1 737.12\n## + AC008736.1      1 737.13\n## + AC092718.4      1 737.15\n## + LINC01082       1 737.15\n## + AC020916.1      1 737.16\n## + AL390719.2      1 737.16\n## + LINC00865       1 737.17\n## + AL162424.1      1 737.17\n## + AC079313.2      1 737.17\n## + AC018904.1      1 737.17\n## + `VPS9D1-AS1`    1 737.17\n## - NR4A1AS         1 737.56\n## - PCAT6           1 737.73\n## - LINC01980       1 737.88\n## - `SPINT1-AS1`    1 737.89\n## - AP001107.5      1 737.96\n## - AC093010.3      1 739.15\n## - AC015912.3      1 739.84\n## - AC005180.2      1 740.38\n## \n## Step:  AIC=734.72\n## Surv(time_months, event) ~ AC005180.2 + MIR100HG + AP001107.5 + \n##     NR4A1AS + AC093010.3 + PCAT6 + AC036108.3 + AL049555.1 + \n##     `MIR1-1HG-AS1` + `SPINT1-AS1` + LINC01980 + `ZNF710-AS1` + \n##     AL161431.1 + `PCCA-DT` + U62317.1 + AL023284.4 + AC015912.3\n## \n##                  Df    AIC\n## &lt;none&gt;              734.72\n## + LINC00641       1 734.91\n## + AC012085.2      1 735.01\n## - AL049555.1      1 735.02\n## + AC002398.2      1 735.06\n## - AC036108.3      1 735.12\n## + `MAFG-DT`       1 735.17\n## - `ZNF710-AS1`    1 735.28\n## + AF001548.1      1 735.44\n## + AL445524.1      1 735.44\n## - `MIR1-1HG-AS1`  1 735.54\n## - U62317.1        1 735.76\n## + `C5orf66-AS1`   1 735.89\n## + `MBNL1-AS1`     1 735.91\n## + MIR205HG        1 735.92\n## + AP003071.4      1 735.99\n## - `PCCA-DT`       1 736.08\n## + AATBC           1 736.14\n## + LINC01133       1 736.25\n## + AC099850.4      1 736.27\n## - AL161431.1      1 736.29\n## + AC245041.2      1 736.30\n## + AC008735.2      1 736.34\n## + AC025575.2      1 736.36\n## + SNHG12          1 736.36\n## + MIR200CHG       1 736.42\n## + LINC02657       1 736.46\n## - AL023284.4      1 736.47\n## + `KRT7-AS`       1 736.49\n## + SNHG25          1 736.50\n## + `PPP1R14B-AS1`  1 736.52\n## + `ADAMTS9-AS1`   1 736.53\n## + U62317.2        1 736.53\n## + FENDRR          1 736.56\n## + `ACTA2-AS1`     1 736.60\n## + AC008736.1      1 736.60\n## + `HAND2-AS1`     1 736.60\n## + `PGM5-AS1`      1 736.61\n## + MIR22HG         1 736.61\n## + AL390719.2      1 736.66\n## + `VPS9D1-AS1`    1 736.67\n## + CASC9           1 736.67\n## + AC053503.3      1 736.67\n## + AC005180.1      1 736.68\n## + AL162424.1      1 736.68\n## + LINC01082       1 736.71\n## + AC079313.2      1 736.71\n## + LINC00865       1 736.71\n## + AC092718.4      1 736.71\n## + AC020916.1      1 736.72\n## + AC018904.1      1 736.72\n## - NR4A1AS         1 736.74\n## - MIR100HG        1 736.79\n## - LINC01980       1 736.86\n## - `SPINT1-AS1`    1 736.89\n## - AP001107.5      1 737.71\n## - PCAT6           1 738.00\n## - AC015912.3      1 738.51\n## - AC093010.3      1 739.96\n## - AC005180.2      1 739.97\nsummary(fit.step)\n## Call:\n## coxph(formula = Surv(time_months, event) ~ AC005180.2 + MIR100HG + \n##     AP001107.5 + NR4A1AS + AC093010.3 + PCAT6 + AC036108.3 + \n##     AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + LINC01980 + \n##     `ZNF710-AS1` + AL161431.1 + `PCCA-DT` + U62317.1 + AL023284.4 + \n##     AC015912.3, data = dat.cox)\n## \n##   n= 297, number of events= 71 \n## \n##                    coef exp(coef) se(coef)      z Pr(&gt;|z|)   \n## AC005180.2      0.83728   2.31007  0.30399  2.754  0.00588 **\n## MIR100HG        0.59783   1.81818  0.28762  2.079  0.03766 * \n## AP001107.5     -1.63414   0.19512  0.80039 -2.042  0.04118 * \n## NR4A1AS         0.48095   1.61761  0.22753  2.114  0.03453 * \n## AC093010.3     -0.65126   0.52139  0.24377 -2.672  0.00755 **\n## PCAT6           0.34371   1.41017  0.14756  2.329  0.01985 * \n## AC036108.3      1.48666   4.42231  0.96894  1.534  0.12495   \n## AL049555.1      0.23994   1.27117  0.15931  1.506  0.13203   \n## `MIR1-1HG-AS1` -1.95396   0.14171  1.21419 -1.609  0.10756   \n## `SPINT1-AS1`    0.48314   1.62116  0.23919  2.020  0.04340 * \n## LINC01980      -0.17331   0.84087  0.08564 -2.024  0.04300 * \n## `ZNF710-AS1`   -0.55489   0.57414  0.35644 -1.557  0.11953   \n## AL161431.1      0.17192   1.18758  0.08854  1.942  0.05217 . \n## `PCCA-DT`      -0.35372   0.70207  0.19499 -1.814  0.06966 . \n## U62317.1       -0.20670   0.81326  0.12168 -1.699  0.08937 . \n## AL023284.4     -0.30170   0.73956  0.15674 -1.925  0.05425 . \n## AC015912.3     -0.43266   0.64878  0.18428 -2.348  0.01888 * \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##                exp(coef) exp(-coef) lower .95 upper .95\n## AC005180.2        2.3101     0.4329   1.27311    4.1916\n## MIR100HG          1.8182     0.5500   1.03470    3.1949\n## AP001107.5        0.1951     5.1251   0.04065    0.9367\n## NR4A1AS           1.6176     0.6182   1.03563    2.5266\n## AC093010.3        0.5214     1.9180   0.32334    0.8407\n## PCAT6             1.4102     0.7091   1.05601    1.8831\n## AC036108.3        4.4223     0.2261   0.66204   29.5404\n## AL049555.1        1.2712     0.7867   0.93025    1.7370\n## `MIR1-1HG-AS1`    0.1417     7.0566   0.01312    1.5308\n## `SPINT1-AS1`      1.6212     0.6168   1.01443    2.5908\n## LINC01980         0.8409     1.1892   0.71094    0.9946\n## `ZNF710-AS1`      0.5741     1.7417   0.28551    1.1546\n## AL161431.1        1.1876     0.8420   0.99839    1.4126\n## `PCCA-DT`         0.7021     1.4244   0.47908    1.0288\n## U62317.1          0.8133     1.2296   0.64070    1.0323\n## AL023284.4        0.7396     1.3522   0.54395    1.0055\n## AC015912.3        0.6488     1.5413   0.45211    0.9310\n## \n## Concordance= 0.735  (se = 0.029 )\n## Likelihood ratio test= 54.26  on 17 df,   p=9e-06\n## Wald test            = 47.59  on 17 df,   p=1e-04\n## Score (logrank) test = 51.16  on 17 df,   p=3e-05\n\n最终59个变量剩下17个，筛选效果还不错。\n查看回归系数：\n\nstep.coef &lt;- coef(fit.step)\nstep.coef\n##     AC005180.2       MIR100HG     AP001107.5        NR4A1AS     AC093010.3 \n##      0.8372759      0.5978335     -1.6341403      0.4809485     -0.6512620 \n##          PCAT6     AC036108.3     AL049555.1 `MIR1-1HG-AS1`   `SPINT1-AS1` \n##      0.3437133      1.4866631      0.2399385     -1.9539623      0.4831391 \n##      LINC01980   `ZNF710-AS1`     AL161431.1      `PCCA-DT`       U62317.1 \n##     -0.1733137     -0.5548853      0.1719177     -0.3537250     -0.2067033 \n##     AL023284.4     AC015912.3 \n##     -0.3017031     -0.4326573\n\n提取这17个变量：\n\nstep.lnc &lt;- names(coef(fit.step))\nstep.lnc\n##  [1] \"AC005180.2\"     \"MIR100HG\"       \"AP001107.5\"     \"NR4A1AS\"       \n##  [5] \"AC093010.3\"     \"PCAT6\"          \"AC036108.3\"     \"AL049555.1\"    \n##  [9] \"`MIR1-1HG-AS1`\" \"`SPINT1-AS1`\"   \"LINC01980\"      \"`ZNF710-AS1`\"  \n## [13] \"AL161431.1\"     \"`PCCA-DT`\"      \"U62317.1\"       \"AL023284.4\"    \n## [17] \"AC015912.3\"\n\n简单。"
  },
  {
    "objectID": "feature-selection_randomforest.html#准备数据",
    "href": "feature-selection_randomforest.html#准备数据",
    "title": "14  变量筛选之随机森林",
    "section": "14.1 准备数据",
    "text": "14.1 准备数据\n我们使用TCGA-BLCA的lncRNA数据，其中包括408个样本，time_months是生存时间，event是生存状态，1代表死亡，0代表生存，其余变量都是自变量。\n先简单处理一下数据：\n\nrm(list = ls())\nload(file = \"datasets/lnc_expr_clin.RData\")\n#去掉没有生存信息的样本\nlnc_expr_clin &lt;- lnc_expr_clin[!is.na(lnc_expr_clin$time_months),]\nlnc_expr_clin &lt;- lnc_expr_clin[lnc_expr_clin$time_months&gt;0,]\n\n#选择其中一部分数据\ndat.cox &lt;- lnc_expr_clin[,c(72,1:59)]\n\n#把变量命中的“-”去掉\ncolnames(dat.cox)&lt;- gsub(\"-\",\"\",colnames(dat.cox))\n\n#结果变量变为因子型\ndat.cox$event &lt;- factor(dat.cox$event)\ndim(dat.cox)\n## [1] 297  60\ndat.cox[1:4,1:6]\n##   event    PGM5AS1 LINC01082 AC005180.2 AC005180.1    FENDRR\n## 1     0 0.15064007 0.2642238  0.0000000  0.1547768 0.7802599\n## 2     0 0.06309362 0.1666554  0.3105983  0.2436603 0.7239329\n## 3     1 2.16399508 3.5662920  2.2454129  2.0073496 2.8409939\n## 4     0 2.73075081 1.7314314  0.8609916  0.7323014 1.0531249"
  },
  {
    "objectID": "feature-selection_randomforest.html#建立模型",
    "href": "feature-selection_randomforest.html#建立模型",
    "title": "14  变量筛选之随机森林",
    "section": "14.2 建立模型",
    "text": "14.2 建立模型\n使用经典的randomForest建立随机森林模型：\n\nlibrary(randomForest)\n\nset.seed(124)\nfit &lt;- randomForest(event~., data = dat.cox)\n\nfit\n## \n## Call:\n##  randomForest(formula = event ~ ., data = dat.cox) \n##                Type of random forest: classification\n##                      Number of trees: 500\n## No. of variables tried at each split: 7\n## \n##         OOB estimate of  error rate: 23.91%\n## Confusion matrix:\n##     0 1 class.error\n## 0 225 1 0.004424779\n## 1  70 1 0.985915493\n\n结果给出了树的数量：500颗；OOB错误率：23.91%；还给出了混淆矩阵。"
  },
  {
    "objectID": "feature-selection_randomforest.html#结果探索",
    "href": "feature-selection_randomforest.html#结果探索",
    "title": "14  变量筛选之随机森林",
    "section": "14.3 结果探索",
    "text": "14.3 结果探索\n下面是可视化整体错误率和树的数量的关系，可以看到随着树的数量增加，错误率逐渐降低并渐趋平稳，中间的黑色线条是整体的错误率，上下两条是结果变量中两个类别的错误率。\n\nplot(fit)\n\n\n\n\n可以看到结果有一个类别的错误率竟然是逐渐增加的，因为我们这个数据的存在严重的类不平衡问题，也就是结果变量中的两种类别差异很大：\n\ntable(dat.cox$event)\n## \n##   0   1 \n## 226  71\n\n类别0有226个，类别1只有71个，模型为了提高整体准确率，就会牺牲掉类别为1的准确性~\n查看整体错误率最小时有几棵树：\n\nwhich.min(fit$err.rate[,1])\n## [1] 252\n\n查看各个变量的重要性，这里给出了mean decrease gini，数值越大说明变量越重要：\n\nimportance(fit)\n##             MeanDecreaseGini\n## PGM5AS1            0.9352510\n## LINC01082          1.3866068\n## AC005180.2         1.6168145\n## AC005180.1         1.3488141\n## FENDRR             1.3961145\n## AC053503.3         1.1375051\n## MIR100HG           1.8389235\n## AP001107.5         1.4790429\n## C5orf66AS1         1.9776753\n## NR4A1AS            1.5676917\n## AL162424.1         1.4297710\n## AF001548.1         1.4044652\n## AC099850.4         1.9485050\n## MBNL1AS1           1.7969564\n## ADAMTS9AS1         2.6993467\n## MIR22HG            1.7904790\n## MIR200CHG          2.0379430\n## AC093010.3         2.8789159\n## LINC00865          1.4885762\n## AP003071.4         1.6418555\n## PCAT6              2.0033471\n## LINC02657          2.2435347\n## PPP1R14BAS1        1.8262720\n## AC012085.2         1.3986750\n## ACTA2AS1           1.3608811\n## AC036108.3         1.6392733\n## AC079313.2         1.1854198\n## AC020916.1         1.5358508\n## SNHG25             3.2320090\n## AL049555.1         3.2795519\n## MIR11HGAS1         1.1433175\n## AC018904.1         1.5742751\n## SNHG12             2.9166977\n## SPINT1AS1          2.2857854\n## KRT7AS             2.1031232\n## MIR205HG           1.5659665\n## HAND2AS1           1.9955215\n## AL445524.1         2.2827356\n## LINC01980          1.4518537\n## ZNF710AS1          1.7042160\n## AC092718.4         1.7060641\n## AC008735.2         1.5337512\n## LINC01133          1.2802464\n## AC025575.2         1.5706176\n## MAFGDT             1.9238538\n## CASC9              2.6039129\n## AL390719.2         2.1003651\n## AC002398.2         0.7629889\n## AC008736.1         1.9839028\n## AL161431.1         3.0891759\n## PCCADT             1.5235273\n## AC245041.2         1.9197363\n## U62317.1           1.6662262\n## U62317.2           1.4415305\n## VPS9D1AS1          2.0524334\n## AL023284.4         1.8027226\n## AATBC              2.1357139\n## LINC00641          1.6734872\n## AC015912.3         2.4443188\n\n可视化变量重要性：\n\nvarImpPlot(fit)\n\n\n\n\n通过变量重要性，大家就可以选择比较重要的变量了。你可以选择前5个，前10个，或者大于所有变量性平均值(中位数，百分位数等)的变量等等。"
  },
  {
    "objectID": "feature-selection_randomforest.html#交叉验证变量筛选",
    "href": "feature-selection_randomforest.html#交叉验证变量筛选",
    "title": "14  变量筛选之随机森林",
    "section": "14.4 交叉验证变量筛选",
    "text": "14.4 交叉验证变量筛选\nrandomForest还提供了使用交叉验证法进行递归特征消除，筛选变量的方法：rfcv，下面是使用5折交叉验证进行递归特征消除：\n\nset.seed(647)\nres &lt;- rfcv(trainx = dat.cox[,-1],trainy = dat.cox[,1],\n            cv.fold = 5,\n            recursive = T\n            )\nres$n.var #变量个数\n## [1] 59 30 15  7  4  1\nres$error.cv #错误率\n##        59        30        15         7         4         1 \n## 0.2558923 0.2693603 0.2592593 0.2558923 0.2929293 0.3333333\n\n可以看到在变量个数为7的时候，错误率是最小的(和59一样，但是肯定选简单的)。\n可视化这个结果，很明显变量个数为7(和59)的时候错误率最小：\n\nwith(res, plot(n.var, error.cv, type=\"o\", lwd=2))\n\n\n\n\n结合上面的变量重要性，你可以选择前7个最重要的变量。\n\n\n\n\n\n\n注意\n\n\n\nrfcv得出的变量重要性和randomForest得出的变量重要性并不一样，而且rfcv的结果也并没有明确给出到底哪几个变量才是被选中的。这个方法并不常用，也不推荐大家用~\n参考：stackoverflow"
  },
  {
    "objectID": "feature-selection_randomforest.html#boruta筛选变量",
    "href": "feature-selection_randomforest.html#boruta筛选变量",
    "title": "14  变量筛选之随机森林",
    "section": "14.5 Boruta筛选变量",
    "text": "14.5 Boruta筛选变量\nBoruta是基于随机森林的一种变量筛选方法，它可以基于随机森林的变量重要性计算z-score，然后对每个变量标记确认 or 待定 or 拒绝，从而实现变量筛选。\n这种方法倾向于找到所有与结果变量最相关的变量，所以结果有可能是冗余的(或者存在共线性、相关性)。\n参考文献：Kursa M B, Rudnicki W R. Feature selection with the Boruta package[J]. Journal of statistical software, 2010, 36: 1-13.\n我们还是以这个数据集为例进行演示。\n\nlibrary(Boruta)\n## Warning: package 'Boruta' was built under R version 4.2.3\n\nset.seed(23)\n\nfs &lt;- Boruta(event ~ ., data = dat.cox, doTrace=1)\n## After 13 iterations, +0.9 secs:\n##  rejected 35 attributes: AATBC, AC002398.2, AC008735.2, AC008736.1, AC012085.2 and 30 more;\n##  still have 24 attributes left.\n## After 17 iterations, +0.98 secs:\n##  rejected 2 attributes: KRT7AS, MAFGDT;\n##  still have 22 attributes left.\n## After 21 iterations, +1.1 secs:\n##  confirmed 1 attribute: AL161431.1;\n##  rejected 3 attributes: AC099850.4, AL162424.1, FENDRR;\n##  still have 18 attributes left.\n## After 24 iterations, +1.1 secs:\n##  rejected 1 attribute: AP001107.5;\n##  still have 17 attributes left.\n## After 30 iterations, +1.2 secs:\n##  confirmed 1 attribute: ADAMTS9AS1;\n##  still have 16 attributes left.\n## After 45 iterations, +1.5 secs:\n##  confirmed 1 attribute: SNHG25;\n##  still have 15 attributes left.\n## After 48 iterations, +1.6 secs:\n##  confirmed 2 attributes: AC093010.3, MIR100HG;\n##  still have 13 attributes left.\n## After 63 iterations, +1.9 secs:\n##  confirmed 1 attribute: SPINT1AS1;\n##  still have 12 attributes left.\n## After 71 iterations, +2 secs:\n##  confirmed 1 attribute: HAND2AS1;\n##  still have 11 attributes left.\n\n查看筛选结果，有8个变量确认，7个变量待定，44个变量拒绝：\n\ntable(fs$finalDecision)\n## \n## Tentative Confirmed  Rejected \n##        11         7        41\n\n获取8个确认变量的名字：\n\ngetSelectedAttributes(fs)\n## [1] \"MIR100HG\"   \"ADAMTS9AS1\" \"AC093010.3\" \"SNHG25\"     \"SPINT1AS1\" \n## [6] \"HAND2AS1\"   \"AL161431.1\"\n\n这样就搞定了！用这8个变量重新建立模型即可，当然也可以用用这8个变量建立其他你喜欢的模型，都是可以的。"
  },
  {
    "objectID": "feature-selection_rfe.html#rfeiter",
    "href": "feature-selection_rfe.html#rfeiter",
    "title": "16  递归特征消除",
    "section": "16.1 rfeIter",
    "text": "16.1 rfeIter\n做法如下：\n1. 在训练集中使用所有的预测变量进行建模\n2. 计算模型表现\n3. 计算变量重要性并进行排序\n4. 对每一个样本量大小为S[i]，i = 1,2...,S的子集\n5.    保留S[i]个最重要的变量\n6.    [可选]预处理数据\n7.    用保留的S[i]个变量在训练集中建模\n8.    计算模型表现\n9.    [可选]重新计算变量重要性\n10. 结束\n11. 计算每个子集的模型表现\n12. 决定合适的变量个数（即最优的模型对应的变量）\n13. 使用最优的变量拟合最终的模型"
  },
  {
    "objectID": "feature-selection_rfe.html#交叉验证rfe",
    "href": "feature-selection_rfe.html#交叉验证rfe",
    "title": "16  递归特征消除",
    "section": "16.2 交叉验证rfe",
    "text": "16.2 交叉验证rfe\n单纯的递归特征消除容易出现过拟合问题，所以出现了交叉验证的递归特征消除(rfecv)。rfecv实现了对整个变量选择过程的重抽样，因此可以获得更加准确的结果。\n它的步骤如下：\n1. 对每一次重抽样做以下事情：\n  1. 重抽样把数据划分为训练集/测试集\n  2. 使用训练集中的所有预测变量进行建模\n  3. 计算模型表现\n  4. 计算变量重要性或者排序\n  5. 对每一个样本量大小为S[i]，i = 1,2...,S的子集：\n    1. 保留S[i]个最重要的变量\n    2. [可选]预处理数据\n    3. 用保留的S[i]个变量在训练集中建模\n    4. 在测试集计算模型表现\n    5. [可选]重新计算变量重要性\n  6. 结束\n2. 结束\n3. 在测试集中计算每个子集的模型表现\n4. 决定合适的预测变量数量\n4. 决定最终的预测变量\n5. 用最初的训练集和最终的预测变量拟合最终模型\nrfecv包含两层循环，举个例子，比如最开始的一层循环我们是用10折交叉验证，10折交叉验证把数据分为10份，其中9折用来进行变量选择，剩下的1折用来评估每个变量子集的模型表现。整个变量选择的过程会重复进行10次，最终会得到10个变量子集，选择最好的那个，然后拟合最终的模型。\n说起来蛮复杂的，不理解也问题不大，我知道你们只是想要一个牛逼的结果而已……\n上面这么多步骤只需要rfe函数即可完成，不用担心，简单得很！\n以下是交叉验证递归特征消除的演示，使用rfe函数实现，rfeIter就不演示了。"
  },
  {
    "objectID": "feature-selection_rfe.html#caret实操",
    "href": "feature-selection_rfe.html#caret实操",
    "title": "16  递归特征消除",
    "section": "16.3 caret实操",
    "text": "16.3 caret实操\ncaret支持非常多的模型，可以做递归特征消除，有几个是已经预定义好的，可以写上名字直接用：\n\n线性回归lmFuncs，\n线性判别分析ldaFuncs，\n广义线性模型gamFuncs\n逻辑回归lrFuncs\n随机森林rfFuncs，\n朴素贝叶斯nbFuncs，\n袋装树treebagFuncs\n\n除此之外，所有train()函数可以用的模型，都能做递归特征消除。下面会演示用法。如果你不知道train能用的模型有哪些，参考这篇推文：caret可视化\ncaret中通过rfe实现交叉验证的递归特征消除，rfe函数有几个主要的参数：\n\nx：预测变量，可以是矩阵或者数据框\ny：结果变量，需要数值型或者因子型向量，a vector (numeric or factor) of outcomes\nsizes：整数型向量，每次迭代留下的重要性比较高的特征数量，结合下面的例子理解\nmetric：模型评价指标，分类默认Accuracy和Kappa，回归默认RMSE和MAE\nrfecontrol：选择算法，重抽样方法等\n\n用caret自带的BloodBrain数据集进行演示。\nMente和Lombardo(2005)开发了预测大脑中化合物浓度与血液中化合物浓度比值对数的模型。对于每一种化合物，他们计算了三组描述分子的变量:MOE 2D、rule-of-five和Charge Polar Surface Area (CPSA)。\n其中数据集bbbDescr总共有134列(134个描述分子性质的预测变量)，208行(208个分子化合物)。向量logBBB是浓度比值的对数，是结果变量。\n\nlibrary(caret)\n## Loading required package: ggplot2\n## Warning: package 'ggplot2' was built under R version 4.2.3\n## Loading required package: lattice\n\n# 加载后会在当前环境下出现自变量数据框bbbDescr，因变量是logBBB\ndata(BloodBrain)\n\npsych::headTail(bbbDescr)\n##      tpsa nbasic negative vsa_hyd a_aro weight peoe_vsa.0 peoe_vsa.1 peoe_vsa.2\n## 1   12.03      1        0  167.07     0 156.29      76.95      43.45          0\n## 2   49.33      0        0   92.64     6 151.16      38.24      25.52          0\n## 3   50.53      1        0  295.17    15 366.48      58.05     124.74      21.65\n## 4   37.39      0        0  319.11    15 382.55      62.24     124.74      13.19\n## ...   ...    ...      ...     ...   ...    ...        ...        ...        ...\n## 205  3.24      0        0  343.24    10 292.45       40.6     104.68      13.19\n## 206 32.34      1        0  234.79     6 261.39      75.12      86.67          0\n## 207  37.3      0        0  124.26     0 143.21      63.98      14.71          0\n## 208 64.43      0        0  224.75    10 319.38      74.42      43.65      29.69\n##     peoe_vsa.3 peoe_vsa.4 peoe_vsa.5 peoe_vsa.6 peoe_vsa.0.1 peoe_vsa.1.1\n## 1            0          0          0      17.24        18.75        43.51\n## 2         8.62      23.27          0          0        49.02            0\n## 3         8.62      17.44          0       8.62        83.82        49.02\n## 4        21.79          0          0       8.62        83.82        68.78\n## ...        ...        ...        ...        ...          ...          ...\n## 205          0          0          0       8.62        85.17        117.4\n## 206       8.62      12.95          0       8.62        34.07        62.01\n## 207          0          0          0          0         17.4         54.9\n## 208        6.7          0      12.95      14.71        82.73        19.76\n##     peoe_vsa.2.1 peoe_vsa.3.1 peoe_vsa.4.1 peoe_vsa.5.1 peoe_vsa.6.1 a_acc\n## 1              0            0            0            0            0     0\n## 2              0            0            0        13.57          7.9     2\n## 3              0            0         5.68          2.5         2.64     2\n## 4              0            0         5.68            0         2.64     2\n## ...          ...          ...          ...          ...          ...   ...\n## 205            0            0            0            0            0     0\n## 206            0            0            0        13.57         0.14     1\n## 207            0            0            0            0        27.13     0\n## 208            0            0         5.68        27.13          2.5     4\n##     a_acid a_base vsa_acc vsa_acid vsa_base vsa_don vsa_other vsa_pol\n## 1        0      1       0        0     5.68    5.68         0       0\n## 2        0      0   13.57        0        0    5.68     28.11   13.57\n## 3        0      1    8.19        0        0    5.68     43.56       0\n## 4        0      1    8.19        0        0    5.68     28.32       0\n## ...    ...    ...     ...      ...      ...     ...       ...     ...\n## 205      0      1       0        0        0       0         0       0\n## 206      0      1   13.57        0        0    5.68     19.65       0\n## 207      2      0   27.13    27.13        0       0     14.71       0\n## 208      0      0   35.32        0        0       0     47.76       0\n##     slogp_vsa0 slogp_vsa1 slogp_vsa2 slogp_vsa3 slogp_vsa4 slogp_vsa5\n## 1        18.01          0       3.98          0       4.41       32.9\n## 2        25.39      23.27      23.86          0          0          0\n## 3        14.12       34.8          0      76.25       3.19       9.51\n## 4        14.12       34.8          0      76.25       3.19          0\n## ...        ...        ...        ...        ...        ...        ...\n## 205       3.12          0          0       52.5       3.19       32.9\n## 206       3.12      23.27      23.86      55.32       6.37      37.74\n## 207      42.68       1.46      23.86          0       4.41          0\n## 208          0      34.81         11          0       54.6       32.9\n##     slogp_vsa6 slogp_vsa7 slogp_vsa8 slogp_vsa9 smr_vsa0 smr_vsa1 smr_vsa2\n## 1            0          0     113.21      33.33        0    18.01     4.41\n## 2            0      70.57          0      41.33    23.86    25.39        0\n## 3            0     148.13      75.47      28.27    12.63    27.79        0\n## 4            0     144.04      75.47      55.46     3.12    27.79        0\n## ...        ...        ...        ...        ...      ...      ...      ...\n## 205          0     163.93          0     118.42     3.12        0        0\n## 206          0      52.93      37.74      69.41    26.99        0        0\n## 207          0          0      75.47      66.65    66.55        0     4.41\n## 208          0         53          0      149.7    58.72    21.81        0\n##     smr_vsa3 smr_vsa4 smr_vsa5 smr_vsa6 smr_vsa7 tpsa.1 logp.o.w. frac.anion7.\n## 1       3.98        0   113.21        0    66.22  16.61      2.95            0\n## 2       5.24    20.77    70.57     5.26    33.33  49.33      0.89            0\n## 3       8.43    29.58   235.06    76.25        0  51.73      4.44            0\n## 4       8.43     21.4   235.06    76.25    31.28  38.59      5.25            0\n## ...      ...      ...      ...      ...      ...    ...       ...          ...\n## 205    37.25     5.15   177.23    18.44   132.88   4.44      5.89            0\n## 206     6.37    20.77    128.4    60.58    66.65  33.54      3.02            0\n## 207        0        0    75.47     1.46    66.65  40.13      2.65         0.99\n## 208     6.87     2.76    68.68       13   164.15  64.43       1.6            0\n##     frac.cation7. andrewbind rotatablebonds mlogp clogp     mw nocount hbdnr\n## 1               1        3.4              3   2.5  2.97 155.29       1     1\n## 2               0       -3.3              2  1.06  0.49 151.17       3     2\n## 3            0.99       12.8              8  4.66  5.14 365.48       5     1\n## 4            0.99       12.8              8  3.82  5.88 381.54       4     1\n## ...           ...        ...            ...   ...   ...    ...     ...   ...\n## 205          0.54        7.3              6  4.98  5.96 291.44       1     0\n## 206             1        8.6              7  2.63   2.8 260.38       3     1\n## 207             0       -3.7              5  2.06  2.76 144.22       2     1\n## 208             0        6.2              3  1.66  1.36 319.39       6     0\n##     rule.of.5violations alert prx  ub pol inthb  adistm adistd polar_area\n## 1                     0     0   0   0   0     0       0      0      21.12\n## 2                     0     0   1   3   2     0  395.38  10.89     117.41\n## 3                     1     0   6 5.3   3     0 1364.55  25.68      82.09\n## 4                     1     0   2 5.3   3     0  702.64  10.02      65.09\n## ...                 ...   ... ... ... ...   ...     ...    ...        ...\n## 205                   1     0   0 4.7   0     0       0      0       4.67\n## 206                   0     0   1   3   1     0  419.76   8.41      93.71\n## 207                   0     0   2   1   0     0  101.76  20.84      76.85\n## 208                   0     0   5 4.7   2     0 1208.28  43.16      73.62\n##     nonpolar_area psa_npsa tcsa tcpa tcnp ovality surface_area  volume\n## 1          379.07     0.06 0.01 0.18 0.01     1.1       400.19  656.07\n## 2          247.54     0.47 0.01 0.04 0.02    1.12       364.95   555.1\n## 3          637.72     0.13 0.01  0.1 0.01     1.3       719.82 1224.46\n## 4          667.97      0.1 0.01 0.12 0.01     1.3       733.06  1257.2\n## ...           ...      ...  ...  ...  ...     ...          ...     ...\n## 205        623.48     0.01 0.01 1.09 0.01    1.24       628.14 1072.64\n## 206         452.7     0.21 0.01 0.07 0.01    1.18       546.41  931.18\n## 207        292.74     0.26 0.01 0.05 0.01    1.09       369.58  586.54\n## 208        482.03     0.15 0.01  0.1 0.01    1.18       555.65  959.84\n##     most_negative_charge most_positive_charge sum_absolute_charge dipole_moment\n## 1                  -0.62                 0.31                3.89          1.19\n## 2                  -0.84                  0.5                4.89          4.21\n## 3                   -0.8                 0.54                7.98          3.52\n## 4                  -0.76                 0.48                7.93          3.15\n## ...                  ...                  ...                 ...           ...\n## 205                 -0.4                 0.14                 5.1          0.49\n## 206                 -0.8                  0.5                6.66          4.14\n## 207                -0.51                 0.41                4.21          1.61\n## 208                -0.77                 0.59                7.13          2.93\n##      homo  lumo hardness  ppsa1   ppsa2 ppsa3  pnsa1   pnsa2  pnsa3 fpsa1 fpsa2\n## 1   -9.67   3.4     6.54 349.14  679.38 30.97  51.06  -99.35 -10.49  0.87   1.7\n## 2   -8.96  0.19     4.58 223.13  545.83  42.3 141.81 -346.91 -44.04  0.61   1.5\n## 3   -8.63  0.06     4.34 517.82 2066.02 63.95    202 -805.93 -43.76  0.72  2.87\n## 4   -8.56 -0.27     4.15 507.61 2012.91 61.69 225.45 -893.99 -42.03  0.69  2.75\n## ...   ...   ...      ...    ...     ...   ...    ...     ...    ...   ...   ...\n## 205 -8.72 -0.36     4.18 443.86 1132.32 45.54 184.28 -470.11 -24.72  0.71   1.8\n## 206 -9.08   0.1     4.59 382.32 1272.66 48.96 164.09 -546.24 -44.86   0.7  2.33\n## 207 -10.9  1.31     6.11  287.3  604.89 34.14  82.28 -173.23 -27.97  0.78  1.64\n## 208 -9.65 -1.21     4.22 407.36  1453.1 47.58 148.29 -528.97 -38.48  0.73  2.62\n##     fpsa3 fnsa1 fnsa2 fnsa3  wpsa1   wpsa2 wpsa3  wnsa1   wnsa2  wnsa3  dpsa1\n## 1    0.08  0.13 -0.25 -0.03 139.72  271.89 12.39  20.43  -39.76   -4.2 298.08\n## 2    0.12  0.39 -0.95 -0.12  81.43   199.2 15.44  51.75  -126.6 -16.07  81.32\n## 3    0.09  0.28 -1.12 -0.06 372.74 1487.16 46.03  145.4 -580.12  -31.5 315.83\n## 4    0.08  0.31 -1.22 -0.06 372.11 1475.58 45.22 165.27 -655.35 -30.81 282.17\n## ...   ...   ...   ...   ...    ...     ...   ...    ...     ...    ...    ...\n## 205  0.07  0.29 -0.75 -0.04 278.81  711.26  28.6 115.75  -295.3 -15.53 259.58\n## 206  0.09   0.3    -1 -0.08  208.9  695.39 26.75  89.66 -298.47 -24.51 218.22\n## 207  0.09  0.22 -0.47 -0.08 106.18  223.56 12.62  30.41  -64.02 -10.34 205.03\n## 208  0.09  0.27 -0.95 -0.07 226.35  807.42 26.44   82.4 -293.92 -21.38 259.07\n##       dpsa2  dpsa3 rpcg rncg wpcs wncs sadh1 sadh2 sadh3 chdh1 chdh2 chdh3\n## 1    778.73  41.46 0.16 0.32 2.38 1.91  15.1  15.1  0.04  0.31  0.31     0\n## 2    892.75  86.34  0.2 0.34 1.31 2.25 45.22 22.61  0.12   0.8   0.4     0\n## 3   2871.95 107.71 0.14  0.2 1.14 1.57 16.72 16.72  0.02  0.46  0.46     0\n## 4   2906.89 103.72 0.12 0.19 0.76 1.53 17.25 17.25  0.02  0.44  0.44     0\n## ...     ...    ...  ...  ...  ...  ...   ...   ...   ...   ...   ...   ...\n## 205 1602.43  70.26 0.06 0.16 1.15 0.73     0     0     0     0     0     0\n## 206 1818.89  93.82 0.15 0.24  1.3 2.66 23.17 23.17  0.04  0.43  0.43     0\n## 207  778.12  62.11 0.19 0.24 0.86 3.84  30.8  30.8  0.08   0.4   0.4     0\n## 208 1982.08  86.06 0.16 0.22 0.92 0.13     0     0     0     0     0     0\n##     scdh1 scdh2 scdh3 saaa1 saaa2 saaa3 chaa1 chaa2 chaa3  scaa1  scaa2 scaa3\n## 1    4.63  4.63  0.01  6.03  6.03  0.02 -0.62 -0.62     0  -3.72  -3.72 -0.01\n## 2   17.62  8.81  0.05 65.62 32.81  0.18 -0.84 -0.42     0 -27.51 -13.76 -0.08\n## 3    7.61  7.61  0.01 57.54 14.39  0.08 -1.37 -0.34     0 -21.79  -5.45 -0.03\n## 4    7.51  7.51  0.01 39.86 13.29  0.05 -1.23 -0.41     0  -17.6  -5.87 -0.02\n## ...   ...   ...   ...   ...   ...   ...   ...   ...   ...    ...    ...   ...\n## 205     0     0     0  4.67  4.67  0.01  -0.4  -0.4     0  -1.86  -1.86     0\n## 206  9.97  9.97  0.02 59.43 29.72  0.11 -0.79 -0.39     0 -22.21 -11.11 -0.04\n## 207 12.34 12.34  0.03 46.05 23.02  0.12 -0.93 -0.46     0 -20.72 -10.36 -0.06\n## 208     0     0     0 71.59  17.9  0.13  -1.4 -0.35     0 -24.58  -6.14 -0.04\n##     ctdh ctaa mchg achg rdta n_sp2 n_sp3 o_sp2 o_sp3\n## 1      1    1 0.92 0.92    1     0  6.03     0     0\n## 2      2    2 1.27 1.04    1     0  6.57 32.01 33.61\n## 3      1    4 1.26 1.26 0.25 26.97 10.86     0 27.55\n## 4      1    3  1.2  1.2 0.33 21.71    11     0 15.13\n## ...  ...  ...  ...  ...  ...   ...   ...   ...   ...\n## 205    0    1    0    0    0     0  4.67     0     0\n## 206    1    2 1.23 1.23  0.5     0 16.18 54.36     0\n## 207    1    2 0.91 0.91  0.5     0     0  30.1 15.94\n## 208    0    4    0    0    0 26.67  2.03 40.46  4.47\nhead(logBBB)\n## [1]  1.08 -0.40  0.22  0.14  0.69  0.44\n\n首先对这个数据做一下数据预处理，如果你看不懂下面这段代码，强烈建议你先看前面的推文：R语言机器学习caret-02：数据预处理\n\nx &lt;- scale(bbbDescr[,-nearZeroVar(bbbDescr)])\nx &lt;- x[, -findCorrelation(cor(x), .8)]\nx &lt;- as.data.frame(x, stringsAsFactors = TRUE)\npsych::headTail(x)\n##     nbasic peoe_vsa.0 peoe_vsa.1 peoe_vsa.2 peoe_vsa.3 peoe_vsa.4 peoe_vsa.5\n## 1     1.31        0.4      -0.81      -0.88      -0.76      -0.63      -0.56\n## 2    -0.76      -0.72      -1.25      -0.88      -0.16        1.9      -0.56\n## 3     1.31      -0.15       1.22       0.39      -0.16       1.27      -0.56\n## 4    -0.76      -0.03       1.22       -0.1       0.74      -0.63      -0.56\n## ...    ...        ...        ...        ...        ...        ...        ...\n## 205  -0.76      -0.66       0.72       -0.1      -0.76      -0.63      -0.56\n## 206   1.31       0.35       0.27      -0.88      -0.16       0.78      -0.56\n## 207  -0.76       0.02      -1.52      -0.88      -0.76      -0.63      -0.56\n## 208  -0.76       0.33       -0.8       0.87      -0.29      -0.63       1.27\n##     peoe_vsa.6 peoe_vsa.0.1 peoe_vsa.1.1 peoe_vsa.4.1 peoe_vsa.5.1 peoe_vsa.6.1\n## 1         0.07         -0.9        -0.29        -0.61        -0.81        -0.69\n## 2         -1.3         0.16        -1.36        -0.61         0.51         0.16\n## 3        -0.62         1.38        -0.16         0.24        -0.56        -0.41\n## 4        -0.62         1.38         0.32         0.24        -0.81        -0.41\n## ...        ...          ...          ...          ...          ...          ...\n## 205      -0.62         1.42         1.51        -0.61        -0.81        -0.69\n## 206      -0.62        -0.36         0.16        -0.61         0.51        -0.68\n## 207       -1.3        -0.95        -0.02        -0.61        -0.81         2.24\n## 208      -0.13         1.34        -0.87         0.24         1.83        -0.42\n##     a_acc a_base vsa_base vsa_other vsa_pol slogp_vsa0 slogp_vsa1 slogp_vsa2\n## 1   -1.45  -0.14     0.04     -1.74   -0.51      -0.55      -1.13      -0.66\n## 2   -0.06  -1.04    -0.58      0.08    1.51      -0.24        0.3       0.43\n## 3   -0.06  -0.14    -0.58      1.08   -0.51      -0.71       1.01      -0.87\n## 4   -0.06  -0.14    -0.58       0.1   -0.51      -0.71       1.01      -0.87\n## ...   ...    ...      ...       ...     ...        ...        ...        ...\n## 205 -1.45  -0.14    -0.58     -1.74   -0.51      -1.17      -1.13      -0.87\n## 206 -0.75  -0.14    -0.58     -0.47   -0.51      -1.17        0.3       0.43\n## 207 -1.45  -1.04    -0.58     -0.78   -0.51       0.48      -1.04       0.43\n## 208  1.33  -1.04    -0.58      1.35   -0.51       -1.3       1.01      -0.27\n##     slogp_vsa4 slogp_vsa5 slogp_vsa6 slogp_vsa8 slogp_vsa9 smr_vsa0 smr_vsa1\n## 1        -0.46       0.13      -0.51       2.67      -0.64    -0.99    -0.41\n## 2        -0.85      -0.98      -0.51      -0.93      -0.45    -0.06    -0.14\n## 3        -0.57      -0.66      -0.51       1.47      -0.76     -0.5    -0.06\n## 4        -0.57      -0.98      -0.51       1.47      -0.11    -0.87    -0.06\n## ...        ...        ...        ...        ...        ...      ...      ...\n## 205      -0.57       0.13      -0.51      -0.93       1.38    -0.87    -1.07\n## 206      -0.29        0.3      -0.51       0.27       0.22     0.06    -1.07\n## 207      -0.46      -0.98      -0.51       1.47       0.15     1.59    -1.07\n## 208       3.91       0.13      -0.51      -0.93       2.12     1.29    -0.27\n##     smr_vsa2 smr_vsa3 smr_vsa4 smr_vsa6 smr_vsa7 frac.cation7. andrewbind\n## 1       -0.5    -0.87    -0.64    -1.21    -0.01          0.81      -0.98\n## 2      -0.74    -0.74     0.95    -1.03    -0.78         -1.39      -2.02\n## 3      -0.74     -0.4     1.62     1.42    -1.57          0.78       0.48\n## 4      -0.74     -0.4        1     1.42    -0.83          0.78       0.48\n## ...      ...      ...      ...      ...      ...           ...        ...\n## 205    -0.74     2.63    -0.25    -0.58     1.55          -0.2      -0.38\n## 206    -0.74    -0.62     0.95     0.88        0           0.8      -0.18\n## 207     -0.5    -1.29    -0.64    -1.16        0         -1.39      -2.09\n## 208    -0.74    -0.57    -0.43    -0.76     2.29         -1.39      -0.55\n##     rotatablebonds mlogp clogp rule.of.5violations   prx    ub   pol inthb\n## 1            -0.54 -0.19  0.15               -0.48 -1.01 -3.27 -1.36 -0.24\n## 2            -0.86 -1.44 -1.18               -0.48 -0.67 -0.94  0.19 -0.24\n## 3             1.09  1.67  1.32                1.69  1.01  0.85  0.97 -0.24\n## 4             1.09  0.95  1.72                1.69 -0.34  0.85  0.97 -0.24\n## ...            ...   ...   ...                 ...   ...   ...   ...   ...\n## 205           0.44  1.95  1.77                1.69 -1.01  0.39 -1.36 -0.24\n## 206           0.76 -0.08  0.06               -0.48 -0.67 -0.94 -0.58 -0.24\n## 207           0.11 -0.57  0.04               -0.48 -0.34 -2.49 -1.36 -0.24\n## 208          -0.54 -0.92 -0.71               -0.48  0.67  0.39  0.19 -0.24\n##     adistd  tcsa  tcpa ovality most_negative_charge most_positive_charge\n## 1     -0.9 -1.03  0.16   -1.47                 0.54                -0.93\n## 2    -0.59   0.2 -0.41   -1.13                -0.53                -0.14\n## 3    -0.16 -0.57 -0.19    1.83                -0.35                 0.04\n## 4    -0.61 -0.67 -0.09    1.84                -0.15                -0.21\n## ...    ...   ...   ...     ...                  ...                  ...\n## 205   -0.9 -1.56  3.82    0.84                 1.59                 -1.6\n## 206  -0.66  -0.2  -0.3   -0.04                -0.33                -0.11\n## 207   -0.3 -0.47 -0.36   -1.56                 1.07                -0.52\n## 208   0.34     0 -0.19    -0.1                -0.19                 0.23\n##     dipole_moment  homo  lumo hardness pnsa1 fpsa3 fnsa1 fnsa2  rpcg  rncg\n## 1           -1.17 -0.96  6.88     5.08 -2.48 -0.63 -2.47  2.15  0.14   1.5\n## 2            0.63   0.1   0.7     0.36 -0.92  1.35  0.44  0.64  0.98  1.88\n## 3            0.22   0.6  0.44    -0.21  0.12 -0.04 -0.76  0.28 -0.26 -0.19\n## 4           -0.01   0.7 -0.18    -0.68  0.52 -0.28 -0.46  0.06 -0.53 -0.32\n## ...           ...   ...   ...      ...   ...   ...   ...   ...   ...   ...\n## 205         -1.58  0.46 -0.37     -0.6 -0.19 -0.88 -0.62  1.08 -1.72 -0.83\n## 206          0.58 -0.08  0.52     0.39 -0.53     0 -0.54  0.54  0.03  0.37\n## 207         -0.92 -2.82  2.85     4.05 -1.94  0.14 -1.41  1.68  0.79   0.4\n## 208         -0.13 -0.93    -2     -0.5 -0.81 -0.21 -0.92  0.64  0.26  0.02\n##      wpcs  wncs sadh2 saaa2 chaa2 chaa3  achg  rdta n_sp2 n_sp3 o_sp2 o_sp3\n## 1    0.97 -0.08  0.13 -1.36 -1.52  0.77  0.15   0.7 -0.68 -0.47 -0.83 -0.69\n## 2    0.08  0.07  0.93  1.54  0.05 -0.15  0.39   0.7 -0.68 -0.41  0.09  1.32\n## 3   -0.07 -0.22   0.3 -0.46  0.65  0.31  0.84 -0.57  0.78  0.02 -0.83  0.96\n## 4   -0.38 -0.24  0.36 -0.58  0.11  0.54  0.71 -0.42   0.5  0.03 -0.83  0.21\n## ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...\n## 205 -0.06 -0.59 -1.48 -1.51   0.2  1.81 -1.78 -0.99 -0.68  -0.6 -0.83 -0.69\n## 206  0.07  0.25  0.99   1.2  0.25  0.89  0.78 -0.14 -0.68  0.56  0.74 -0.69\n## 207  -0.3  0.76   1.8  0.48 -0.31 -0.38  0.11 -0.14 -0.68 -1.08  0.04  0.26\n## 208 -0.24 -0.85 -1.48 -0.08  0.59 -0.38 -1.78 -0.99  0.76 -0.87  0.34 -0.43\n\n\n16.3.1 线性回归\n接下来演示一个基于线性回归的递归特征消除，数据量少选择自助法比较好，重抽样方法选择也是一门学问，可以参考之前的推文：临床预测模型和机器学习中的重抽样问题\n\n# 加速\nlibrary(future)\n## Warning: package 'future' was built under R version 4.2.3\n## \n## Attaching package: 'future'\n## The following object is masked from 'package:caret':\n## \n##     cluster\nplan(\"multisession\",workers=8)\n\n# 设置rfe的选项\nset.seed(1)\nrfeControl = rfeControl(functions = lmFuncs,\n                        method = \"cv\", # 默认自助法重采样 boot\n                        saveDetails = T, # 保存预测值和变量重要性\n                        number = 5, # 重抽样次数\n                        allowParallel = T # 允许多线程，用这个之前你要先准备好多线程！\n                        )\n\n定义好之后，下面是正式进行特征选择：\nsizes这么理解：这里如果设置为sizes = c(1:71)，意思就是我们要在所有的变量子集中寻找最优的，一共只有71个预测变量，就是要在1,2,3，。。。，71，每一个数量的变量子集都要试一下。\n\nset.seed(1)\nlmProfile &lt;- rfe(x, logBBB,\n                 sizes = c(2:25, 30, 35, 40, 45, 50, 55, 60, 65),\n                 rfeControl = rfeControl\n                 )\n\n运行结束之后，即可查看结果：\n\n# 查看运行结果\nlmProfile\n## \n## Recursive feature selection\n## \n## Outer resampling method: Cross-Validated (5 fold) \n## \n## Resampling performance over subset size:\n## \n##  Variables   RMSE Rsquared    MAE  RMSESD RsquaredSD   MAESD Selected\n##          2 0.7820  0.01385 0.6135 0.04318    0.01540 0.04276         \n##          3 0.7917  0.04226 0.6235 0.04771    0.06134 0.04531         \n##          4 0.7801  0.06268 0.6101 0.06865    0.09728 0.05553         \n##          5 0.7495  0.11827 0.5840 0.08888    0.16112 0.06200         \n##          6 0.7377  0.13665 0.5716 0.08566    0.16106 0.06741         \n##          7 0.7309  0.15437 0.5700 0.05845    0.08013 0.03619         \n##          8 0.7153  0.18904 0.5546 0.06004    0.09937 0.02895         \n##          9 0.6984  0.22469 0.5471 0.07742    0.12875 0.05199         \n##         10 0.6976  0.22220 0.5511 0.07632    0.12143 0.05549         \n##         11 0.6694  0.28289 0.5244 0.06061    0.06490 0.03248         \n##         12 0.6648  0.29297 0.5242 0.05517    0.05391 0.02942         \n##         13 0.6642  0.29852 0.5250 0.06342    0.07266 0.03543         \n##         14 0.6531  0.32167 0.5137 0.08665    0.12619 0.05820         \n##         15 0.6584  0.32371 0.5089 0.08956    0.13920 0.05879         \n##         16 0.6423  0.35466 0.4944 0.10306    0.15733 0.08299         \n##         17 0.6532  0.34422 0.5054 0.10736    0.14515 0.08796         \n##         18 0.6525  0.35123 0.5032 0.11508    0.15685 0.09495         \n##         19 0.6546  0.34789 0.5007 0.10632    0.14159 0.09047         \n##         20 0.6341  0.37890 0.4858 0.07458    0.08931 0.06239         \n##         21 0.6359  0.37810 0.4873 0.07951    0.09254 0.06605         \n##         22 0.6288  0.39270 0.4838 0.08384    0.09001 0.06214        *\n##         23 0.6313  0.38975 0.4870 0.08167    0.08728 0.06092         \n##         24 0.6408  0.37938 0.4939 0.07783    0.07434 0.06306         \n##         25 0.6395  0.37862 0.4920 0.07773    0.07582 0.06751         \n##         30 0.6983  0.32262 0.5157 0.09891    0.09837 0.07248         \n##         35 0.7193  0.29867 0.5234 0.10489    0.09395 0.08779         \n##         40 0.7079  0.33202 0.5195 0.10378    0.09336 0.07573         \n##         45 0.7518  0.29916 0.5602 0.07306    0.06445 0.05038         \n##         50 0.7484  0.30170 0.5592 0.07480    0.05449 0.05324         \n##         55 0.7477  0.31832 0.5532 0.09521    0.08273 0.06976         \n##         60 0.7661  0.30018 0.5661 0.08239    0.05746 0.06844         \n##         65 0.7624  0.30845 0.5688 0.08959    0.07645 0.07412         \n##         71 0.7598  0.30810 0.5658 0.08384    0.07334 0.06893         \n## \n## The top 5 variables (out of 22):\n##    hardness, homo, lumo, pnsa1, fnsa2\n\n结果告诉我们很多信息，比如外层循环使用的重抽样方法是Bootstrapped；\n然后给出了不同数量的特征子集的模型表现，Variables这一列是使用的特征数量，可以看到最后有个71特征，明明我们设置的特征数量是sizes = c(2:25, 30, 35, 40, 45, 50, 55, 60, 65)，最多就是65，为啥会有71呢？因为你看上面那个步骤，在最开始都是要用全部特征拟合模型的！\n剩下的几列是模型性能指标，最后一列Selected是选中的模型，有*的就是被选中的，特征数量是22个。此时的RMSE是0.6288，Rsquared是0.39270。\n最后给出了前5个选中的变量。\n通过以下代码查看选中的22个变量是哪些：\n\n# 查看选中的变量\npredictors(lmProfile)\n##  [1] \"hardness\"             \"homo\"                 \"lumo\"                \n##  [4] \"pnsa1\"                \"fnsa2\"                \"o_sp2\"               \n##  [7] \"fnsa1\"                \"peoe_vsa.5.1\"         \"a_base\"              \n## [10] \"most_positive_charge\" \"vsa_base\"             \"rotatablebonds\"      \n## [13] \"peoe_vsa.6\"           \"peoe_vsa.6.1\"         \"rpcg\"                \n## [16] \"peoe_vsa.1\"           \"vsa_other\"            \"smr_vsa0\"            \n## [19] \"ovality\"              \"rdta\"                 \"fpsa3\"               \n## [22] \"clogp\"\n\n清楚明白！\n结果也可以使用图形方式查看：\n\nggplot(data = lmProfile, metric = \"RMSE\") + theme_bw()\n\n\n\n\n\nggplot(data = lmProfile, metric = \"MAE\") + theme_bw()\n\n\n\n\n查看变量重要性：\n\nvarImp(lmProfile)\n##                          Overall\n## hardness             307.2096022\n## homo                 246.7418439\n## lumo                 192.4442402\n## pnsa1                  0.9009845\n## fnsa1                  0.6431244\n## o_sp2                  0.6270888\n## peoe_vsa.5.1           0.5879659\n## fnsa2                  0.5682413\n## most_positive_charge   0.5538182\n## rdta                   0.5436882\n## prx                    0.5390927\n## andrewbind             0.5334340\n## vsa_base               0.5084030\n## peoe_vsa.1             0.5020039\n## rotatablebonds         0.4785500\n## a_base                 0.4717276\n## tcsa                   0.4636548\n## mlogp                  0.4626432\n## peoe_vsa.6.1           0.4526228\n## vsa_other              0.4465362\n## ovality                0.4464361\n## fpsa3                  0.4400715\n## rpcg                   0.4293029\n## peoe_vsa.6             0.4221961\n## smr_vsa0               0.4015024\n## adistd                 0.3485839\n## slogp_vsa5             0.3426358\n## clogp                  0.3399694\n## chaa2                  0.3298837\n## peoe_vsa.4.1           0.3285177\n## peoe_vsa.5             0.3219318\n## wncs                   0.3124847\n## smr_vsa4               0.3119868\n## ub                     0.3096761\n## slogp_vsa9             0.3094456\n## frac.cation7.          0.3013126\n## chaa3                  0.2795578\n## most_negative_charge   0.2775598\n## peoe_vsa.3             0.2765230\n## o_sp3                  0.2750614\n## n_sp2                  0.2535690\n## smr_vsa7               0.2404868\n## n_sp3                  0.2091113\n## peoe_vsa.1.1           0.2014472\n\n只看数字不够直观，可以把变量重要性画图展示，方法非常简单：\n\nvarimp_data &lt;- data.frame(feature = row.names(varImp(lmProfile))[1:22],\n                          importance = varImp(lmProfile)[1:22, 1])\n\nggplot(data = varimp_data, aes(x = reorder(feature, -importance), \n                               y = importance, fill = feature)) +\n  geom_bar(stat=\"identity\") + \n  labs(x = \"Features\", y = \"Variable Importance\") + \n  geom_text(aes(label = round(importance, 2)), vjust=1.6, color=\"white\", size=4) + \n  theme_bw() + \n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45,hjust = 1))\n\n\n\n\n可以看到前3个变量重要性远远超过其他变量！\n如果你在一开始划分了训练集/测试集，那此时你就可以使用这22个选中的变量查看在测试集中的表现了，不过我们一开始并没有划分，所以就用原数据集演示了：\n\n# 其实这里应该用测试集\npostResample(predict(lmProfile, x), logBBB)\n##      RMSE  Rsquared       MAE \n## 0.5016721 0.5836101 0.3834269\n\n如果要使用选中的这22变量对新的数据集进行预测，也是非常简单：\n\n# 直接使用predict即可\npredict(lmProfile, head(x))\n##           1           2           3           4           5           6 \n##  0.22346973 -0.52855194 -0.09119803  0.29685104  0.22498362  0.15485051\n\n查看每一次迭代结果：\n\nhead(lmProfile$resample)\n##     Variables      RMSE  Rsquared       MAE Resample\n## 21         22 0.5682701 0.4369318 0.4686130    Fold1\n## 54         22 0.6521735 0.3683946 0.5034888    Fold2\n## 87         22 0.6756625 0.3546881 0.5082219    Fold3\n## 120        22 0.5198089 0.5205895 0.3861660    Fold4\n## 153        22 0.7279476 0.2829001 0.5523393    Fold5\n\n\n\n16.3.2 随机森林\n再演示一个基于随机森林的递归特征消除。\n\nset.seed(1)\nrfeControl = rfeControl(functions = rfFuncs,\n                        method = \"cv\", \n                        number = 5\n                        )\n\n# 加速\nlibrary(future)\nplan(\"multisession\",workers=8)\n\nset.seed(1)\nrfProfile &lt;- rfe(x, logBBB,\n                 sizes = c(2:25, 30, 35, 40, 45, 50, 55, 60, 65),\n                 rfeControl = rfeControl,\n                 allowParallel = T\n                 )\nrfProfile\n## \n## Recursive feature selection\n## \n## Outer resampling method: Cross-Validated (5 fold) \n## \n## Resampling performance over subset size:\n## \n##  Variables   RMSE Rsquared    MAE  RMSESD RsquaredSD   MAESD Selected\n##          2 0.6797   0.2699 0.5247 0.09383     0.1240 0.06923         \n##          3 0.6339   0.3477 0.4793 0.08518     0.1081 0.06429         \n##          4 0.6009   0.4098 0.4559 0.10603     0.1500 0.07971         \n##          5 0.5932   0.4258 0.4500 0.09672     0.1344 0.06971         \n##          6 0.5936   0.4272 0.4425 0.10719     0.1536 0.07327         \n##          7 0.5922   0.4280 0.4368 0.09625     0.1346 0.06932         \n##          8 0.5821   0.4450 0.4234 0.09817     0.1357 0.07087         \n##          9 0.5755   0.4584 0.4172 0.08825     0.1173 0.06345         \n##         10 0.5618   0.4863 0.4091 0.08361     0.1098 0.05929         \n##         11 0.5577   0.4925 0.4067 0.09333     0.1238 0.06680         \n##         12 0.5527   0.5015 0.4002 0.09667     0.1282 0.06588         \n##         13 0.5446   0.5166 0.3991 0.08919     0.1142 0.06425         \n##         14 0.5388   0.5281 0.3975 0.08202     0.1063 0.05540         \n##         15 0.5390   0.5296 0.3960 0.08311     0.1046 0.05952         \n##         16 0.5362   0.5336 0.3921 0.08491     0.1096 0.06068         \n##         17 0.5316   0.5412 0.3910 0.08870     0.1151 0.06519         \n##         18 0.5349   0.5356 0.3921 0.09198     0.1202 0.06558         \n##         19 0.5276   0.5475 0.3868 0.09313     0.1234 0.06696         \n##         20 0.5271   0.5503 0.3836 0.09376     0.1234 0.06771         \n##         21 0.5293   0.5450 0.3878 0.09410     0.1236 0.06991         \n##         22 0.5260   0.5528 0.3832 0.09190     0.1200 0.06507         \n##         23 0.5289   0.5481 0.3871 0.09107     0.1164 0.06989         \n##         24 0.5283   0.5463 0.3842 0.09108     0.1188 0.06904         \n##         25 0.5254   0.5546 0.3848 0.09639     0.1261 0.07094         \n##         30 0.5179   0.5689 0.3775 0.09953     0.1277 0.07627        *\n##         35 0.5187   0.5711 0.3767 0.08848     0.1146 0.06470         \n##         40 0.5195   0.5680 0.3781 0.09101     0.1125 0.07158         \n##         45 0.5186   0.5709 0.3756 0.09137     0.1168 0.06954         \n##         50 0.5185   0.5727 0.3768 0.09089     0.1140 0.06905         \n##         55 0.5218   0.5694 0.3786 0.08865     0.1155 0.06736         \n##         60 0.5189   0.5733 0.3763 0.08574     0.1062 0.06867         \n##         65 0.5218   0.5687 0.3788 0.08603     0.1081 0.06711         \n##         71 0.5219   0.5708 0.3809 0.08333     0.1049 0.06280         \n## \n## The top 5 variables (out of 30):\n##    tcsa, fpsa3, tcpa, clogp, most_positive_charge\n\n随机森林选出了30个变量，还不如线性回归的效果好。\n\n\n16.3.3 支持向量机\n再演示一下径向基核函数SVM。\n径向基核函数svm不是预先定义好的算法，所以在进行特征选择时需要在指定rfeControl中指定functions = caretFuncs，然后在rfe中写method = \"svmRadial\"，其他算法也是类似。\n\nset.seed(1)\nrfeControl = rfeControl(functions = caretFuncs,\n                        method = \"cv\", \n                        number = 5\n                        )\n\n# 加速\nlibrary(future)\nplan(\"multisession\",workers=8)\n\nset.seed(1)\nsvmProfile &lt;- rfe(x, logBBB,\n                 sizes = c(2:25, 30, 35, 40, 45, 50, 55, 60, 65),\n                 method = \"svmRadial\",\n                 rfeControl = rfeControl,\n                 allowParallel = T\n                 )"
  },
  {
    "objectID": "feature-selection_rfe.html#多个模型比较",
    "href": "feature-selection_rfe.html#多个模型比较",
    "title": "16  递归特征消除",
    "section": "16.4 多个模型比较",
    "text": "16.4 多个模型比较\n以上我们建立了3个模型，可以通过可视化的方法更加直观的比较模型表现：\n\nxyplot(lmProfile$results$RMSE + rfProfile$results$RMSE + svmProfile$results$RMSE ~ lmProfile$results$Variables,\n       xlab = \"features\", ylab = \"RMSE\",\n       type = c(\"g\",\"p\",\"l\"),\n       auto.key = T\n       )\n\n\n\n\n可以选择不同的模型指标画图，这个图用ggplot2画也是很easy，还可以通过分面的形式把多个指标画在一张图里。\n\nplot.df &lt;- data.frame(\n  performance = c(lmProfile$results$RMSE,lmProfile$results$Rsquared,lmProfile$results$MAE,\n                  rfProfile$results$RMSE,rfProfile$results$Rsquared,rfProfile$results$MAE,\n                  svmProfile$results$RMSE,svmProfile$results$Rsquared,svmProfile$results$MAE\n                  ),\n  metrics = rep(rep(c(\"RMSE\",\"Rsquared\",\"MAE\"),each=length(lmProfile$results$Variables)),3),\n  features = rep(lmProfile$results$Variables,9),\n  models = rep(c(\"linearRegression\",\"randomForest\",\"rbfsvm\"),\n               each = 3*length(lmProfile$results$Variables))\n)\n\nlibrary(ggplot2)\nggplot2::ggplot(plot.df, aes(features, performance))+\n  geom_line(aes(group = models, color = models))+\n  geom_point(aes(color = models))+\n  scale_color_viridis_d()+\n  facet_wrap(~ metrics, scales = \"free_y\")+\n  theme_bw()+\n  theme(legend.position = \"top\")\n\n\n\n\n\n16.4.1 knn+调参\n下面演示一个knn的例子，在进行特征选择时同时可以调参！\nknn不是预先定义好的算法，所以在进行特征选择时需要在指定rfeControl中指定functions = caretFuncs，然后在rfe中写method = \"knn\"，其他算法也是类似。\n\nlibrary(caret)\nlibrary(mlbench)\n## Warning: package 'mlbench' was built under R version 4.2.3\ndata(Sonar)\n\n# knn，交叉验证\nset.seed(1)\nrctrl1 &lt;- rfeControl(method = \"cv\", # 交叉验证\n                     number = 5,\n                     returnResamp = \"all\",\n                     functions = caretFuncs,\n                     saveDetails = TRUE)\n\n# knn 特征选择，调参\nset.seed(1)\nknnProfile &lt;- rfe(Class ~ ., data = Sonar,\n             sizes = c(2:25, 30, 35, 40, 45, 50, 55, 60, 65),\n             method = \"knn\", # 不要乱写\n             trControl = trainControl(method = \"cv\", # 交叉验证\n                                      classProbs = TRUE),\n             tuneGrid = data.frame(k = 1:10), # 超参数网格\n             rfeControl = rctrl1)\n\nknnProfile\n## \n## Recursive feature selection\n## \n## Outer resampling method: Cross-Validated (5 fold) \n## \n## Resampling performance over subset size:\n## \n##  Variables Accuracy  Kappa AccuracySD KappaSD Selected\n##          2   0.7545 0.5019    0.05878 0.12072         \n##          3   0.7645 0.5218    0.04551 0.09357         \n##          4   0.7692 0.5327    0.06859 0.14152         \n##          5   0.7448 0.4809    0.05461 0.11213         \n##          6   0.7548 0.5014    0.07020 0.14407         \n##          7   0.7595 0.5102    0.08814 0.17986         \n##          8   0.7304 0.4521    0.07578 0.15435         \n##          9   0.7739 0.5407    0.06294 0.12867         \n##         10   0.7547 0.5015    0.06210 0.12747         \n##         11   0.7454 0.4823    0.07974 0.16396         \n##         12   0.7793 0.5505    0.09630 0.19648         \n##         13   0.7551 0.5008    0.09051 0.18883         \n##         14   0.7837 0.5584    0.09348 0.19819         \n##         15   0.7790 0.5482    0.08609 0.18333         \n##         16   0.7739 0.5406    0.10119 0.21049         \n##         17   0.7833 0.5583    0.09512 0.19835         \n##         18   0.8317 0.6593    0.03395 0.07109         \n##         19   0.8220 0.6392    0.03306 0.06930         \n##         20   0.8509 0.6989    0.04396 0.08925         \n##         21   0.8124 0.6216    0.08675 0.17529         \n##         22   0.8218 0.6416    0.03800 0.07586         \n##         23   0.8316 0.6609    0.06694 0.13398         \n##         24   0.8316 0.6615    0.06189 0.12303         \n##         25   0.8655 0.7275    0.02668 0.05632         \n##         30   0.8705 0.7381    0.03906 0.08043        *\n##         35   0.8510 0.6996    0.05532 0.11247         \n##         40   0.8700 0.7380    0.05047 0.10232         \n##         45   0.8412 0.6772    0.05784 0.12154         \n##         50   0.8174 0.6299    0.01081 0.02288         \n##         55   0.8125 0.6203    0.06145 0.12447         \n##         60   0.7836 0.5601    0.03849 0.07488         \n## \n## The top 5 variables (out of 30):\n##    V11, V12, V10, V9, V49\n\n查看交叉验证的结果：\n\nknnProfile$fit$results\n##     k  Accuracy     Kappa AccuracySD   KappaSD\n## 1   1 0.8454329 0.6892630 0.06862738 0.1364061\n## 2   2 0.8418182 0.6795104 0.07044070 0.1431458\n## 3   3 0.8318398 0.6609428 0.07523813 0.1510544\n## 4   4 0.8513636 0.7000060 0.06529929 0.1318002\n## 5   5 0.8227706 0.6409301 0.06975862 0.1423341\n## 6   6 0.7944156 0.5854349 0.07880035 0.1605779\n## 7   7 0.7741991 0.5428163 0.08134842 0.1658695\n## 8   8 0.7794372 0.5525427 0.07050749 0.1429124\n## 9   9 0.7982684 0.5898521 0.07648364 0.1573860\n## 10 10 0.7989610 0.5914536 0.09913461 0.2043514\n\n以上就是caret中使用递归特征消除的演示，更多细节大家自己探索。递归特征消除的方法非常多，大家不要天天只知道用支持向量机！\n另外，在使用时可能会遇到一些问题，毕竟是一个很老的包了……比如，x和y长度不相等问题…网上答案一搜一大堆，大家遇到了百度下即可。"
  },
  {
    "objectID": "dca-cox.html#方法1",
    "href": "dca-cox.html#方法1",
    "title": "40  生存数据的决策曲线分析",
    "section": "40.1 方法1",
    "text": "40.1 方法1\n使用dcurves包,使用的数据集是包自带的df_surv数据集，一共有750行，9列，其中ttcancer是时间，cancer是结局事件，TRUE代表有癌症，FALSE代表没有癌症。\n并不是只有结局事件是生存或者死亡的才叫生存资料哦！只要是time-event类型的，都可以。\n\nrm(list = ls())\n# 加载R包和数据，不知道怎么安装的请看我前面的推文\nlibrary(dcurves)\n## Warning: package 'dcurves' was built under R version 4.2.3\nlibrary(survival)\ndata(\"df_surv\")\n\n# 查看数据结构\ndim(df_surv)\n## [1] 750   9\nstr(df_surv)\n## tibble [750 × 9] (S3: tbl_df/tbl/data.frame)\n##  $ patientid       : num [1:750] 1 2 3 4 5 6 7 8 9 10 ...\n##  $ cancer          : logi [1:750] FALSE FALSE FALSE FALSE FALSE FALSE ...\n##  $ ttcancer        : num [1:750] 3.009 0.249 1.59 3.457 3.329 ...\n##  $ risk_group      : chr [1:750] \"low\" \"high\" \"low\" \"low\" ...\n##  $ age             : num [1:750] 64 78.5 64.1 58.5 64 ...\n##  $ famhistory      : num [1:750] 0 0 0 0 0 0 0 0 0 0 ...\n##  $ marker          : num [1:750] 0.7763 0.2671 0.1696 0.024 0.0709 ...\n##  $ cancerpredmarker: num [1:750] 0.0372 0.57891 0.02155 0.00391 0.01879 ...\n##  $ cancer_cr       : Factor w/ 3 levels \"censor\",\"diagnosed with cancer\",..: 1 1 1 1 1 1 1 2 1 1 ...\n\n这个包使用起来很别扭，但是可以说它很灵活！\n如果预测变量只有1个，且是0,1表示的，那就很简单，直接用就行；如果有多个预测变量，就需要先计算出预测概率，然后才能使用。\n预测变量是famhistory，这是0,1表示的二分类变量：\n\nlibrary(ggplot2)\n## Warning: package 'ggplot2' was built under R version 4.2.3\n\ndcurves::dca(Surv(ttcancer, cancer) ~ famhistory,\n             data = df_surv,\n             time = 1 # 时间选1年\n             ) %&gt;% \n  plot(smooth = T)\n\n\n\n\n下面展示一个把多个模型的DCA画在一起的例子，和之前介绍的dca.r的用法优点类似。\ncancerpredmarker这一列已经是概率了，marker是数值型的连续性变量，famhistory是0,1表示的二分类变量。\n\ndcurves::dca(Surv(ttcancer, cancer) ~ cancerpredmarker + marker + famhistory,\n    data = df_surv,\n    as_probability = \"marker\", # 只有marker需要转换成概率\n    time = 1,\n    label = list(cancerpredmarker = \"Prediction Model\", marker = \"Biomarker\")) %&gt;%\n  plot(smooth = TRUE,show_ggplot_code = T) +\n  ggplot2::labs(x = \"Treatment Threshold Probability\")\n## # ggplot2 code to create DCA figure -------------------------------\n## as_tibble(x) %&gt;%\n##   dplyr::filter(!is.na(net_benefit)) %&gt;%\n##   ggplot(aes(x = threshold, y = net_benefit, color = label)) +\n##   stat_smooth(method = \"loess\", se = FALSE, formula = \"y ~ x\", \n##     span = 0.2) +\n##   coord_cartesian(ylim = c(-0.0147287067742928, 0.147287067742928\n## )) +\n##   scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n##   labs(x = \"Threshold Probability\", y = \"Net Benefit\", color = \"\") +\n##   theme_bw()\n\n\n\n\n可以看到marker这个曲线有点过分了。。结果也给出了ggplot2的代码，大家可以自己修改。\n上面是多个模型在同一个时间点的DCA曲线，如果是同一个模型在不同时间点的DCA，这个包不能直接画出，需要自己整理数据，因为不同时间点进行治疗的风险和获益都是不一样的，所以会出现同一个阈值概率对应多个净获益的情况，所以none和all每个概率阈值下都有1套数据。\n如果你的预测变量是多个，就需要先计算预测概率。\n\n# 构建一个多元cox回归\ncox_model &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory + marker, data = df_surv)\n\n# 计算1.5年的概率\ndf_surv$prob1 &lt;- c(1-(summary(survfit(cox_model, newdata=df_surv), times=1.5)$surv))\n\n# 我们分2步，先获取数据，再用ggplot2画图\nx1 &lt;- dcurves::dca(Surv(ttcancer, cancer) ~ prob1,\n    data = df_surv,\n    time = 1.5\n    )%&gt;% \n  dcurves::as_tibble()\n\n# 使用自带的画图代码\nggplot(x1, aes(x=threshold, y=net_benefit,color=variable))+\n  stat_smooth(method = \"loess\", se = FALSE, formula = \"y ~ x\", span = 0.2) +\n  coord_cartesian(ylim = c(-0.03, 0.25)) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +\n  labs(x = \"Threshold Probability\", y = \"Net Benefit\", color = \"\") +\n  theme_bw()\n## Warning: Removed 20 rows containing non-finite values (`stat_smooth()`).\n\n\n\n\n大家还可以根据自己的喜好继续调整细节。"
  },
  {
    "objectID": "dca-cox.html#方法2",
    "href": "dca-cox.html#方法2",
    "title": "40  生存数据的决策曲线分析",
    "section": "40.2 方法2",
    "text": "40.2 方法2\n使用ggDCA包。是这么多方法里面最简单的一个。对于同一个模型多个时间点、同一个时间点多个模型，都可以非常简单的画出来。\n如果遇到报错：no points selected for one or more curves, consider using …，请安装GitHub版本的ggDCA包，且不要同时加载其它可以做DCA的R包。\n还是使用dcurves里面的df_surv数据集作为演示。\n\nlibrary(ggDCA)\n## \n## Attaching package: 'ggDCA'\n## The following object is masked from 'package:dcurves':\n## \n##     dca\n\n# 建立多个模型\ncox_fit1 &lt;- coxph(Surv(ttcancer, cancer) ~ famhistory+marker, \n                  data = df_surv)\ncox_fit2 &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory + marker, data = df_surv)\ncox_fit3 &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory, data = df_surv)\n\n多个模型同一时间点的DCA：\n\ndf1 &lt;- ggDCA::dca(cox_fit1, cox_fit2, cox_fit3,\n                  times = 1.5 # 1.5年，默认值是中位数\n                  )\n\nlibrary(ggsci)\n\nggplot(df1,linetype = F)+\n  scale_color_jama(name=\"Model Type\",labels=c(\"Cox 1\",\"Cox 2\",\"Cox 3\",\"All\",\"None\"))+\n  theme_bw(base_size = 14)+\n  theme(legend.position = c(0.8,0.75),\n        legend.background = element_blank()\n        )\n## Warning: Removed 498 rows containing missing values (`geom_line()`).\n\n\n\n\n同一个模型多个时间的DCA：\n\ndf2 &lt;- ggDCA::dca(cox_fit2,\n                  times = c(1,2,3)\n                  )\n\nggplot(df2,linetype = F)+\n  scale_color_jama(name=\"Model Type\")+\n  theme_bw()+\n  facet_wrap(~time) # 分面展示，因为不同时间点净获益是不一样的\n## Warning: Removed 1689 rows containing missing values (`geom_line()`).\n\n\n\n\n多个模型多个时间点：\n\ndf3 &lt;- ggDCA::dca(cox_fit1,cox_fit2,cox_fit3,\n                  times = c(1,2,3)\n                  )\n\nggplot(df3,linetype = F)+\n  scale_color_jama(name=\"Model Type\")+\n  theme_bw()+\n  facet_wrap(~time)\n## Warning: Removed 1226 rows containing missing values (`geom_line()`).\n\n\n\n\n非常强！如果你不会自己搞数据，就用这个！"
  },
  {
    "objectID": "dca-cox.html#方法3",
    "href": "dca-cox.html#方法3",
    "title": "40  生存数据的决策曲线分析",
    "section": "40.3 方法3",
    "text": "40.3 方法3\n使用这个网站给出的stdca.r文件绘制cox的DCA，需要代码的直接去网站下载即可。\n\n\n\n\n\n\n注意\n\n\n\n这个网站已经不再提供该代码的下载，我把dca.r/stdca.r这两段代码已经放在粉丝QQ群文件，需要的加群下载即可。\n\n\n数据还是用df_surv数据集。\n\nrm(list = ls())\nlibrary(survival)\nlibrary(dcurves)\ndata(\"df_surv\")\n\n# 加载函数,这个是我修改过的\n# 原函数有时会报错:no points selected for one or more curves, consider using...\n# 获取方式：https://mp.weixin.qq.com/s/TZ7MSaPZZ0Pwomyp_7wqFw\nsource(\"E:/R/r-clinical-model/000files/stdca.R\") \n\n# 构建一个多元cox回归\ndf_surv$cancer &lt;- as.numeric(df_surv$cancer) # stdca函数需要结果变量是0,1\ndf_surv &lt;- as.data.frame(df_surv) # stdca函数只接受data.frame\n\ncox_model &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory + marker, data = df_surv)\n\n# 计算1.5年的概率\ndf_surv$prob1 &lt;- c(1-(summary(survfit(cox_model, newdata=df_surv), times=1.5)$surv))\n\n# 这个函数我修改过，如果你遇到报错，可以通过添加参数 xstop=0.5 解决\ndd &lt;- stdca(data=df_surv, \n      outcome=\"cancer\", \n      ttoutcome=\"ttcancer\", \n      timepoint=1.5, \n      predictors=\"prob1\",\n      smooth=TRUE\n    )\n\n\n\n\n\n\n\n\n\n\n注意\n\n\n\n原网站下载的stdca.r脚本在某些数据中会遇到以下报错：Error in findrow(fit,times,extend):no points selected for one or more curves, consider using the extend argument，所以我对这段脚本进行了修改，可以解决这个报错。但是需要付费获取，获取链接：适用于一切模型的DCA，没有任何答疑服务，介意勿扰。\n\n\n多个模型在同一个时间点的DCA画法，和第一种方法很类似，也是要分别计算出每个模型的概率。\n\n# 建立多个模型\ncox_fit1 &lt;- coxph(Surv(ttcancer, cancer) ~ famhistory+marker, \n                  data = df_surv)\ncox_fit2 &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory + marker, data = df_surv)\ncox_fit3 &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory, data = df_surv)\n\n# 计算每个模型的概率\ndf_surv$prob1 &lt;- c(1-(summary(survfit(cox_fit1, newdata=df_surv), times=1.5)$surv))\ndf_surv$prob2 &lt;- c(1-(summary(survfit(cox_fit2, newdata=df_surv), times=1.5)$surv))\ndf_surv$prob3 &lt;- c(1-(summary(survfit(cox_fit3, newdata=df_surv), times=1.5)$surv))\n\n# 画图\ndd &lt;- stdca(data=df_surv, \n      outcome=\"cancer\", \n      ttoutcome=\"ttcancer\", \n      timepoint=1.5, \n      predictors=c(\"prob1\",\"prob2\",\"prob3\"),  \n      smooth=TRUE\n    )"
  },
  {
    "objectID": "dca-cox.html#方法4",
    "href": "dca-cox.html#方法4",
    "title": "40  生存数据的决策曲线分析",
    "section": "40.4 方法4",
    "text": "40.4 方法4\n返回画图数据，再用ggplot2画图：\n\ncox_dca &lt;- stdca(data = df_surv, \n      outcome = \"cancer\", \n      ttoutcome = \"ttcancer\", \n      timepoint = 1.5, \n      predictors = c(\"prob1\",\"prob2\",\"prob3\"),\n      smooth=TRUE,\n      graph = FALSE\n    )\n\nlibrary(tidyr)\n\ncox_dca_df &lt;- cox_dca$net.benefit %&gt;% \n  pivot_longer(cols = c(all,none,contains(\"sm\")),names_to = \"models\",\n               values_to = \"net_benefit\"\n               )\n\n使用ggplot2画图：\n\nlibrary(ggplot2)\nlibrary(ggsci)\n\nggplot(cox_dca_df, aes(x=threshold,y=net_benefit))+\n  geom_line(aes(color=models),linewidth=1.2)+\n  scale_color_jama(name=\"Models Types\",\n                   labels=c(\"All\",\"None\",\"Model1\",\"Model2\",\"Model3\"))+\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1),\n                     name=\"Threshold Probility\")+\n  scale_y_continuous(limits = c(-0.05,0.2),name=\"Net Benefit\")+\n  theme_bw(base_size = 14)+\n  theme(legend.background = element_blank(),\n        legend.position = c(0.85,0.75)\n        )\n## Warning: Removed 83 rows containing missing values (`geom_line()`).\n\n\n\n\n常见的DCA方法都展示了，大家自己选择使用哪个就好。"
  },
  {
    "objectID": "dca-diy.html#多个时间点多个cox模型的数据提取",
    "href": "dca-diy.html#多个时间点多个cox模型的数据提取",
    "title": "41  适用于一切模型的决策曲线分析",
    "section": "41.1 多个时间点多个cox模型的数据提取",
    "text": "41.1 多个时间点多个cox模型的数据提取\n其实ggDCA包完全可以做到，只要1行代码就搞定了，而且功能还很丰富。\n我给大家演示一遍基于stdca.r的方法，给大家开阔思路，代码可能不够简洁，但是思路没问题，无非就是各种数据整理与转换。\n而且很定会有人对默认结果不满意，想要各种修改，下面介绍的这个方法非常适合自己进行各种自定义！\n\nrm(list = ls())\nlibrary(survival)\nlibrary(dcurves)\n## Warning: package 'dcurves' was built under R version 4.2.3\ndata(\"df_surv\")\n\n# 加载函数\n# 原函数有问题，这个是我修改过的\n# 获取方式：https://mp.weixin.qq.com/s/TZ7MSaPZZ0Pwomyp_7wqFw\nsource(\"E:/R/r-clinical-model/000files/stdca.R\") # 原函数有问题\n\n# 构建一个多元cox回归\ndf_surv$cancer &lt;- as.numeric(df_surv$cancer) # stdca函数需要结果变量是0,1\ndf_surv &lt;- as.data.frame(df_surv) # stdca函数只接受data.frame\n\n\n\n\n\n\n\n注意\n\n\n\n原网站下载的stdca.r脚本在某些数据中会遇到以下报错：Error in findrow(fit,times,extend):no points selected for one or more curves, consider using the extend argument，所以我对这段脚本进行了修改，可以解决这个报错。但是需要付费获取，获取链接：适用于一切模型的DCA，没有任何答疑服务，介意勿扰。\n\n\n\n# 建立多个模型\ncox_fit1 &lt;- coxph(Surv(ttcancer, cancer) ~ famhistory+marker, data = df_surv)\ncox_fit2 &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory + marker, data = df_surv)\ncox_fit3 &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory, data = df_surv)\n\n# 计算每个模型在不同时间点的概率\ndf_surv$prob11 &lt;- c(1-(summary(survfit(cox_fit1, newdata=df_surv), times=1)$surv))\ndf_surv$prob21 &lt;- c(1-(summary(survfit(cox_fit2, newdata=df_surv), times=1)$surv))\ndf_surv$prob31 &lt;- c(1-(summary(survfit(cox_fit3, newdata=df_surv), times=1)$surv))\n\ndf_surv$prob12 &lt;- c(1-(summary(survfit(cox_fit1, newdata=df_surv), times=2)$surv))\ndf_surv$prob22 &lt;- c(1-(summary(survfit(cox_fit2, newdata=df_surv), times=2)$surv))\ndf_surv$prob32 &lt;- c(1-(summary(survfit(cox_fit3, newdata=df_surv), times=2)$surv))\n\ndf_surv$prob13 &lt;- c(1-(summary(survfit(cox_fit1, newdata=df_surv), times=3)$surv))\ndf_surv$prob23 &lt;- c(1-(summary(survfit(cox_fit2, newdata=df_surv), times=3)$surv))\ndf_surv$prob33 &lt;- c(1-(summary(survfit(cox_fit3, newdata=df_surv), times=3)$surv))\n\n计算threshold和net benefit：\n\ncox_dca1 &lt;- stdca(data = df_surv, \n      outcome = \"cancer\", \n      ttoutcome = \"ttcancer\", \n      timepoint = 1, \n      predictors = c(\"prob11\",\"prob21\",\"prob31\"),\n      smooth=TRUE,\n      graph = FALSE\n    )\n## [1] \"prob31: No observations with risk greater than 99%, and therefore net benefit not calculable in this range.\"\n\ncox_dca2 &lt;- stdca(data = df_surv, \n      outcome = \"cancer\", \n      ttoutcome = \"ttcancer\", \n      timepoint = 2, \n      predictors = c(\"prob12\",\"prob22\",\"prob32\"),\n      smooth=TRUE,\n      graph = FALSE\n    )\n\ncox_dca3 &lt;- stdca(data = df_surv, \n      outcome = \"cancer\", \n      ttoutcome = \"ttcancer\", \n      timepoint = 3, \n      predictors = c(\"prob13\",\"prob23\",\"prob33\"),\n      smooth=TRUE,\n      graph = FALSE\n    )\n\n\nlibrary(tidyr)\nlibrary(dplyr)\n## Warning: package 'dplyr' was built under R version 4.2.3\n## \n## Attaching package: 'dplyr'\n## The following objects are masked from 'package:stats':\n## \n##     filter, lag\n## The following objects are masked from 'package:base':\n## \n##     intersect, setdiff, setequal, union\n\n\n41.1.1 第一种数据整理方法\n\ncox_dca_df1 &lt;- cox_dca1$net.benefit\ncox_dca_df2 &lt;- cox_dca2$net.benefit\ncox_dca_df3 &lt;- cox_dca3$net.benefit\n\nnames(cox_dca_df1)[2] &lt;- \"all1\"\nnames(cox_dca_df2)[2] &lt;- \"all2\"\nnames(cox_dca_df3)[2] &lt;- \"all3\"\n\ntmp &lt;- cox_dca_df1 %&gt;% \n  left_join(cox_dca_df2) %&gt;% \n  left_join(cox_dca_df3) %&gt;% \n  pivot_longer(cols = contains(c(\"all\",\"sm\",\"none\")),\n               names_to = \"models\",\n               values_to = \"net_benefit\"\n               )\n## Joining with `by = join_by(threshold, none)`\n## Joining with `by = join_by(threshold, none)`\n\n画图：\n\nlibrary(ggplot2)\n## Warning: package 'ggplot2' was built under R version 4.2.3\nlibrary(ggsci)\n\nggplot(tmp, aes(x=threshold,y=net_benefit))+\n  geom_line(aes(color=models),linewidth=1.2)+\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1),\n                     name=\"Threshold Probility\")+\n  scale_y_continuous(limits = c(-0.05,0.3),name=\"Net Benefit\")+\n  theme_bw(base_size = 14)\n## Warning: Removed 235 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\n41.1.2 第二种数据整理方法\n\ncox_dca_df1 &lt;- cox_dca1$net.benefit\ncox_dca_df2 &lt;- cox_dca2$net.benefit\ncox_dca_df3 &lt;- cox_dca3$net.benefit\n\ncox_dca_long_df1 &lt;- cox_dca_df1 %&gt;% \n  rename(mod1 = prob11_sm,\n         mod2 = prob21_sm,\n         mod3 = prob31_sm\n         ) %&gt;% \n  select(-4:-6) %&gt;% \n  mutate(time = \"1\") %&gt;% \n  pivot_longer(cols = c(all,none,contains(\"mod\")),names_to = \"models\",\n               values_to = \"net_benefit\"\n               )\n\ncox_dca_long_df2 &lt;- cox_dca_df2 %&gt;% \n  rename(mod1 = prob12_sm,\n         mod2 = prob22_sm,\n         mod3 = prob32_sm\n         ) %&gt;% \n  select(-4:-6) %&gt;% \n  mutate(time = \"2\") %&gt;% \n  pivot_longer(cols = c(all,none,contains(\"mod\")),names_to = \"models\",\n               values_to = \"net_benefit\"\n               )\n\n\ncox_dca_long_df3 &lt;- cox_dca_df3 %&gt;% \n  rename(mod1 = prob13_sm,\n         mod2 = prob23_sm,\n         mod3 = prob33_sm\n         ) %&gt;% \n  select(-4:-6) %&gt;% \n  mutate(time = \"3\") %&gt;% \n  pivot_longer(cols = c(all,none,contains(\"mod\")),names_to = \"models\",\n               values_to = \"net_benefit\"\n               )\n\ntes &lt;- bind_rows(cox_dca_long_df1,cox_dca_long_df2,cox_dca_long_df3)\n\n画图：\n\nggplot(tes,aes(x=threshold,y=net_benefit))+\n  geom_line(aes(color=models,linetype=time),linewidth=1.2)+\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1),\n                     name=\"Threshold Probility\")+\n  scale_y_continuous(limits = c(-0.05,0.3),name=\"Net Benefit\")+\n  theme_bw(base_size = 14)\n## Warning: Removed 235 rows containing missing values (`geom_line()`).\n\n\n\n\n这种方法可以分面。\n\nggplot(tes,aes(x=threshold,y=net_benefit))+\n  geom_line(aes(color=models),linewidth=1.2)+\n  scale_y_continuous(limits = c(-0.05,0.3),name=\"Net Benefit\")+\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1),\n                     name=\"Threshold Probility\")+\n  scale_y_continuous(limits = c(-0.05,0.3),name=\"Net Benefit\")+\n  theme_bw(base_size = 14)+\n  facet_wrap(~time)\n## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Warning: Removed 73 rows containing missing values (`geom_line()`).\n\n\n\n\n接下来演示其他模型的DCA实现方法，这里就以二分类变量为例，生存资料的DCA也是一样的，就是需要一个概率而已！"
  },
  {
    "objectID": "dca-diy.html#lasso回归",
    "href": "dca-diy.html#lasso回归",
    "title": "41  适用于一切模型的决策曲线分析",
    "section": "41.2 lasso回归",
    "text": "41.2 lasso回归\n\nrm(list = ls())\nsuppressMessages(library(glmnet))\n## Warning: package 'glmnet' was built under R version 4.2.3\nsuppressPackageStartupMessages(library(tidyverse))\n## Warning: package 'tibble' was built under R version 4.2.3\n\n准备数据，这是从TCGA下载的一部分数据，其中sample_type是样本类型，1代表tumor，0代表normal，我们首先把因变量变为0,1。然后划分训练集和测试集。\n\ndf &lt;- readRDS(file = \"./datasets/df_example.rds\")\n\ndf &lt;- df %&gt;% \n  select(-c(2:3)) %&gt;% \n  mutate(sample_type = ifelse(sample_type==\"Tumor\",1,0))\n\nind &lt;- sample(1:nrow(df),nrow(df)*0.6)\n\ntrain_df &lt;- df[ind,]\ntest_df &lt;- df[-ind,]\n\n构建lasso回归需要的参数值。\n\nx &lt;- as.matrix(train_df[,-1])\ny &lt;- train_df$sample_type\n\n在训练集建立lasso回归模型：\n\ncvfit = cv.glmnet(x, y, family = \"binomial\")\nplot(cvfit)\n\n\n\n\n在测试集上查看模型表现：\n\nprob_lasso &lt;- predict(cvfit,\n                      newx = as.matrix(test_df[,-1]),\n                      s=\"lambda.1se\",\n                      type=\"response\") #返回概率\n\n然后进行DCA，也是基于测试集的：\n\nsource(\"./datasets/dca.r\")\n\ntest_df$lasso &lt;- prob_lasso\n\ndf_lasso &lt;- dca(data = test_df, # 指定数据集,必须是data.frame类型\n    outcome=\"sample_type\", # 指定结果变量\n    predictors=\"lasso\", # 指定预测变量\n    probability = T\n    )\n\n\n\n\n这就是lasso的DCA，由于数据和模型原因，这个DCA看起来很诡异，大家千万要理解实现方法！\n\nlibrary(ggplot2)\nlibrary(ggsci)\nlibrary(tidyr)\n\ndf_lasso$net.benefit %&gt;% \n  pivot_longer(cols = -threshold, \n               names_to = \"type\", \n               values_to = \"net_benefit\") %&gt;% \n  ggplot(aes(threshold, net_benefit, color = type))+\n  geom_line(linewidth = 1.2)+\n  scale_color_jama(name = \"Model Type\")+ \n  scale_y_continuous(limits = c(-0.02,1),name = \"Net Benefit\")+ \n  scale_x_continuous(limits = c(0,1),name = \"Threshold Probility\")+\n  theme_bw(base_size = 16)+\n  theme(legend.position = c(0.2,0.3),\n        legend.background = element_blank()\n        )\n## Warning: Removed 8 rows containing missing values (`geom_line()`)."
  },
  {
    "objectID": "dca-diy.html#随机森林",
    "href": "dca-diy.html#随机森林",
    "title": "41  适用于一切模型的决策曲线分析",
    "section": "41.3 随机森林",
    "text": "41.3 随机森林\n\nlibrary(ranger)\n\nrf &lt;- ranger(sample_type ~ ., data = train_df)\n\nprob_rf &lt;- predict(rf,test_df[,-1],type = \"response\")$predictions\n\ntest_df$rf &lt;- prob_rf\n\ndf_rf &lt;- dca(data = test_df, # 指定数据集,必须是data.frame类型\n    outcome=\"sample_type\", # 指定结果变量\n    predictors=\"rf\", # 指定预测变量\n    probability = T,\n    graph = F\n    )\n\n\ndf_rf$net.benefit %&gt;% \n  pivot_longer(cols = -threshold, \n               names_to = \"type\", \n               values_to = \"net_benefit\") %&gt;% \n  ggplot(aes(threshold, net_benefit, color = type))+\n  geom_line(linewidth = 1.2)+\n  scale_color_jama(name = \"Model Type\")+ \n  scale_y_continuous(limits = c(-0.02,1),name = \"Net Benefit\")+ \n  scale_x_continuous(limits = c(0,1),name = \"Threshold Probility\")+\n  theme_bw(base_size = 16)+\n  theme(legend.position = c(0.2,0.3),\n        legend.background = element_blank()\n        )\n## Warning: Removed 8 rows containing missing values (`geom_line()`)."
  },
  {
    "objectID": "dca-diy.html#logistic",
    "href": "dca-diy.html#logistic",
    "title": "41  适用于一切模型的决策曲线分析",
    "section": "41.4 logistic",
    "text": "41.4 logistic\n\nlogis &lt;- glm(sample_type ~ ., data = train_df,family = binomial())\n## Warning: glm.fit: algorithm did not converge\n## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nprob_logis &lt;- predict(logis, test_df[,-1],type = \"response\")\n\n\ntest_df$logis &lt;- prob_logis\n\ndf_logis &lt;- dca(data = test_df, # 指定数据集,必须是data.frame类型\n    outcome=\"sample_type\", # 指定结果变量\n    predictors=\"logis\", # 指定预测变量\n    probability = T,\n    graph = T\n    )\n\n\n\n\n还有其他比如支持向量机等，就不一一介绍了，实现原理都是一样的，就是需要一个概率而已。"
  },
  {
    "objectID": "clinmodel-definition.html#简单理解",
    "href": "clinmodel-definition.html#简单理解",
    "title": "1  什么是临床预测模型？",
    "section": "1.1 简单理解",
    "text": "1.1 简单理解\n临床预测模型，初听这个名字，或许会觉得很高大上，其实没那么复杂，你可以理解成一种方法，这种方法可以预测一个人到底是有病还是没病，或者预测一个人一段时间后会不会死，或者预测一个人的某种疾病会不会复发，又或者是预测一个样本到底是肿瘤还是正常组织……\n再直白一点，临床预测模型是一个公式，根据这个公式，你提供一些基本信息，比如年龄、性别、体重、血红蛋白量等（或者某个基因的表达量等），就可以计算出这个人到底是有病还是没病！\n目前很多疾病都需要做磁共振、做CT、病理才能确诊，假如你发现了一个公式，只要验个血，得到几个生化指标，就能根据你的公式算出来这个人到底是有病还是没病！这不比CT、磁共振、病理简单多了？值得推广。\n所以，临床预测模型的本质是一种分类方法。通过这种方法，你可以对很多东西进行分类，比如，生和死、有病和没病、肿瘤和非肿瘤、复发和不复发等等。\n既然是一种方法，那肯定就有准确和不准确，看名字也能知道，这只是一种预测，或者叫：猜（有根据的猜）！ 如果你这种方法能和金标准相提并论，那说明你的方法很牛，如果恰好你的方法更加简单方便、经济适用，那你的方法真是太厉害了，非常有希望成为新的金标准！\n那如何评价你的方法好还是不好呢？这就是临床预测模型的评价，通过各种指标（后面会详细介绍）、从各种不同的角度评价。\n说了这么多，我怎么才能得到我的模型（或者叫方法）呢？这就是临床预测模型的另一个主要内容：临床预测模型的建立。\n前面说过，临床预测模型本质上就是一个公式而已！说个最简单的，逻辑回归（logistic），大家应该都知道怎么构建逻辑回归吧？不就是自变量和因变量吗。给你几个自变量，一个二分类的因变量，大家通过SPSS点点点，就可以得到各个自变量的系数，然后就能写出逻辑回归方程了。你的这个逻辑回归方程，这就是一个临床预测模型了！给你几个自变量的值，根据这个方程，你就可以算出因变量的值，然后就可以分类了！\n说到这里，相信你应该明白很多了！但是这还不够，你可能还听过什么机器学习、lasso、随机森林、支持向量机等等，别慌，这就是我们接下来要说的：临床预测模型和机器学习的关系。"
  },
  {
    "objectID": "clinmodel-definition.html#临床预测模型和机器学习",
    "href": "clinmodel-definition.html#临床预测模型和机器学习",
    "title": "1  什么是临床预测模型？",
    "section": "1.2 临床预测模型和机器学习",
    "text": "1.2 临床预测模型和机器学习\n机器学习，是不是听上去也高大上，但是对于学习临床医学的我们来说，不需要知道的太彻底，大概明白是什么就够了。\n逻辑回归也是机器学习的一种，随机森林、决策树、支持向量机、lasso、岭回归、弹性网络、xgboost等等，这些都是和逻辑回归一样，就是不同的方法而已！\n学过医学统计学的都知道（没学过可能也知道），如果因变量是连续性变量，那么我们就用多元线性回归，如果因变量是二分类变量，就用logistic回归（分类）。回归和分类，刚好就是机器学习的两个主要任务。很多方法，比如随机森林，既可以做回归，又可以做分类，而且准确度还很高，这就是为什么大家喜欢用其他方法的原因，主要是为了提高准确性。\n临床预测模型，只是机器学习在医学领域的应用之一，回归和分类，适用于各行各业，所以在很多领域你都听过机器学习这几个字。此外，还有深度学习、人工智能等等，这些都可以简单的理解为更加牛逼的方法！\n这些不同的方法都有各自适合的场景，在合适的场景下才能得到最好的表现，如何让模型表现的更好，那就需要学习一些机器学习的基本知识了，这些东西在bilibili一搜一大堆，大家可以自行学习，不过千万不要太沉迷哟！\n但是你一搜机器学习教程，出来的都是推荐你吴恩达、西瓜书等内容，我是不太推荐的，这些东西不是给生物医药领域的人看的，你看这些，可能就是听天书，毕竟很多医学生，连高数都是不学的！我比较推荐statquest，b站也可以搜到，这是一个国外的生物统计教授的课程，他的风格更适合我们。不过在学习这些这些之前，希望你已经学会了书本中常见的医学统计知识。"
  },
  {
    "objectID": "clinmodel-definition.html#临床预测模型和统计学",
    "href": "clinmodel-definition.html#临床预测模型和统计学",
    "title": "1  什么是临床预测模型？",
    "section": "1.3 临床预测模型和统计学",
    "text": "1.3 临床预测模型和统计学\n我们学过的医学统计学，在某些方面和机器学习是有交集的。比如，逻辑回归、多元线性回归，既是统计学方法，也是机器学习算法，这并不冲突，就像一个人在不同场合有不同身份一样。\n在谈临床预测模型时，我们可能是偏向于机器学习多一点的，毕竟用到的很多方法，都是来自于机器学习领域。\n你可能见到在很多生信文章中，使用一个模型并没有提前检验各种条件，直接就用了。但在医学统计学中，很多方法都是有适用条件的，符合条件才能用。哪种才是正确的呢？\n其实不用纠结，别人能用你也能用，多看文章，你能发现各种用法，但是别人依然发了SCI，你也可以。如果非要说区别，这就涉及到频率学派和贝叶斯学派这些东西了，咱也不是很懂了，如果你有兴趣，可以自己探索。如果就是为了发文章，那就别搞这些没用的了，多看几篇高分SCI，跟着里面的思路模仿吧！\n读到这里，你应该大致了解临床预测模型，不致于云里雾里了。但是光说不练是假把式，还是希望你能多读几篇相关的文献。"
  },
  {
    "objectID": "nomogram-logistic.html#安装r包",
    "href": "nomogram-logistic.html#安装r包",
    "title": "2  logistic回归列线图绘制",
    "section": "2.1 安装R包",
    "text": "2.1 安装R包\n\ninstall.packages(\"rms\")\ninstall.packages(\"DynNom\")\ninstall.packages(\"regplot\")\ndevtools::install_local(\"D:/R/R包/VRPM_1.2.tar.gz\") # 需要下载压缩包本地安装\n\n使用lowbirth数据集，这个数据集是关于低出生体重儿是否会死亡的数据集，其中dead这一列是结果变量，0代表存活，1代表死亡，其余列都是预测变量。\n\n注意：需要把分类变量因子化，对于无序分类变量，需要设置哑变量！"
  },
  {
    "objectID": "nomogram-logistic.html#方法1",
    "href": "nomogram-logistic.html#方法1",
    "title": "2  logistic回归列线图绘制",
    "section": "2.2 方法1",
    "text": "2.2 方法1\n\nrm(list = ls())\nlibrary(rms)\n## Loading required package: Hmisc\n## Loading required package: lattice\n## Loading required package: survival\n## Loading required package: Formula\n## Loading required package: ggplot2\n## Warning: package 'ggplot2' was built under R version 4.2.3\n## \n## Attaching package: 'Hmisc'\n## The following objects are masked from 'package:base':\n## \n##     format.pval, units\n## Loading required package: SparseM\n## \n## Attaching package: 'SparseM'\n## The following object is masked from 'package:base':\n## \n##     backsolve\n\nlowbirth &lt;- read.csv(\"./datasets/lowbirth.csv\")\n\n查看一下数据：\n\ndim(lowbirth) # 565行，10列\n## [1] 565  10\nstr(lowbirth) \n## 'data.frame':    565 obs. of  10 variables:\n##  $ birth   : num  81.5 81.6 81.6 81.6 81.6 ...\n##  $ lowph   : num  7.25 7.06 7.25 6.97 7.32 ...\n##  $ pltct   : int  244 114 182 54 282 153 229 182 361 378 ...\n##  $ race    : chr  \"white\" \"black\" \"black\" \"black\" ...\n##  $ bwt     : int  1370 620 1480 925 1255 1350 1310 1110 1180 970 ...\n##  $ delivery: chr  \"abdominal\" \"vaginal\" \"vaginal\" \"abdominal\" ...\n##  $ apg1    : int  7 1 8 5 9 4 6 6 6 2 ...\n##  $ vent    : int  0 1 0 1 0 0 1 0 0 1 ...\n##  $ sex     : chr  \"female\" \"female\" \"male\" \"female\" ...\n##  $ dead    : int  0 1 0 1 0 0 0 0 0 1 ...\n\n简单的把人种分为白色和黑色人种（无序分类变量需要设置哑变量），再去掉race这一列，然后其余分类变量因子化。\n\nlibrary(dplyr)\n## Warning: package 'dplyr' was built under R version 4.2.3\n## \n## Attaching package: 'dplyr'\n## The following objects are masked from 'package:Hmisc':\n## \n##     src, summarize\n## The following objects are masked from 'package:stats':\n## \n##     filter, lag\n## The following objects are masked from 'package:base':\n## \n##     intersect, setdiff, setequal, union\n\ntmp &lt;- lowbirth %&gt;% \n  mutate(across(where(is.character),as.factor),\n         vent = factor(vent),\n         black = ifelse(race == \"black\",1,0),\n         white = ifelse(race == \"white\",1,0),\n         other = ifelse(race %in% c(\"native American\",\"oriental\"),1,0)\n         ) %&gt;% \n  select(- race)\n\nglimpse(tmp)\n## Rows: 565\n## Columns: 12\n## $ birth    &lt;dbl&gt; 81.514, 81.552, 81.558, 81.593, 81.610, 81.624, 81.626, 81.68…\n## $ lowph    &lt;dbl&gt; 7.250000, 7.059998, 7.250000, 6.969997, 7.320000, 7.160000, 7…\n## $ pltct    &lt;int&gt; 244, 114, 182, 54, 282, 153, 229, 182, 361, 378, 255, 186, 26…\n## $ bwt      &lt;int&gt; 1370, 620, 1480, 925, 1255, 1350, 1310, 1110, 1180, 970, 770,…\n## $ delivery &lt;fct&gt; abdominal, vaginal, vaginal, abdominal, vaginal, abdominal, v…\n## $ apg1     &lt;int&gt; 7, 1, 8, 5, 9, 4, 6, 6, 6, 2, 4, 8, 1, 8, 5, 9, 9, 9, 6, 2, 1…\n## $ vent     &lt;fct&gt; 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1…\n## $ sex      &lt;fct&gt; female, female, male, female, female, female, male, male, mal…\n## $ dead     &lt;int&gt; 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n## $ black    &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0…\n## $ white    &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1…\n## $ other    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n然后是打包数据。\n\ndd &lt;- datadist(tmp)\noptions(datadist=\"dd\")\n\n构建模型：\n\nfit1 &lt;- lrm(dead ~ birth + lowph + pltct + bwt + delivery + apg1 +\n              vent + sex + black + white,\n            data = tmp,x=T,y=T)\n\n接下来就是构建列线图模型，然后画图。\n\nnom1 &lt;- nomogram(fit1, fun=plogis,\n                 fun.at=c(0.001,0.1,0.25,0.5,0.75,0.9,0.99),\n                 lp=T, # 是否显示线性概率\n                 funlabel=\"Risk of Death\")  \nplot(nom1) \n\n\n\n\n从这个图来看，sex、delivery、apg1对模型的贡献很小，几乎可以忽略不计，下面我们去掉这两个变量再看看。\n\nfit2 &lt;- lrm(dead ~ birth + lowph + pltct + bwt + vent + black + white,\n            data = tmp,x=T,y=T)\nnom2 &lt;- nomogram(fit2, fun=plogis,\n                 fun.at=c(0.001,0.01,0.1,0.25,0.5,0.75,0.9,0.99),\n                 lp=T, \n                 maxscale = 100, # 最大得分数\n                 conf.int = F, # 添加置信区间，很难看，可以不要\n                 funlabel=\"Dead\")  \nplot(nom2,\n     col.grid=c(\"tomato\",\"grey\")\n     #conf.space = c(0.3,0.5) # 置信区间位置\n     )"
  },
  {
    "objectID": "nomogram-logistic.html#方法2",
    "href": "nomogram-logistic.html#方法2",
    "title": "2  logistic回归列线图绘制",
    "section": "2.3 方法2",
    "text": "2.3 方法2\n使用这种方法会在你的Rstudio中弹出一个窗口，你可以自由调节其中给出的选项。\n\nlibrary(DynNom)\n\nfit2 &lt;- glm(dead ~ birth + lowph + pltct + bwt + vent + black + white,\n            data = tmp, family = binomial)\nDynNom(fit2,DNtitle = \"nomogram\",DNxlab = \"probability\")\n\n选择好你的参数，点击Predict即可出图：\n\n\n\n\n\n\n\n注意\n\n\n\n仔细看上面这个图其实有错误，black和white作为性别，只有2种可能，不可能为小数，这就提醒我们在建立模型时需要把这样的变量先因子化。"
  },
  {
    "objectID": "nomogram-logistic.html#方法3",
    "href": "nomogram-logistic.html#方法3",
    "title": "2  logistic回归列线图绘制",
    "section": "2.4 方法3",
    "text": "2.4 方法3\n\nlibrary(regplot)\n\nfit2 &lt;- lrm(dead ~ birth + lowph + pltct + bwt + vent + black + white,\n            data = tmp,x=T,y=T)\nregplot(fit2,\n        #连续性变量形状，\"no plot\"\"density\"\"boxes\"\"ecdf\"\n        #\"bars\"\"boxplot\"\"violin\"\"bean\" \"spikes\"；\n        #分类变量的形状，可选\"no plot\" \"boxes\" \"bars\" \"spikes\"\n        plots = c(\"violin\", \"boxes\"),   \n        observation = tmp[1,], #用哪行观测，或者T F\n        center = T, # 对齐变量\n        subticks = T,\n        droplines = T,#是否画竖线\n        title = \"nomogram\",\n        points = T, # 截距项显示为0-100\n        odds = T, # 是否显示OR值\n        showP = T, # 是否显示变量的显著性标记\n        rank = \"sd\", # 根据sd给变量排序\n        interval=\"confidence\", # 展示可信区间\n        clickable = F # 是否可以交互\n        )\n## Regression  fit2 lrm formula:\n## dead `~` birth + lowph + pltct + bwt + vent + black + white\n## CI: 0.00496(0.00106,0.0233)\n## [[1]]\n##   white Points\n## 1   0.0     26\n## 2   0.4     34\n## 3   0.8     42\n## \n## [[2]]\n##   black Points\n## 1   0.0     17\n## 2   0.4     29\n## 3   0.8     40\n## \n## [[3]]\n##       vent Points\n## vent1    0     34\n## vent2    1     99\n## \n## [[4]]\n##    bwt Points\n## 1  400     87\n## 2  600     72\n## 3  800     57\n## 4 1000     42\n## 5 1200     27\n## 6 1400     12\n## \n## [[5]]\n##   pltct Points\n## 1     0     42\n## 2   300     30\n## 3   600     18\n## \n## [[6]]\n##    lowph Points\n## 1    6.5    103\n## 2    6.6     93\n## 3    6.7     83\n## 4    6.8     74\n## 5    6.9     64\n## 6    7.0     54\n## 7    7.1     44\n## 8    7.2     34\n## 9    7.3     25\n## 10   7.4     15\n## 11   7.5      5\n## 12   7.6     -5\n## \n## [[7]]\n##   birth Points\n## 1  81.5     43\n## 2  84.5     34\n## 3  87.5     26\n## \n## [[8]]\n##   Total Points    Pr(  )\n## 1          100 3.798e-05\n## 2          150 3.144e-04\n## 3          200 2.598e-03\n## 4          250 2.112e-02\n## 5          300 1.516e-01\n## 6          350 5.967e-01\n## 7          400 9.245e-01\n## 8          450 9.902e-01"
  },
  {
    "objectID": "nomogram-logistic.html#方法4",
    "href": "nomogram-logistic.html#方法4",
    "title": "2  logistic回归列线图绘制",
    "section": "2.5 方法4",
    "text": "2.5 方法4\n\nlibrary(VRPM)\n\nfit2 &lt;- glm(dead ~ birth + lowph + pltct + bwt + vent + black + white,\n            data = tmp, family = binomial)\n\n# 图片保存在你的目录下\ncolplot(fit2,coloroptions = 3)\n\n\n以上就是4种Cox回归列线图绘制的方法，其中方法1和3是最常用的。\n获取lowbirth数据请在公众号：医学和生信笔记 后台回复20220520。"
  },
  {
    "objectID": "nomogram-cox.html#加载数据和r包",
    "href": "nomogram-cox.html#加载数据和r包",
    "title": "3  Cox回归列线图绘制",
    "section": "3.1 加载数据和R包",
    "text": "3.1 加载数据和R包\nCox回归模型在医学统计中是一个很重要的统计方法，关于Cox比例风险模型，我写过一些实现方法的推文，大家可以参考：\n\nR语言生存分析：Cox回归\nR语言时依系数和时依协变量Cox回归\n\n\n# 加载需要的R包和数据\nlibrary(survival)\nlibrary(rms)\n## Loading required package: Hmisc\n## Loading required package: lattice\n## Loading required package: Formula\n## Loading required package: ggplot2\n## Warning: package 'ggplot2' was built under R version 4.2.3\n## \n## Attaching package: 'Hmisc'\n## The following objects are masked from 'package:base':\n## \n##     format.pval, units\n## Loading required package: SparseM\n## \n## Attaching package: 'SparseM'\n## The following object is masked from 'package:base':\n## \n##     backsolve\n\nrm(list = ls())\n\ndim(lung)\n## [1] 228  10\nstr(lung)\n## 'data.frame':    228 obs. of  10 variables:\n##  $ inst     : num  3 3 3 5 1 12 7 11 1 7 ...\n##  $ time     : num  306 455 1010 210 883 ...\n##  $ status   : num  2 2 1 2 2 1 2 2 2 2 ...\n##  $ age      : num  74 68 56 57 60 74 68 71 53 61 ...\n##  $ sex      : num  1 1 1 1 1 1 2 2 1 1 ...\n##  $ ph.ecog  : num  1 0 0 1 0 1 2 2 1 2 ...\n##  $ ph.karno : num  90 90 90 90 100 50 70 60 70 70 ...\n##  $ pat.karno: num  100 90 90 60 90 80 60 80 80 70 ...\n##  $ meal.cal : num  1175 1225 NA 1150 NA ...\n##  $ wt.loss  : num  NA 15 15 11 0 0 10 1 16 34 ..."
  },
  {
    "objectID": "nomogram-cox.html#方法1",
    "href": "nomogram-cox.html#方法1",
    "title": "3  Cox回归列线图绘制",
    "section": "3.2 方法1",
    "text": "3.2 方法1\n大多数情况下都是使用1代表死亡，0代表删失，下面这个演示数据集用2代表死亡。在这里没有影响，但有的R包会报错，需要注意！\n\n# 使用rms包需要对数据进行“打包”操作\ndd &lt;- datadist(lung)\noptions(datadist = \"dd\")\n\n构建cox比例风险模型：\n\ncoxfit &lt;- cph(Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno,\n              data = lung, x=T,y=T,surv = T\n              )\n\n# 构建生存函数，注意你的最大生存时间\nsurv &lt;- Survival(coxfit) \nsurv1 &lt;- function(x) surv(365,x) # 1年OS\nsurv2 &lt;- function(x) surv(365*2,x) # 2年OS\n\nnom &lt;- nomogram(coxfit,\n                fun = list(surv1,surv2),\n                lp = T,\n                funlabel = c('1-year survival Probability',\n                         '2-year survival Probability'),\n                maxscale = 100,\n                fun.at = c(0.95,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1))\n\n然后就是画图：\n\nplot(nom, \n     lplabel=\"Linear Predictor\",\n     xfrac = 0.2, # 左侧标签距离坐标轴的距离\n     #varname.label = TRUE, \n     tcl = -0.2, # 刻度长短和方向 \n     lmgp = 0.1, # 坐标轴标签距离坐标轴远近\n     points.label ='Points', \n     total.points.label = 'Total Points',\n     cap.labels = FALSE,\n     cex.var = 1, # 左侧标签字体大小\n     cex.axis = 1, # 坐标轴字体大小\n     col.grid = gray(c(0.8, 0.95))) # 竖线颜色"
  },
  {
    "objectID": "nomogram-cox.html#方法2",
    "href": "nomogram-cox.html#方法2",
    "title": "3  Cox回归列线图绘制",
    "section": "3.3 方法2",
    "text": "3.3 方法2\n使用这种方法会在你的Rstudio中弹出一个窗口，你可以自由调节其中给出的选项。\n\nlibrary(DynNom)\n\ncoxfit &lt;- cph(Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno,\n              data = lung, x=T,y=T,surv = T\n              )\n\nDynNom(coxfit,\n       DNxlab = \"Survival probability\",\n       KMtitle=\"Kaplan-Meier plot\", \n       KMxlab = \"Time (Days)\", \n       KMylab = \"Survival probability\")\n\n选择好你的参数，点击Predict即可出图：\n\n仔细看上面这个图其实有错误，sex作为性别，只有2种可能：男或女，所以只能是1或者2，不可能为小数，这就提醒我们在建立模型时需要把这样的变量先因子化。"
  },
  {
    "objectID": "nomogram-cox.html#方法3",
    "href": "nomogram-cox.html#方法3",
    "title": "3  Cox回归列线图绘制",
    "section": "3.4 方法3",
    "text": "3.4 方法3\n使用regplot包实现，这个包很强大，以后还会经常用到。\n\nlibrary(regplot)\n\ncoxfit &lt;- cph(Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno,\n              data = lung, x=T,y=T,surv = T\n              )\n\nregplot(coxfit,\n        #连续性变量形状，\"no plot\"\"density\"\"boxes\"\"ecdf\"\n        #\"bars\"\"boxplot\"\"violin\"\"bean\" \"spikes\"；\n        #分类变量的形状，可选\"no plot\" \"boxes\" \"bars\" \"spikes\"\n        plots = c(\"violin\", \"boxes\"), \n        observation = lung[1,], #用哪行观测，或者T F\n        center = T, # 对齐变量\n        subticks = T,\n        droplines = T,#是否画竖线\n        title = \"nomogram\",\n        points = T, # 截距项显示为0-100\n        odds = T, # 是否显示OR值\n        showP = T, # 是否显示变量的显著性标记\n        rank = \"sd\", # 根据sd给变量排序\n        interval=\"confidence\", # 展示可信区间\n        clickable = F # 是否可以交互\n        )\n## Regression  coxfit cph formula:\n## Surv(time, status) `~` age + sex + ph.ecog + ph.karno + pat.karno\n## CI: 0.931(4.82,57.5)\n## [[1]]\n##   pat.karno Points\n## 1        30     61\n## 2        50     49\n## 3        70     37\n## 4        90     25\n## \n## [[2]]\n##   ph.karno Points\n## 1       50      1\n## 2       60     11\n## 3       70     20\n## 4       80     29\n## 5       90     39\n## 6      100     48\n## \n## [[3]]\n##   ph.ecog Points\n## 1     0.0      0\n## 2     0.5     17\n## 3     1.0     33\n## 4     1.5     50\n## 5     2.0     67\n## 6     2.5     83\n## 7     3.0    100\n## \n## [[4]]\n##   sex Points\n## 1 1.0     45\n## 2 1.4     31\n## 3 1.8     18\n## \n## [[5]]\n##   age Points\n## 1  35     13\n## 2  45     20\n## 3  55     26\n## 4  65     33\n## 5  75     40\n## 6  85     47\n## \n## [[6]]\n##    Total Points Pr( time &lt; 267 )\n## 1            60           0.0889\n## 2            80           0.1225\n## 3           100           0.1676\n## 4           120           0.2271\n## 5           140           0.3034\n## 6           160           0.3981\n## 7           180           0.5097\n## 8           200           0.6324\n## 9           220           0.7546\n## 10          240           0.8609\n## 11          260           0.9373"
  },
  {
    "objectID": "nomogram-cox.html#方法4",
    "href": "nomogram-cox.html#方法4",
    "title": "3  Cox回归列线图绘制",
    "section": "3.5 方法4",
    "text": "3.5 方法4\n\nlibrary(VRPM)\nlibrary(survival)\n\ncox_fit &lt;- coxph(Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno,\n                 data = lung,\n                 model = T)\n\n# 图片保存在你的目录下\ncolplot(cox_fit,coloroptions = 3,filename = \"cox.png\")\n\n\n以上就是4种Cox回归列线图绘制的方法，其中方法1和3是最常用的。"
  },
  {
    "objectID": "nomogram-rcs.html#建立logistic模型",
    "href": "nomogram-rcs.html#建立logistic模型",
    "title": "4  样条回归列线图绘制",
    "section": "4.1 建立logistic模型",
    "text": "4.1 建立logistic模型\n\nlibrary(rms)\n## Loading required package: Hmisc\n## Loading required package: lattice\n## Loading required package: survival\n## Loading required package: Formula\n## Loading required package: ggplot2\n## Warning: package 'ggplot2' was built under R version 4.2.3\n## \n## Attaching package: 'Hmisc'\n## The following objects are masked from 'package:base':\n## \n##     format.pval, units\n## Loading required package: SparseM\n## \n## Attaching package: 'SparseM'\n## The following object is masked from 'package:base':\n## \n##     backsolve\n# 逻辑回归数据\ngetHdata(titanic3)\n\n# 使用rms前先把数据打包\ndd &lt;- datadist(titanic3); options(datadist='dd')\n\n# 逻辑回归的立方样条\nf &lt;- lrm(survived ~ rcs(sqrt(age),5) + sex, data=titanic3)\nf\n## Frequencies of Missing Values Due to Each Variable\n## survived      age      sex \n##        0      263        0 \n## \n## Logistic Regression Model\n## \n## lrm(formula = survived ~ rcs(sqrt(age), 5) + sex, data = titanic3)\n## \n## \n##                        Model Likelihood      Discrimination    Rank Discrim.    \n##                              Ratio Test             Indexes          Indexes    \n## Obs          1046    LR chi2     328.06      R2       0.363    C       0.794    \n##  0            619    d.f.             5     R2(5,1046)0.266    Dxy     0.587    \n##  1            427    Pr(&gt; chi2) &lt;0.0001    R2(5,758.1)0.347    gamma   0.593    \n## max |deriv| 2e-07                            Brier    0.168    tau-a   0.284    \n## \n##           Coef     S.E.    Wald Z Pr(&gt;|Z|)\n## Intercept   3.0936  0.5428   5.70 &lt;0.0001 \n## age        -0.6383  0.1771  -3.60 0.0003  \n## age'        1.5544  0.6527   2.38 0.0172  \n## age''     -12.1583  8.8925  -1.37 0.1715  \n## age'''     15.8326 16.9397   0.93 0.3500  \n## sex=male   -2.4944  0.1549 -16.10 &lt;0.0001"
  },
  {
    "objectID": "nomogram-rcs.html#画列线图",
    "href": "nomogram-rcs.html#画列线图",
    "title": "4  样条回归列线图绘制",
    "section": "4.2 画列线图",
    "text": "4.2 画列线图\n下面直接画图即可，没有任何难度，因为rms这个包把一切都给你做好了，不用自己操心，如果你做临床预测模型，是不可能绕开这个包的。\n\nnom &lt;- nomogram(f, fun=plogis,\n                 lp=T,\n                 funlabel=\"Risk of Death\")  \nplot(nom) \n\n\n\n\n这样RCS的列线图就画好了，关于一些参数的意义和细节的美化，可以参考前面的推文，这里就不多说了。\n既然logistic回归没问题，那COX回归自然也是没问题的！"
  },
  {
    "objectID": "nomogram-rcs.html#cox回归rcs的列线图",
    "href": "nomogram-rcs.html#cox回归rcs的列线图",
    "title": "4  样条回归列线图绘制",
    "section": "4.3 COX回归RCS的列线图",
    "text": "4.3 COX回归RCS的列线图\n\ndd &lt;- datadist(lung)\noptions(datadist = \"dd\")\n\n构建cox比例风险模型：\n\ncoxfit &lt;- cph(Surv(time, status) ~ rcs(sqrt(age),5) + sex,\n              data = lung, x=T,y=T,surv = T\n              )\n\n# 构建生存函数，注意你的最大生存时间\nsurv &lt;- Survival(coxfit) \nsurv1 &lt;- function(x) surv(365,x) # 1年OS\nsurv2 &lt;- function(x) surv(365*2,x) # 2年OS\n\nnom &lt;- nomogram(coxfit,\n                fun = list(surv1,surv2),\n                lp = T,\n                funlabel = c('1-year survival Probability',\n                         '2-year survival Probability')\n                )\n\nplot(nom)\n\n\n\n\n这就是COX回归RCS的列线图，关于一些参数的意义和细节的美化，可以参考前面的推文，这里就不多说了。\n是不是很简单？\n因为是演示数据，所以画出来的图不是很美观，但是实现方法就是这么简单！"
  },
  {
    "objectID": "nomogram-compete-risk.html#加载数据和r包",
    "href": "nomogram-compete-risk.html#加载数据和r包",
    "title": "5  竞争风险模型列线图绘制",
    "section": "5.1 加载数据和R包",
    "text": "5.1 加载数据和R包\n探讨骨髓移植和血液移植治疗白血病的疗效，结局事件定义为复发，某些患者因为移植不良反应死亡，定义为竞争风险事件。\n\nrm(list = ls())\ndata(\"bmtcrr\",package = \"casebase\")\nstr(bmtcrr)\n## 'data.frame':    177 obs. of  7 variables:\n##  $ Sex   : Factor w/ 2 levels \"F\",\"M\": 2 1 2 1 1 2 2 1 2 1 ...\n##  $ D     : Factor w/ 2 levels \"ALL\",\"AML\": 1 2 1 1 1 1 1 1 1 1 ...\n##  $ Phase : Factor w/ 4 levels \"CR1\",\"CR2\",\"CR3\",..: 4 2 3 2 2 4 1 1 1 4 ...\n##  $ Age   : int  48 23 7 26 36 17 7 17 26 8 ...\n##  $ Status: int  2 1 0 2 2 2 0 2 0 1 ...\n##  $ Source: Factor w/ 2 levels \"BM+PB\",\"PB\": 1 1 1 1 1 1 1 1 1 1 ...\n##  $ ftime : num  0.67 9.5 131.77 24.03 1.47 ...\n\n这个数据一共7个变量，177行。\n\nSex: 性别，F是女，M是男\nD: 疾病类型，ALL是急性淋巴细胞白血病，AML是急性髓系细胞白血病。\nPhase: 不同阶段，4个水平，CR1，CR2，CR3，Relapse。\nAge: 年龄。\nStatus: 结局变量，0=删失，1=复发，2=竞争风险事件。\nSource: 因子变量，2个水平：BM+PB(骨髓移植+血液移植)，PB(血液移植)。\nftime: 生存时间。\n\n\n# 竞争风险分析需要用的R包\nlibrary(cmprsk)\n## Loading required package: survival"
  },
  {
    "objectID": "nomogram-compete-risk.html#fine-gray检验单因素分析",
    "href": "nomogram-compete-risk.html#fine-gray检验单因素分析",
    "title": "5  竞争风险模型列线图绘制",
    "section": "5.2 Fine-Gray检验（单因素分析）",
    "text": "5.2 Fine-Gray检验（单因素分析）\n在普通的生存分析中，可以用log-rank检验做单因素分析，在竞争风险模型中，使用Fine-Gray检验进行单因素分析。\n\n比如现在我们想要比较不同疾病类型（D）有没有差异，可以进行Fine-Gray检验：\n\nbmtcrr$Status &lt;- factor(bmtcrr$Status)\nf &lt;- cuminc(bmtcrr$ftime, bmtcrr$Status, bmtcrr$D)\nf\n## Tests:\n##        stat         pv df\n## 1 2.8623325 0.09067592  1\n## 2 0.4481279 0.50322531  1\n## Estimates and Variances:\n## $est\n##              20        40        60        80       100       120\n## ALL 1 0.3713851 0.3875571 0.3875571 0.3875571 0.3875571 0.3875571\n## AML 1 0.2414530 0.2663827 0.2810390 0.2810390 0.2810390        NA\n## ALL 2 0.3698630 0.3860350 0.3860350 0.3860350 0.3860350 0.3860350\n## AML 2 0.4439103 0.4551473 0.4551473 0.4551473 0.4551473        NA\n## \n## $var\n##                20          40          60          80         100         120\n## ALL 1 0.003307032 0.003405375 0.003405375 0.003405375 0.003405375 0.003405375\n## AML 1 0.001801156 0.001995487 0.002130835 0.002130835 0.002130835          NA\n## ALL 2 0.003268852 0.003373130 0.003373130 0.003373130 0.003373130 0.003373130\n## AML 2 0.002430406 0.002460425 0.002460425 0.002460425 0.002460425          NA\n\n结果中1代表复发,2代表竞争风险事件。\n第一行统计量=2.8623325, P=0.09067592,表示在控制了竞争风险事件（即第二行计算的统计量和P值）后，两种疾病类型ALL和AML的累计复发风险无统计学差异P=0.09067592。\n第2行说明ALL和AML的累计竞争风险无统计学差异。\n$est表示估计的各时间点ALL和AML组的累计复发率与与累计竞争风险事件发生率（分别用1和2来区分，与第一行第二行一致）。\n$var表示估计的各时间点ALL和AML组的累计复发率与与累计竞争风险事件发生率的方差（分别用1和2来区分，与第一行第二行一致）。\n\n5.2.1 图形展示结果\n对于上述结果可以使用图形展示：\n\nplot(f,xlab = 'Month', ylab = 'CIF',lwd=2,lty=1,\n     col = c('red','blue','black','forestgreen'))\n\n\n\n\n图形解读：\n纵坐标表示累计发生率CIF，横坐标是时间。我们从ALL1对应的红色曲线和AML1对应的蓝色曲线可以得出，ALL组的复发风险较AML 组高，但无统计学意义，P=0.09067592。同理，ALL2对应的黑色曲线在AML2对应的草绿色曲线下方，我们可以得出，ALL组的竞争风险事件发生率较AML组低，同样无统计学意义，P=0.50322531。\n简单来讲，这个图可以用一句话来概括：在控制了竞争风险事件后，ALL和AML累计复发风险无统计学差异P=0.09067592。\n\n\n5.2.2 ggplot2\n这个图不好看，非常的不ggplot，所以我们要用ggplot2重新画它！所以首先要提取数据，因为数就是图，图就是数。但是万能的broom包竟然没有不能提取这个对象的数据，只能手动来，太不优雅了！\n\n# 提取数据\nALL1 &lt;- data.frame(ALL1_t = f[[1]][[1]], ALL1_C = f[[1]][[2]])\nAML1 &lt;- data.frame(AML1_t = f[[2]][[1]], AML1_C = f[[2]][[2]])\nALL2 &lt;- data.frame(ALL2_t = f[[3]][[1]], ALL2_C = f[[3]][[2]])\nAML2 &lt;- data.frame(AML2_t = f[[4]][[1]], AML2_C = f[[4]][[2]])\n\nlibrary(ggplot2)\n## Warning: package 'ggplot2' was built under R version 4.2.3\n\nggplot()+\n  geom_line(data = ALL1, aes(ALL1_t,ALL1_C))+\n  geom_line(data = ALL2, aes(ALL2_t,ALL2_C))+\n  geom_line(data = AML1, aes(AML1_t,AML1_C))+\n  geom_line(data = AML2, aes(AML2_t,AML2_C))+\n  labs(x=\"month\",y=\"cif\")+\n  theme_bw()\n\n\n\n\n但是这种不好上色，所以我们美化一下，变成长数据再画图即可。\n\ntmp &lt;- data.frame(month = c(ALL1$ALL1_t,AML1$AML1_t,ALL2$ALL2_t,AML2$AML2_t),\n                  cif = c(ALL1$ALL1_C,AML1$AML1_C,ALL2$ALL2_C,AML2$AML2_C),\n                  type = rep(c(\"ALL1\",\"AML1\",\"ALL2\",\"AML2\"), c(58,58,58,88))\n                  )\n\nggplot(tmp, aes(month, cif))+\n  geom_line(aes(color=type, group=type),size=1.2)+\n  theme_bw()+\n  theme(legend.position = \"top\")\n## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n## ℹ Please use `linewidth` instead."
  },
  {
    "objectID": "nomogram-compete-risk.html#竞争风险模型多因素分析",
    "href": "nomogram-compete-risk.html#竞争风险模型多因素分析",
    "title": "5  竞争风险模型列线图绘制",
    "section": "5.3 竞争风险模型（多因素分析）",
    "text": "5.3 竞争风险模型（多因素分析）\n做完了单因素分析，再看看竞争风险模型的多因素分析。\n首先要把自变量单独放在一个数据框里，使用中发现一个问题，这里如果把分类变量变为因子型不会自动进行哑变量编码，所以需要手动进行哑变量编码！\n但是我这里偷懒了，并没有进行哑变量设置！实际中是需要的哦！！\n\ncovs &lt;- subset(bmtcrr, select = - c(ftime,Status))\ncovs[,c(1:3,5)] &lt;- lapply(covs[,c(1:3,5)],as.integer)\n\nstr(covs)\n## 'data.frame':    177 obs. of  5 variables:\n##  $ Sex   : int  2 1 2 1 1 2 2 1 2 1 ...\n##  $ D     : int  1 2 1 1 1 1 1 1 1 1 ...\n##  $ Phase : int  4 2 3 2 2 4 1 1 1 4 ...\n##  $ Age   : int  48 23 7 26 36 17 7 17 26 8 ...\n##  $ Source: int  1 1 1 1 1 1 1 1 1 1 ...\n\n指定failcode=1, cencode=0, 分别代表结局事件1与截尾0，其他默认为竞争风险事件2。\n\n# 构建竞争风险模型\nf2 &lt;- crr(bmtcrr$ftime, bmtcrr$Status, covs, failcode=1, cencode=0)\nsummary(f2)\n## Competing Risks Regression\n## \n## Call:\n## crr(ftime = bmtcrr$ftime, fstatus = bmtcrr$Status, cov1 = covs, \n##     failcode = 1, cencode = 0)\n## \n##           coef exp(coef) se(coef)      z p-value\n## Sex     0.0494     1.051   0.2867  0.172 0.86000\n## D      -0.4860     0.615   0.3040 -1.599 0.11000\n## Phase   0.4144     1.514   0.1194  3.470 0.00052\n## Age    -0.0174     0.983   0.0118 -1.465 0.14000\n## Source  0.9526     2.592   0.5469  1.742 0.08200\n## \n##        exp(coef) exp(-coef)  2.5% 97.5%\n## Sex        1.051      0.952 0.599  1.84\n## D          0.615      1.626 0.339  1.12\n## Phase      1.514      0.661 1.198  1.91\n## Age        0.983      1.018 0.960  1.01\n## Source     2.592      0.386 0.888  7.57\n## \n## Num. cases = 177\n## Pseudo Log-likelihood = -267 \n## Pseudo likelihood ratio test = 23.6  on 5 df,\n\n结果解读：在控制了竞争分险事件后，phase变量，即疾病所处阶段是患者复发的独立影响因素(p =0.00052)。"
  },
  {
    "objectID": "nomogram-compete-risk.html#列线图",
    "href": "nomogram-compete-risk.html#列线图",
    "title": "5  竞争风险模型列线图绘制",
    "section": "5.4 列线图",
    "text": "5.4 列线图\nregplot包绘制列线图。但是它目前只适用coxph()、lm()和glm()返回的对象。\n因此我们需要对原数据集加权创建一个新数据集用于为竞争风险模型分析，使用mstate包中的crprep()创建加权数据集,然后使用coxph()对加权数据集进行竞争风险模型拟合，这样就可以画列线图了。\n首先是加载数据和R包：\n\nrm(list = ls())\ndata(\"bmtcrr\",package = \"casebase\") # 还是这个数据\n\nlibrary(mstate) # 加权用到的R包\n\nbmtcrr$id &lt;- 1:nrow(bmtcrr) # 创建id\n\n# phase变为2分类，不然列线图不好解释\nbmtcrr$Phase &lt;- factor(ifelse(bmtcrr$Phase==\"Relapse\",1,0)) \nstr(bmtcrr)\n## 'data.frame':    177 obs. of  8 variables:\n##  $ Sex   : Factor w/ 2 levels \"F\",\"M\": 2 1 2 1 1 2 2 1 2 1 ...\n##  $ D     : Factor w/ 2 levels \"ALL\",\"AML\": 1 2 1 1 1 1 1 1 1 1 ...\n##  $ Phase : Factor w/ 2 levels \"0\",\"1\": 2 1 1 1 1 2 1 1 1 2 ...\n##  $ Age   : int  48 23 7 26 36 17 7 17 26 8 ...\n##  $ Status: int  2 1 0 2 2 2 0 2 0 1 ...\n##  $ Source: Factor w/ 2 levels \"BM+PB\",\"PB\": 1 1 1 1 1 1 1 1 1 1 ...\n##  $ ftime : num  0.67 9.5 131.77 24.03 1.47 ...\n##  $ id    : int  1 2 3 4 5 6 7 8 9 10 ...\n\n然后是对原数据进行加权：\n\ndf.w &lt;- crprep(\"ftime\", \"Status\",\n               data=bmtcrr, \n               trans=c(1,2),# 要加权的变量，1表示结局事件，2表示竞争风险事件\n               cens=0, # 删失\n               id=\"id\",\n               \n               # 要保留的协变量\n               keep=c(\"Age\",\"Sex\",\"D\",\"Source\",\"Phase\"))\n\nhead(df.w)\n##   id Tstart Tstop status weight.cens Age Sex   D Source Phase count failcode\n## 1  1   0.00  0.67      2   1.0000000  48   M ALL  BM+PB     1     1        1\n## 2  1   0.67  9.50      2   1.0000000  48   M ALL  BM+PB     1     2        1\n## 3  1   9.50 13.07      2   0.9679938  48   M ALL  BM+PB     1     3        1\n## 4  1  13.07 17.23      2   0.8730924  48   M ALL  BM+PB     1     4        1\n## 5  1  17.23 20.83      2   0.8536904  48   M ALL  BM+PB     1     5        1\n## 6  1  20.83 28.53      2   0.8120469  48   M ALL  BM+PB     1     6        1\ndf.w$T&lt;- df.w$Tstop - df.w$Tstart\n\n上述代码已经创建一个加权数据集df.w，此时还需要选择failcode == 1的行，然后我们才可以在此数据集上使用coxph()函数进行竞争风险分析，不然最后画列线图会报错。\n\n# 参考资料\n# https://blog.csdn.net/zhongkeyuanchongqing/article/details/124086113\ndf.w2 &lt;- df.w[df.w$failcode == 1,]\n\n构建cox模型：\n\nm.crr&lt;- coxph(Surv(T,status==1)~Age+Sex+D+Source+Phase,\n             data=df.w2,\n             weight=weight.cens,\n             subset=failcode==1)\nsummary(m.crr)\n## Call:\n## coxph(formula = Surv(T, status == 1) ~ Age + Sex + D + Source + \n##     Phase, data = df.w2, weights = weight.cens, subset = failcode == \n##     1)\n## \n##   n= 686, number of events= 56 \n## \n##              coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)    \n## Age      -0.02174   0.97850  0.01172   0.01208 -1.800 0.071914 .  \n## SexM      0.10551   1.11128  0.27981   0.29571  0.357 0.721247    \n## DAML     -0.53163   0.58764  0.29917   0.30613 -1.737 0.082450 .  \n## SourcePB  1.06564   2.90269  0.53453   0.56000  1.903 0.057051 .  \n## Phase1    1.06140   2.89040  0.27870   0.28129  3.773 0.000161 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##          exp(coef) exp(-coef) lower .95 upper .95\n## Age         0.9785     1.0220    0.9556     1.002\n## SexM        1.1113     0.8999    0.6225     1.984\n## DAML        0.5876     1.7017    0.3225     1.071\n## SourcePB    2.9027     0.3445    0.9686     8.699\n## Phase1      2.8904     0.3460    1.6654     5.016\n## \n## Concordance= 0.737  (se = 0.037 )\n## Likelihood ratio test= 28.33  on 5 df,   p=3e-05\n## Wald test            = 27.27  on 5 df,   p=5e-05\n## Score (logrank) test = 30.49  on 5 df,   p=1e-05,   Robust = 20.2  p=0.001\n## \n##   (Note: the likelihood ratio and score tests assume independence of\n##      observations within a cluster, the Wald and robust score tests do not).\n\n接下来，我们可以使用regplot()函数绘制nomogram。其实你可以绘制多种不同的列线图，可以参考之前的推文：生存资料列线图的4种绘制方法\n\nlibrary(regplot)\nregplot(m.crr,\n        observation=df.w2[df.w2$id==25&df.w2$failcode==1,],\n        failtime = c(36, 60), \n        prfail = T, \n        droplines=T)\n## \"observation\" has &gt;1 row. The first  row provides plotted values\n## Regression  m.crr coxph formula:\n## Surv(T, status == 1) `~` Age + Sex + D + Source + Phase\n## Replicate integer weights assumed\n## Note: non-integer weights have been floored\n## [1] \"note: points tables not constructed unless points=TRUE \"\n\n\n在这个列线图中，将数据集中id=25的患者各协变量的取值映射到相应的得分，并计算总得分,并分别计算其在36个月和60个月的累计复发概率，此概率即为控制了竞争风险的累计复发概率，分别为：0.134和0.146。"
  },
  {
    "objectID": "calibration-qhscrnomo.html#安装",
    "href": "calibration-qhscrnomo.html#安装",
    "title": "38  竞争风险模型的校准曲线",
    "section": "38.1 安装",
    "text": "38.1 安装\n2选1：\n\ndevtools::install_github(\"ClevelandClinicQHS/QHScrnomo\")\ninstall.packages(\"QHScrnomo\")"
  },
  {
    "objectID": "calibration-qhscrnomo.html#准备数据",
    "href": "calibration-qhscrnomo.html#准备数据",
    "title": "38  竞争风险模型的校准曲线",
    "section": "38.2 准备数据",
    "text": "38.2 准备数据\n使用casebase中的bmtcrr数据，只使用其中的一部分，并且把字符型变成因子型。\n\nlibrary(QHScrnomo)\n## Warning: package 'QHScrnomo' was built under R version 4.2.3\n## Loading required package: rms\n## Loading required package: Hmisc\n## Loading required package: lattice\n## Loading required package: survival\n## Loading required package: Formula\n## Loading required package: ggplot2\n## Warning: package 'ggplot2' was built under R version 4.2.3\n## \n## Attaching package: 'Hmisc'\n## The following objects are masked from 'package:base':\n## \n##     format.pval, units\n## Loading required package: SparseM\n## \n## Attaching package: 'SparseM'\n## The following object is masked from 'package:base':\n## \n##     backsolve\n\ndata(\"bmtcrr\",package = \"casebase\")\nbmtcrr[,c(1,2,3,6)] &lt;- lapply(bmtcrr[,c(1,2,3,6)],as.factor)\nstr(bmtcrr)\n## 'data.frame':    177 obs. of  7 variables:\n##  $ Sex   : Factor w/ 2 levels \"F\",\"M\": 2 1 2 1 1 2 2 1 2 1 ...\n##  $ D     : Factor w/ 2 levels \"ALL\",\"AML\": 1 2 1 1 1 1 1 1 1 1 ...\n##  $ Phase : Factor w/ 4 levels \"CR1\",\"CR2\",\"CR3\",..: 4 2 3 2 2 4 1 1 1 4 ...\n##  $ Age   : int  48 23 7 26 36 17 7 17 26 8 ...\n##  $ Status: int  2 1 0 2 2 2 0 2 0 1 ...\n##  $ Source: Factor w/ 2 levels \"BM+PB\",\"PB\": 1 1 1 1 1 1 1 1 1 1 ...\n##  $ ftime : num  0.67 9.5 131.77 24.03 1.47 ..."
  },
  {
    "objectID": "calibration-qhscrnomo.html#拟合竞争风险模型",
    "href": "calibration-qhscrnomo.html#拟合竞争风险模型",
    "title": "38  竞争风险模型的校准曲线",
    "section": "38.3 拟合竞争风险模型",
    "text": "38.3 拟合竞争风险模型\n先使用rms拟合cox回归模型，这几个变量只是我随便挑选的，可能并不是完全适合~\n\ndd &lt;- datadist(bmtcrr)\noptions(datadist = \"dd\")\n\nfit &lt;- cph(Surv(ftime,Status == 1) ~ Sex + rcs(Age,3)+D+Phase, data = bmtcrr,\n           x = TRUE, y= TRUE, surv=TRUE, time.inc = 24)\n\n拟合好之后再使用crr.fit变为竞争风险模型，其实是借助了cmprsk::crr：\n\ncrr &lt;- crr.fit(fit = fit, cencode = 0, failcode = 1)\nclass(crr)\n## [1] \"cmprsk\" \"crr\"\nsummary(crr)\n##              Effects              Response : Surv(ftime, Status == 1) \n## \n##  Factor              Low High Diff. Effect    S.E.    Lower 0.95 Upper 0.95\n##  Age                 20  40   20    -0.337350 0.23489 -0.79772    0.12303  \n##   Hazard Ratio       20  40   20     0.713660      NA  0.45035    1.13090  \n##  Sex - F:M            2   1   NA     0.022279 0.28692 -0.54007    0.58463  \n##   Hazard Ratio        2   1   NA     1.022500      NA  0.58271    1.79430  \n##  D - ALL:AML          2   1   NA     0.363100 0.29546 -0.21599    0.94219  \n##   Hazard Ratio        2   1   NA     1.437800      NA  0.80575    2.56560  \n##  Phase - CR1:Relapse  4   1   NA    -1.135800 0.37803 -1.87670   -0.39488  \n##   Hazard Ratio        4   1   NA     0.321160      NA  0.15309    0.67376  \n##  Phase - CR2:Relapse  4   2   NA    -1.034200 0.35885 -1.73750   -0.33084  \n##   Hazard Ratio        4   2   NA     0.355520      NA  0.17596    0.71832  \n##  Phase - CR3:Relapse  4   3   NA    -0.914910 0.58559 -2.06260    0.23282  \n##   Hazard Ratio        4   3   NA     0.400550      NA  0.12712    1.26220\n\n可以用方差分析看看各个系数的显著性：\n\nanova(crr)\n##                 Wald Statistics          Response: Surv(ftime, Status == 1) \n## \n##  Factor     Chi-Square d.f. P     \n##  Sex         0.01      1    0.9381\n##  Age         2.25      2    0.3238\n##   Nonlinear  0.04      1    0.8510\n##  D           1.51      1    0.2191\n##  Phase      14.70      3    0.0021\n##  TOTAL      19.86      7    0.0059"
  },
  {
    "objectID": "calibration-qhscrnomo.html#内部验证",
    "href": "calibration-qhscrnomo.html#内部验证",
    "title": "38  竞争风险模型的校准曲线",
    "section": "38.4 内部验证",
    "text": "38.4 内部验证\n建立好模型之后，可以用tenf.crr对验证集进行交叉验证，查看感兴趣时间点的预测结果(死亡概率)，就相当于内部验证。\n\n# 默认10折交叉验证\nset.seed(123)\nbmtcrr$preds.tenf &lt;- tenf.crr(crr, time = 36, trace = FALSE)#可以计算线性预测值，可查看帮助文档\nstr(bmtcrr$preds.tenf)\n##  num [1:177] 0.485 0.171 0.284 0.299 0.206 ...\n\n结果是第36个月时，各个病人的死亡风险，而且是考虑到了竞争风险事件的。"
  },
  {
    "objectID": "calibration-qhscrnomo.html#计算c-index",
    "href": "calibration-qhscrnomo.html#计算c-index",
    "title": "38  竞争风险模型的校准曲线",
    "section": "38.5 计算C-index",
    "text": "38.5 计算C-index\n基于上面计算出的概率，计算cindex：\n\ncindex(prob = bmtcrr$preds.tenf,\n       fstatus = bmtcrr$Status,\n       ftime = bmtcrr$ftime,\n       type = \"crr\",\n       failcode = 1, cencode = 0\n       )\n##            N            n       usable   concordant       cindex \n##  177.0000000  177.0000000 8249.0000000 5092.0000000    0.6172869\n\ncindex=0.617，说明模型一般。"
  },
  {
    "objectID": "calibration-qhscrnomo.html#校准曲线",
    "href": "calibration-qhscrnomo.html#校准曲线",
    "title": "38  竞争风险模型的校准曲线",
    "section": "38.6 校准曲线",
    "text": "38.6 校准曲线\n也是基于上面计算出的cindex。\n\ngroupci(x = bmtcrr$preds.tenf,\n        ftime = bmtcrr$ftime,\n        fstatus = bmtcrr$Status,\n        g = 5, # 分成几组\n        u = 36, # 时间点\n        failcode = 1,\n        xlab = \"Predicted 3-year mortality\",\n        ylab = \"Actual 3-year mortality\"\n        )\n\n\n\n##              x  n events        ci    std.err\n## [1,] 0.1408630 36      8 0.2286706 0.07313371\n## [2,] 0.2021363 35      7 0.2114286 0.07429595\n## [3,] 0.2841367 36     10 0.2822421 0.07775400\n## [4,] 0.3876848 35     14 0.3714286 0.08458920\n## [5,] 0.5899486 35     17 0.4857143 0.08757744\n\n这个其实就是内部验证的校准曲线了，看起来还不错，因为是在训练集中，训练集的校准曲线其实说明不了任何问题。\n如果你觉得不好看可以使用给出的数据自己画，或者直接自己计算也可。可信区间是95%CI，可以通过pred.ci计算的。"
  },
  {
    "objectID": "calibration-qhscrnomo.html#列线图",
    "href": "calibration-qhscrnomo.html#列线图",
    "title": "38  竞争风险模型的校准曲线",
    "section": "38.7 列线图",
    "text": "38.7 列线图\n建立列线图，和rms包的使用一模一样：\n\nnomogram.crr(\n  fit = crr,\n  failtime = 36,\n  lp = T,\n  xfrac = 0.65,\n  fun.at = seq(0.2, 0.45, 0.05),\n  funlabel = \"Predicted 3-year risk\"\n)"
  },
  {
    "objectID": "calibration-qhscrnomo.html#生成模型方程",
    "href": "calibration-qhscrnomo.html#生成模型方程",
    "title": "38  竞争风险模型的校准曲线",
    "section": "38.8 生成模型方程",
    "text": "38.8 生成模型方程\n可以直接给出某个时间点的线性预测值的计算方程：\n\nsas.cmprsk(crr,time = 36)\n## Base failure probability by time = 36 is 0.3308 \n## - 0.022279144 * (Sex = \"M\") - 0.012796928 * Age - \n##     6.6881995e-06 * max(Age - 15.6, 0)**3 + 1.140514e-05 * max(Age - \n##     29, 0)**3 - 4.7169407e-06 * max(Age - 48, 0)**3 - 0.36310183 * \n##     (D = \"AML\") + 0.10164664 * (Phase = \"CR2\") + 0.22089946 * \n##     (Phase = \"CR3\") + 1.1358137 * (Phase = \"Relapse\")"
  },
  {
    "objectID": "calibration-qhscrnomo.html#外部验证测试集",
    "href": "calibration-qhscrnomo.html#外部验证测试集",
    "title": "38  竞争风险模型的校准曲线",
    "section": "38.9 外部验证（测试集）",
    "text": "38.9 外部验证（测试集）\n直接predict即可：\n\ntest_df &lt;- head(bmtcrr,50)#取前50个作为测试集\nprob &lt;- predict(crr, time = 36, newdata = test_df)\nhead(prob)\n## [1] 0.4344841 0.2052952 0.3610625 0.2712397 0.2336076 0.6261795\n\n有了概率又可以计算cindex了：\n\ncindex(prob = prob,\n       fstatus = test_df$Status,\n       ftime = test_df$ftime\n       )\n##           N           n      usable  concordant      cindex \n##  50.0000000  50.0000000 630.0000000 454.0000000   0.7206349\n\n还可以绘制校准曲线：\n\ngroupci(x = prob,\n        ftime = test_df$ftime,\n        fstatus = test_df$Status,\n        u = 36,\n        g = 5\n        )\n\n\n\n##              x  n events  ci   std.err\n## [1,] 0.1619231 10      1 0.1 0.1013889\n## [2,] 0.2478567 10      2 0.2 0.1545392\n## [3,] 0.3141252 10      4 0.4 0.1683094\n## [4,] 0.4561951 10      1 0.1 0.1023904\n## [5,] 0.6326698 10      7 0.7 0.1702254\n\n是不是很easy呢。"
  },
  {
    "objectID": "calibration-qhscrnomo.html#参考资料",
    "href": "calibration-qhscrnomo.html#参考资料",
    "title": "38  竞争风险模型的校准曲线",
    "section": "38.10 参考资料",
    "text": "38.10 参考资料\n\nhttps://github.com/ClevelandClinicQHS/QHScrnomo\nvignette(“QHScrnomo”)"
  },
  {
    "objectID": "dca-logistic.html#方法1",
    "href": "dca-logistic.html#方法1",
    "title": "39  分类数据的决策曲线分析",
    "section": "39.1 方法1",
    "text": "39.1 方法1\n使用rmda包。\n\n# 先安装R包\ninstall.packages(\"rmda\")\n\n使用这个包自带的一个dcaData，作为演示，这个数据集一共500行，6列，其中Cancer是结果变量，1代表患病，0代表没病，其余列是预测变量。\n\nlibrary(rmda)\n## Warning: package 'rmda' was built under R version 4.2.3\ndata(\"dcaData\")\n\ndim(dcaData) # 500,6\n## [1] 500   6\n\nhead(dcaData)\n## # A tibble: 6 × 6\n##     Age Female Smokes Marker1  Marker2 Cancer\n##   &lt;int&gt;  &lt;dbl&gt; &lt;lgl&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;int&gt;\n## 1    33      1 FALSE    0.245  1.02         0\n## 2    29      1 FALSE    0.943 -0.256        0\n## 3    28      1 FALSE    0.774  0.332        0\n## 4    27      0 FALSE    0.406 -0.00569      0\n## 5    23      1 FALSE    0.508  0.208        0\n## 6    35      1 FALSE    0.186  1.41         0\n\nstr(dcaData)\n## tibble [500 × 6] (S3: tbl_df/tbl/data.frame)\n##  $ Age    : int [1:500] 33 29 28 27 23 35 34 29 35 27 ...\n##  $ Female : num [1:500] 1 1 1 0 1 1 1 1 1 1 ...\n##  $ Smokes : logi [1:500] FALSE FALSE FALSE FALSE FALSE FALSE ...\n##  $ Marker1: num [1:500] 0.245 0.943 0.774 0.406 0.508 ...\n##  $ Marker2: num [1:500] 1.02108 -0.25576 0.33184 -0.00569 0.20753 ...\n##  $ Cancer : int [1:500] 0 0 0 0 0 0 0 0 0 0 ...\n\n使用起来非常简单，首先构建dca，然后画图：\n\nset.seed(123)\n \nfit1 &lt;- decision_curve(Cancer ~ Age + Female + Smokes, # R语言里常见的公式类型\n                       data = dcaData, \n                       study.design = \"cohort\", # 选择研究类型\n                       bootstraps = 50 # 重抽样次数\n                       )\n## Note:  The data provided is used to both fit a prediction model and to estimate the respective decision curve. This may cause bias in decision curve estimates leading to over-confidence in model performance.\n\n# 画图\nplot_decision_curve(fit1, curve.names = \"fit1\",\n                    cost.benefit.axis = F, # 是否需要损失：获益比 轴\n                    confidence.intervals = \"none\" # 不画可信区间\n                    )\n\n\n\n\n可以查看模型中的各个数据的值：\n\n# 数据很大，没有展示，大家可以自己运行看看\nsummary(fit1)\n\n多个模型的多条DCA曲线一起绘制也是可以的：\n\n# 新建立1个模型\nset.seed(123)\nfit2 &lt;- decision_curve(Cancer~Age + Female + Smokes + Marker1 + Marker2,\n              data = dcaData, \n              bootstraps = 50\n              )\n## Note:  The data provided is used to both fit a prediction model and to estimate the respective decision curve. This may cause bias in decision curve estimates leading to over-confidence in model performance.\n\n# 画图只要把多个模型放在1个列表中即可，还可以进行很多自定义调整\nplot_decision_curve(list(fit1, fit2),\n                    curve.names = c(\"fit1\", \"fit2\"), \n                    xlim = c(0, 1), # 可以设置x轴范围\n                    legend.position = \"topright\", # 图例位置,\n                    col = c(\"red\",\"blue\"), # 自定义颜色\n                    confidence.intervals = \"none\",\n                    lty = c(1,2), # 线型，注意顺序\n                    lwd = c(3,2,2,1) #注意顺序，先是自己的模型，然后All,然后None\n                    )\n## Note: When multiple decision curves are plotted, decision curves for 'All' are calculated using the prevalence from the first DecisionCurve object in the list provided.\n\n\n\n\n这个包还可以绘制临床影响曲线：\n\n# 1次只能绘制1个模型\nplot_clinical_impact(fit1,\n                     population.size= 1000,\n                     cost.benefit.axis = T,\n                     n.cost.benefits= 8,\n                     col=c('red','blue'),\n                     confidence.intervals= T,\n                     ylim=c(0,1000),\n                     legend.position=\"topright\")\n\n\n\n\n这就是这个包画DCA的例子，效果还是不错的，自定义设置也很多，方便大家画出更好看的图。这个包还有很多其他功能，我们就不演示了，感兴趣的小伙伴可以自己探索哦。美中不足的是不能画生存资料的DCA。"
  },
  {
    "objectID": "dca-logistic.html#方法2",
    "href": "dca-logistic.html#方法2",
    "title": "39  分类数据的决策曲线分析",
    "section": "39.2 方法2",
    "text": "39.2 方法2\n使用这个网站给出的dca.r文件绘制DCA，需要代码的直接去网站下载即可。\n\n\n\n\n\n\n注意\n\n\n\n这个网站已经不再提供该代码的下载，我把dca.r/stdca.r这两段代码已经放在粉丝QQ群文件，需要的加群下载即可。\n\n\n还是使用rmda包的数据，首先我们画一个简单的DCA，结果变量是Cancer，预测变量我们只用一个Smokes。使用起来非常简单，一句代码即可：\n\nsource(\"./datasets/dca.r\")\n\ndf &lt;- as.data.frame(dcaData)\n\ndd &lt;- dca(data = df, # 指定数据集,必须是data.frame类型\n    outcome=\"Cancer\", # 指定结果变量\n    predictors=\"Smokes\", # 指定预测变量\n    probability = F # Smokes这一列是0,1组成的二分类变量，不是概率，所以是F\n    )\n\n\n\n\n但是如果你的预测变量不是0,1这种，或者有多个的话，这个函数就比较蛋疼了，它需要你先把预测概率算出来，才能使用这个函数。\n\n# 建立包含多个自变量的logistic模型\nmodel &lt;- glm(Cancer ~ Age + Female + Smokes + Marker1 + Marker2, \n            family=binomial(),\n            data = df\n            )\n\n# 算出概率\ndf$prob &lt;- predict(model, type=\"response\")\n\n# 绘制多个预测变量的DCA\ndd &lt;- dca(data=df, outcome=\"Cancer\", predictors=\"prob\", \n    probability = T,\n    xstop=0.35 # 控制x轴范围\n    )\n\n\n\n\n把多个模型画在一起的方式也有点奇怪，比如我们下面演示下3个模型画在一起，其中prob代表的是上面的model模型，Marker2代表的是只有一个预测变量Marker2的模型，Smokes代表只有一个预测变量Smokes的模型！\nprob是概率，所以是T，Smokes和Marker2不是概率，所以是F。\n\ndd &lt;- dca(data = df, outcome=\"Cancer\", \n    predictors=c(\"prob\",\"Smokes\",\"Marker2\"), # 这是3个模型哦！\n    probability = c(T,F,F) # 和上面是对应的！\n    )\n## [1] \"Smokes converted to a probability with logistic regression. Due to linearity assumption, miscalibration may occur.\"\n## [1] \"Marker2 converted to a probability with logistic regression. Due to linearity assumption, miscalibration may occur.\""
  },
  {
    "objectID": "dca-logistic.html#方法3",
    "href": "dca-logistic.html#方法3",
    "title": "39  分类数据的决策曲线分析",
    "section": "39.3 方法3",
    "text": "39.3 方法3\n上面的方法自定义选项也很少，不利于美化图形。但是呢，有一个优点就是可以直接返回画图数据，我们只要稍加修改，就能使用ggplot2画图了！而且由于直接给出了源码，我们可以试着自己修改，这样可发挥的地方就太多了！\n下面几个将要介绍的方法，都是可以返回数据的，都支持使用ggplot2画图！\n下面我们返回2个模型的画图数据，自己稍加整理，然后使用ggplot2画DCA，大家如果只有1个模型或者更多的模型，道理都是一样的哦，就是整成ggplot2需要的格式就行了！\n\n# 返回模型1的画图数据\nsource(\"./datasets/dca.r\")\ndca_data1 &lt;- dca(data = df, \n    outcome=\"Cancer\", \n    predictors=\"prob\", \n    probability = T,\n    graph = F\n    )\n\n然后提取数据，数据转换：\n\n# 转换数据\nlibrary(tidyr)\n\ndca_df1 &lt;- dca_data1$net.benefit %&gt;% # 画图数据就藏在这里！\n  # 变成长数据,还不懂长宽数据转换这个超强操作的快去翻一下历史文章！\n  pivot_longer(cols = -threshold, names_to = \"type\", values_to = \"net_benefit\") \n\n# 看下数据结构\nstr(dca_df1)\n## tibble [297 × 3] (S3: tbl_df/tbl/data.frame)\n##  $ threshold  : num [1:297] 0.01 0.01 0.01 0.02 0.02 0.02 0.03 0.03 0.03 0.04 ...\n##  $ type       : chr [1:297] \"all\" \"none\" \"prob\" \"all\" ...\n##  $ net_benefit: num [1:297] 0.111 0 0.11 0.102 0 ...\n\n画图就是非常简单了，先给大家看看只画1个模型的例子：\n\nlibrary(ggplot2)\n## Warning: package 'ggplot2' was built under R version 4.2.3\nlibrary(ggsci)\n\n# 以prob这个模型为例\n\nggplot(dca_df1, aes(threshold, net_benefit, color = type))+\n  geom_line(linewidth = 1.2)+\n  scale_color_jama(name = \"Model Type\")+ # c(\"steelblue\",\"firebrick\",\"green4\")\n  scale_y_continuous(limits = c(-0.03,0.12),name = \"Net Benefit\")+\n  #限定y轴范围是重点，你可以去掉这句看看\n  scale_x_continuous(limits = c(0,1),name = \"Threshold Probility\")+\n  theme_bw(base_size = 16)+\n  theme(legend.position = c(0.8,0.8),\n        legend.background = element_blank()\n        )\n## Warning: Removed 85 rows containing missing values (`geom_line()`).\n\n\n\n\n看着是不是比上面的颜值都高些？是不是已经有了JAMA杂志的味道？\n下面是2个模型画在一起的例子，和上面的思路一模一样！\n\n# 构建模型2\nmod2 &lt;- glm(Cancer ~ Marker1 + Age + Smokes, df, family = binomial)\ndf$model2 &lt;- predict(mod2, type=\"response\")\n\n# 返回两个模型的画图数据\ndca12 &lt;- dca(data = df, \n             outcome=\"Cancer\", \n             predictors=c(\"prob\",\"model2\") ,\n             probability = c(T,T),\n             graph = F\n             )\n\n\n# 合并数据，大家可以打开这2个数据看下，可以直接合并\nlibrary(dplyr)\n## Warning: package 'dplyr' was built under R version 4.2.3\n## \n## Attaching package: 'dplyr'\n## The following objects are masked from 'package:stats':\n## \n##     filter, lag\n## The following objects are masked from 'package:base':\n## \n##     intersect, setdiff, setequal, union\n\ndca_df_all &lt;- dca12$net.benefit %&gt;% \n  pivot_longer(cols = -threshold,names_to = \"models\",values_to = \"net_benefit\")\n\nglimpse(dca_df_all)\n## Rows: 396\n## Columns: 3\n## $ threshold   &lt;dbl&gt; 0.01, 0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.02, 0.03, 0.03…\n## $ models      &lt;chr&gt; \"all\", \"none\", \"prob\", \"model2\", \"all\", \"none\", \"prob\", \"m…\n## $ net_benefit &lt;dbl&gt; 0.11111111, 0.00000000, 0.10957576, 0.11111111, 0.10204082…\n\n画图也是一样的简单：\n\nggplot(dca_df_all, aes(threshold, net_benefit, color = models))+\n  #geom_line(size = 1.2)+\n  stat_smooth(method = \"loess\", se = FALSE, formula = \"y ~ x\", span = 0.2)+ \n  # 灵感来自于方法5！\n  scale_color_jama(name = \"Model Type\")+\n  scale_y_continuous(limits = c(-0.03,0.12),name = \"Net Benefit\")+\n  scale_x_continuous(limits = c(0,1),name = \"Threshold Probility\")+\n  theme_bw(base_size = 16)+\n  theme(legend.position = c(0.8,0.75),\n        legend.background = element_blank()\n        )\n## Warning: Removed 85 rows containing non-finite values (`stat_smooth()`).\n## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n## : span too small.  fewer data values than degrees of freedom.\n## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n## : pseudoinverse used at 0.00935\n## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n## : neighborhood radius 0.01065\n## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n## : reciprocal condition number 0\n## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n## : There are other near singularities as well. 0.00011342\n\n\n\n\n挺好，还是不错的，能直接返回数据的都是可以高度自定义的，配合ggplot2，你可以尽情发挥。\n在今天推荐的所有方法中，这个方法我是最喜欢的，虽然只有一段代码，连个正经的R包都没有，但是很明显这个方法的潜力最大！只要你会自己修改，那这个方法就是万能的，适合很多模型的DCA绘制！"
  },
  {
    "objectID": "dca-logistic.html#方法4",
    "href": "dca-logistic.html#方法4",
    "title": "39  分类数据的决策曲线分析",
    "section": "39.4 方法4",
    "text": "39.4 方法4\n使用ggDCA包，和上面的提取数据再画图有点像，不过它给你简化了，一句代码即可，省事儿！\n\n# 安装R包，使用有问题的小伙伴请安装github版本\ninstall.packages(\"ggDCA\")\n\nremotes::install_github('yikeshu0611/ggDCA')\n\n还是使用rmda包里面自带的dcaData演示。\n\nlibrary(ggDCA)\n## \n## Attaching package: 'ggDCA'\n## The following object is masked _by_ '.GlobalEnv':\n## \n##     dca\nlibrary(rmda)\n\n# 构建模型\nfit1 &lt;- glm(Cancer ~ Age + Female + Smokes, data = dcaData, family = binomial())\n\nfit2 &lt;- glm(Cancer~Age + Female + Smokes + Marker1 + Marker2,\n              data = dcaData,family = binomial())\n\n画图，非常简洁！\n\nlibrary(ggplot2)\n\ndca1 &lt;- ggDCA::dca(fit1)\n\nggplot(dca1)\n## Warning: Removed 18 rows containing missing values (`geom_line()`).\n\n\n\n\n大家可以使用ggplot2语法继续修改细节，在此之前先给大家看看这个dca1的数据结构。\n\nstr(dca1)\n## Classes 'dca.lrm' and 'data.frame':  188 obs. of  5 variables:\n##  $ thresholds: num  0.021 0.0228 0.0251 0.0272 0.0298 ...\n##  $ TPR       : num  0.12 0.12 0.12 0.118 0.118 0.116 0.112 0.112 0.112 0.112 ...\n##  $ FPR       : num  0.88 0.85 0.832 0.806 0.784 0.758 0.732 0.7 0.67 0.648 ...\n##  $ NB        : num  0.1011 0.1001 0.0986 0.0955 0.0939 ...\n##  $ model     : Factor w/ 3 levels \"fit1\",\"All\",\"None\": 1 1 1 1 1 1 1 1 1 1 ...\n\n还自动算出了TPR和FPR，如果你想画ROC的话也是一句代码的事，咱就不演示了！就给大家演示下怎么自定义细节。\n\nggplot(dca1,linetype = 1,color = c(\"firebrick\",\"steelblue\",\"green4\"))+\n  theme(legend.position = c(0.8,0.75))\n## Warning: Removed 18 rows containing missing values (`geom_line()`).\n\n\n\n\n多个模型画在一起也是非常简单！\n\n# 2个模型画在一起\ndca12 &lt;- ggDCA::dca(fit1,fit2)\n\nggplot(dca12, linetype = 1,color = c(\"firebrick\",\"steelblue\",\"green4\",\"tomato\"))+\n  theme(legend.position = c(0.8,0.75))\n## Warning: Removed 131 rows containing missing values (`geom_line()`).\n\n\n\n\n简洁强大！"
  },
  {
    "objectID": "dca-logistic.html#方法5",
    "href": "dca-logistic.html#方法5",
    "title": "39  分类数据的决策曲线分析",
    "section": "39.5 方法5",
    "text": "39.5 方法5\n使用dcurves包。\n\n# 安装,2选1\ninstall.packages(\"dcurves\")\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"ddsjoberg/dcurves\")\n\n还是使用rmda包的dcaData数据进行演示。\n和dca.r的使用很像。废话不多说了，直接上 画2个模型DCA 的代码。\n\nlibrary(dcurves)\n## Warning: package 'dcurves' was built under R version 4.2.3\n## \n## Attaching package: 'dcurves'\n## The following object is masked _by_ '.GlobalEnv':\n## \n##     dca\n## The following object is masked from 'package:ggDCA':\n## \n##     dca\nlibrary(rmda)\ndata(\"dcaData\")\n\n# 建立2个模型，算出概率\nmod1 &lt;- glm(Cancer ~ Marker1 + Age + Smokes, dcaData, family = binomial)\ndcaData$model1 &lt;- predict(mod1, type=\"response\")\n\nmod2 &lt;- glm(Cancer ~ Marker1 + Marker2 + Age + Smokes + Female, \n            dcaData, family = binomial)\ndcaData$model2 &lt;- predict(mod2, type=\"response\")\n  \ndcurves::dca(Cancer ~ model1 + model2,\n             data = dcaData\n             ) %&gt;% \n  plot(smooth = T,\n       show_ggplot_code = T # 显示ggplot2代码，方便大家自己调整\n       )\n## Assuming '1' is [Event] and '0' is [non-Event]\n## # ggplot2 code to create DCA figure -------------------------------\n## as_tibble(x) %&gt;%\n##   dplyr::filter(!is.na(net_benefit)) %&gt;%\n##   ggplot(aes(x = threshold, y = net_benefit, color = label)) +\n##   stat_smooth(method = \"loess\", se = FALSE, formula = \"y ~ x\", \n##     span = 0.2) +\n##   coord_cartesian(ylim = c(-0.012, 0.12)) +\n##   scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n##   labs(x = \"Threshold Probability\", y = \"Net Benefit\", color = \"\") +\n##   theme_bw()\n\n\n\n\n大家看到ggplot2的代码了吧？自己调整就可以了。\n今天就给大家简单介绍下logistic回归DCA的5种画法，其实还有很多，留着以后再介绍吧，实在是写不动了。。除了常见的logistic、cox，其实随机森林、决策树、lasso、xgboost、SVM等很多模型都是可以绘制DCA的，更多进阶内容可以关注公众号查看。"
  },
  {
    "objectID": "cindex-compare.html#二分类资料c-index的比较",
    "href": "cindex-compare.html#二分类资料c-index的比较",
    "title": "27  C-index的比较",
    "section": "27.1 二分类资料C-index的比较",
    "text": "27.1 二分类资料C-index的比较\n二分类资料的AUC和C-index是一样的，所以可以参考Chapter 21关于ROC曲线的显著性检验。"
  },
  {
    "objectID": "cindex-compare.html#生存资料c-index的比较",
    "href": "cindex-compare.html#生存资料c-index的比较",
    "title": "27  C-index的比较",
    "section": "27.2 生存资料C-index的比较",
    "text": "27.2 生存资料C-index的比较\n可以使用compareC包，专门用来比较生存资料的C-index。\n\nrm(list = ls())\nlibrary(compareC)\n\n还是用之前推文的数据，获取数据可以查看历史推文。\n\nload(file = \"./datasets/timeROC.RData\")\nstr(df2)\n## 'data.frame':    297 obs. of  8 variables:\n##  $ event    : num  0 0 1 0 0 1 0 0 0 0 ...\n##  $ age      : int  59 63 65 73 59 66 56 42 61 48 ...\n##  $ riskScore: num  -0.249 -0.511 -0.211 -0.427 0.279 ...\n##  $ futime   : num  3.03 1.16 1.82 1.52 1.34 ...\n##  $ gender   : num  2 2 2 1 2 2 1 2 2 2 ...\n##  $ t        : num  4 4 4 3 3 3 5 3 NA 4 ...\n##  $ n        : num  1 5 1 1 1 1 3 1 NA 1 ...\n##  $ m        : num  1 1 1 1 1 3 1 1 3 3 ...\n\n只要提供4个参数：time，status，第一个指标，第二个指标，即可。\n\ncompareC(df2$futime,\n         df2$event,\n         df2$riskScore,\n         df2$age\n         )\n## $est.c\n##       Cxy       Cxz \n## 0.3383690 0.3894508 \n## \n## $est.diff_c\n## [1] -0.05108181\n## \n## $est.vardiff_c\n## [1] 0.002124315\n## \n## $est.varCxy\n## [1] 0.001046384\n## \n## $est.varCxz\n## [1] 0.00112578\n## \n## $est.cov\n## [1] 2.392402e-05\n## \n## $zscore\n## [1] -1.108299\n## \n## $pval\n## [1] 0.2677329\n\n第1行给出了2个C指数； 第2行是2个C指数相减的差值； 第3行是2个C指数方差相减的差值； 第4、5行是方差； 第6行是协方差； 第7、8行是z值和p值。"
  },
  {
    "objectID": "cindex-compare.html#两个cox模型的比较",
    "href": "cindex-compare.html#两个cox模型的比较",
    "title": "27  C-index的比较",
    "section": "27.3 两个cox模型的比较",
    "text": "27.3 两个cox模型的比较\n下面再多说一点两个cox模型的比较，也是很简单的，方差分析即可，使用anova()函数。\n我们用lung数据集进行演示。\n\nlibrary(survival)\nlibrary(dplyr)\n## Warning: package 'dplyr' was built under R version 4.2.3\n## \n## Attaching package: 'dplyr'\n## The following objects are masked from 'package:stats':\n## \n##     filter, lag\n## The following objects are masked from 'package:base':\n## \n##     intersect, setdiff, setequal, union\n\ndf1 &lt;- lung %&gt;% \n  mutate(status=ifelse(status == 1,1,0))\n\n建立两个cox模型：\n\ncox_fit1 &lt;- coxph(Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno,\n                  data = lung,x = T, y = T)\n\ncox_fit2 &lt;- coxph(Surv(time, status) ~ ph.ecog + ph.karno + pat.karno,\n                  data = lung,x = T, y = T)\n\n直接使用anova()即可：\n\nanova(cox_fit1,cox_fit2)\n## Analysis of Deviance Table\n##  Cox model: response is  Surv(time, status)\n##  Model 1: ~ age + sex + ph.ecog + ph.karno + pat.karno\n##  Model 2: ~ ph.ecog + ph.karno + pat.karno\n##    loglik  Chisq Df Pr(&gt;|Chi|)   \n## 1 -706.48                        \n## 2 -712.83 12.703  2   0.001745 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nrms包也带了一个lrtest()函数，也是直接构建两个cph模型即可进行比较，简单演示一下。\n\nsuppressMessages(library(rms))\n## Warning: package 'ggplot2' was built under R version 4.2.3\ndd &lt;- datadist(lung)\noptions(datadist=\"dd\")\n\ncox_fit1 &lt;- cph(Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno,\n                data = lung,x = T, y = T)\n\ncox_fit2 &lt;- cph(Surv(time, status) ~ ph.ecog + ph.karno + pat.karno,\n                data = lung,x = T, y = T)\n\nlrtest(cox_fit1,cox_fit2)\n## \n## Model 1: Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno\n## Model 2: Surv(time, status) ~ ph.ecog + ph.karno + pat.karno\n## \n##   L.R. Chisq         d.f.            P \n## 12.702485990  2.000000000  0.001744577\n\n可以看到P值是一样的~"
  },
  {
    "objectID": "roc-compare.html#二分类资料的roc比较",
    "href": "roc-compare.html#二分类资料的roc比较",
    "title": "21  ROC曲线的显著性检验",
    "section": "21.1 二分类资料的ROC比较",
    "text": "21.1 二分类资料的ROC比较\n可以通过pROC包实现的，使用其中roc.test()函数可实现两个ROC 的Delong检验。\n使用pROC包的aSAH数据，其中outcome列是结果变量，1代表Good，2代表Poor。\n\nlibrary(pROC)\n## Type 'citation(\"pROC\")' for a citation.\n## \n## Attaching package: 'pROC'\n## The following objects are masked from 'package:stats':\n## \n##     cov, smooth, var\n\ndata(aSAH)\ndim(aSAH)\n## [1] 113   7\n\nstr(aSAH)\n## 'data.frame':    113 obs. of  7 variables:\n##  $ gos6   : Ord.factor w/ 5 levels \"1\"&lt;\"2\"&lt;\"3\"&lt;\"4\"&lt;..: 5 5 5 5 1 1 4 1 5 4 ...\n##  $ outcome: Factor w/ 2 levels \"Good\",\"Poor\": 1 1 1 1 2 2 1 2 1 1 ...\n##  $ gender : Factor w/ 2 levels \"Male\",\"Female\": 2 2 2 2 2 1 1 1 2 2 ...\n##  $ age    : int  42 37 42 27 42 48 57 41 49 75 ...\n##  $ wfns   : Ord.factor w/ 5 levels \"1\"&lt;\"2\"&lt;\"3\"&lt;\"4\"&lt;..: 1 1 1 1 3 2 5 4 1 2 ...\n##  $ s100b  : num  0.13 0.14 0.1 0.04 0.13 0.1 0.47 0.16 0.18 0.1 ...\n##  $ ndka   : num  3.01 8.54 8.09 10.42 17.4 ...\n\n构建两个ROC对象，然后直接比较即可：\n\nroc1 &lt;- roc(aSAH$outcome,aSAH$s100b)\n## Setting levels: control = Good, case = Poor\n## Setting direction: controls &lt; cases\nroc2 &lt;- roc(aSAH$outcome,aSAH$ndka)\n## Setting levels: control = Good, case = Poor\n## Setting direction: controls &lt; cases\n\nres &lt;- roc.test(roc1,roc2)\nres\n## \n##  DeLong's test for two correlated ROC curves\n## \n## data:  roc1 and roc2\n## Z = 1.3908, p-value = 0.1643\n## alternative hypothesis: true difference in AUC is not equal to 0\n## 95 percent confidence interval:\n##  -0.04887061  0.28769174\n## sample estimates:\n## AUC of roc1 AUC of roc2 \n##   0.7313686   0.6119580\n\n这个函数里面有个method参数：delong/bootstrap/venkatraman，默认是delong，delong和bootstrap用于比较AUC，如果只是ROC曲线的比较，需要用venkatraman。关于这几种方法的具体原理，大家可以去翻相关的论文~\nroc.test只能用于两个ROC的比较，如果是多个比较，可以使用MedCalc软件，这个是和SPSS类似的软件，只要点点点即可。\n当然也是可以直接画在图里的：\n\nrocobj1 &lt;- plot.roc(aSAH$outcome, aSAH$s100,percent=TRUE, col=\"#1c61b6\")\n## Setting levels: control = Good, case = Poor\n## Setting direction: controls &lt; cases\nrocobj2 &lt;- lines.roc(aSAH$outcome, aSAH$ndka, percent=TRUE, col=\"#008600\")\n## Setting levels: control = Good, case = Poor\n## Setting direction: controls &lt; cases\n\nlegend(\"bottomright\", legend=c(\"S100B\", \"NDKA\"), col=c(\"#1c61b6\", \"#008600\"), lwd=2)\n\ntestobj &lt;- roc.test(rocobj1, rocobj2)\n\ntext(50, 50, labels=paste(\"p-value =\", format.pval(testobj$p.value)), adj=c(0, .5))\n\n\n\n\n当然你也可以用其他非参数检验的方法进行比较，比如mann whitney u检验。"
  },
  {
    "objectID": "roc-compare.html#生存资料roc的比较",
    "href": "roc-compare.html#生存资料roc的比较",
    "title": "21  ROC曲线的显著性检验",
    "section": "21.2 生存资料ROC的比较",
    "text": "21.2 生存资料ROC的比较\n使用timeROC包实现。\n还是用之前推文中用过的例子，获取数据请翻看之前的推文~\n\nrm(list = ls())\nlibrary(timeROC)\nlibrary(survival)\n\nload(file = \"./datasets/timeROC.RData\")\n\n使用其中的df2这个数据：\n\nstr(df2)\n## 'data.frame':    297 obs. of  8 variables:\n##  $ event    : num  0 0 1 0 0 1 0 0 0 0 ...\n##  $ age      : int  59 63 65 73 59 66 56 42 61 48 ...\n##  $ riskScore: num  -0.249 -0.511 -0.211 -0.427 0.279 ...\n##  $ futime   : num  3.03 1.16 1.82 1.52 1.34 ...\n##  $ gender   : num  2 2 2 1 2 2 1 2 2 2 ...\n##  $ t        : num  4 4 4 3 3 3 5 3 NA 4 ...\n##  $ n        : num  1 5 1 1 1 1 3 1 NA 1 ...\n##  $ m        : num  1 1 1 1 1 3 1 1 3 3 ...\n\n构建几个timeROC:\n\n# riskScore的ROC曲线\nROC.risk &lt;- timeROC(T=df2$futime,\n                    delta=df2$event,   \n                    marker=df2$riskScore,   \n                    cause=1,                \n                    weighting=\"marginal\",   \n                    times=3,  # c(1,2) \n                    iid=TRUE)\n\n\n# age的ROC曲线\nROC.age &lt;- timeROC(T=df2$futime,   \n                   delta=df2$event,   \n                   marker=df2$age,   \n                   cause=1,   \n                   weighting=\"marginal\",   \n                   times=3,   # c(1,2)\n                   iid=TRUE)\n\n比较就用compare()函数即可：\n\ncompare(ROC.risk, ROC.age)\n## $p_values_AUC\n##       t=0       t=3 \n##        NA 0.4544231\n\n同时使用多个时间点也是可以的：\n\n# riskScore的ROC曲线\nROC.risk &lt;- timeROC(T=df2$futime,\n                    delta=df2$event,   \n                    marker=df2$riskScore,   \n                    cause=1,                \n                    weighting=\"marginal\",   \n                    times=c(1,2),\n                    iid=TRUE)\n\n\n# age的ROC曲线\nROC.age &lt;- timeROC(T=df2$futime,   \n                   delta=df2$event,   \n                   marker=df2$age,   \n                   cause=1,   \n                   weighting=\"marginal\",   \n                   times=c(1,2),\n                   iid=TRUE)\n\ncompare(ROC.risk, ROC.age)\n## $p_values_AUC\n##        t=1        t=2 \n## 0.09758546 0.27995259\n\ncompare(ROC.risk, ROC.age, adjusted = T) # 计算调整p值\n## $p_values_AUC\n##                     t=1       t=2\n## Non-adjusted 0.09758546 0.2799526\n## Adjusted     0.14983636 0.3984702\n## \n## $Cor\n##           [,1]      [,2]\n## [1,] 1.0000000 0.7750774\n## [2,] 0.7750774 1.0000000\n\n画图就不演示了，可以参考前面的内容。"
  },
  {
    "objectID": "cindex.html#logistic回归的c-statistic",
    "href": "cindex.html#logistic回归的c-statistic",
    "title": "26  C-index的计算",
    "section": "26.1 logistic回归的C-statistic",
    "text": "26.1 logistic回归的C-statistic\n今天学习C-index的4种计算方法，在二分类变量中，C-statistic就是AUC，二者在数值上是一样的。\n使用lowbirth数据集，这个数据集是关于低出生体重儿是否会死亡的数据集，其中dead这一列是结果变量，0代表死亡，1代表存活，其余列都是预测变量。数据的预处理和之前一样。\n\nrm(list = ls())\nlowbirth &lt;- read.csv(\"./datasets/lowbirth.csv\")\n\nlibrary(dplyr)\n## Warning: package 'dplyr' was built under R version 4.2.3\n## \n## Attaching package: 'dplyr'\n## The following objects are masked from 'package:stats':\n## \n##     filter, lag\n## The following objects are masked from 'package:base':\n## \n##     intersect, setdiff, setequal, union\n\ntmp &lt;- lowbirth %&gt;% \n  mutate(across(where(is.character),as.factor),\n         vent = factor(vent),\n         black = ifelse(race == \"black\",1,0),\n         white = ifelse(race == \"white\",1,0),\n         other = ifelse(race %in% c(\"native American\",\"oriental\"),1,0)\n         ) %&gt;% \n  select(- race)\n\nglimpse(tmp)\n## Rows: 565\n## Columns: 12\n## $ birth    &lt;dbl&gt; 81.514, 81.552, 81.558, 81.593, 81.610, 81.624, 81.626, 81.68…\n## $ lowph    &lt;dbl&gt; 7.250000, 7.059998, 7.250000, 6.969997, 7.320000, 7.160000, 7…\n## $ pltct    &lt;int&gt; 244, 114, 182, 54, 282, 153, 229, 182, 361, 378, 255, 186, 26…\n## $ bwt      &lt;int&gt; 1370, 620, 1480, 925, 1255, 1350, 1310, 1110, 1180, 970, 770,…\n## $ delivery &lt;fct&gt; abdominal, vaginal, vaginal, abdominal, vaginal, abdominal, v…\n## $ apg1     &lt;int&gt; 7, 1, 8, 5, 9, 4, 6, 6, 6, 2, 4, 8, 1, 8, 5, 9, 9, 9, 6, 2, 1…\n## $ vent     &lt;fct&gt; 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1…\n## $ sex      &lt;fct&gt; female, female, male, female, female, female, male, male, mal…\n## $ dead     &lt;int&gt; 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n## $ black    &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0…\n## $ white    &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1…\n## $ other    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n26.1.1 方法1\n使用rms包构建模型，模型结果中Rank Discrim.下面的C 就是C-Statistic，本模型中C-Statistic = 0.879。\n\nlibrary(rms)\n## Loading required package: Hmisc\n## Loading required package: lattice\n## Loading required package: survival\n## Loading required package: Formula\n## Loading required package: ggplot2\n## Warning: package 'ggplot2' was built under R version 4.2.3\n## \n## Attaching package: 'Hmisc'\n## The following objects are masked from 'package:dplyr':\n## \n##     src, summarize\n## The following objects are masked from 'package:base':\n## \n##     format.pval, units\n## Loading required package: SparseM\n## \n## Attaching package: 'SparseM'\n## The following object is masked from 'package:base':\n## \n##     backsolve\n\ndd &lt;- datadist(tmp)\noptions(datadist=\"dd\")\n\nfit2 &lt;- lrm(dead ~ birth + lowph + pltct + bwt + vent + black + white,\n            data = tmp,x=T,y=T)\n\nfit2\n## Logistic Regression Model\n## \n## lrm(formula = dead ~ birth + lowph + pltct + bwt + vent + black + \n##     white, data = tmp, x = T, y = T)\n## \n##                        Model Likelihood      Discrimination    Rank Discrim.    \n##                              Ratio Test             Indexes          Indexes    \n## Obs           565    LR chi2     167.56      R2       0.432    C       0.879    \n##  0            471    d.f.             7      R2(7,565)0.247    Dxy     0.759    \n##  1             94    Pr(&gt; chi2) &lt;0.0001    R2(7,235.1)0.495    gamma   0.759    \n## max |deriv| 1e-06                            Brier    0.095    tau-a   0.211    \n## \n##           Coef    S.E.    Wald Z Pr(&gt;|Z|)\n## Intercept 38.3815 11.0303  3.48  0.0005  \n## birth     -0.1201  0.0914 -1.31  0.1890  \n## lowph     -4.1451  1.1881 -3.49  0.0005  \n## pltct     -0.0017  0.0019 -0.91  0.3644  \n## bwt       -0.0031  0.0006 -5.14  &lt;0.0001 \n## vent=1     2.7526  0.7436  3.70  0.0002  \n## black      1.1974  0.8448  1.42  0.1564  \n## white      0.8597  0.8655  0.99  0.3206\n\n\n\n26.1.2 方法2\nROCR包计算AUC，logistic回归的AUC就是C-statistic。这种方法和SPSS得到的一样。\n\nlibrary(ROCR)\n\ntmp$predvalue&lt;-predict(fit2)\n\n# 取出C-Statistics，和上面结果一样\npred &lt;- prediction(tmp$predvalue, tmp$dead)\n\nauc &lt;- round(performance(pred, \"auc\")@y.values[[1]],digits = 4)\n\n这个包也是用来画ROC曲线常用的包，可以根据上面的结果直接画出ROC曲线：\n\nperf &lt;- performance(pred,\"tpr\",\"fpr\")\nplot(perf,col=\"tomato\",lwd=2)\nabline(0,1,lty=2, col=\"grey\")\n\n\n\n\n\n\n26.1.3 方法3\npROC包计算AUC，这个包也是画ROC曲线常用的R包，但是这个包在使用时需要注意，这部分内容会在后面详细介绍。\n\nlibrary(pROC)\n## Type 'citation(\"pROC\")' for a citation.\n## \n## Attaching package: 'pROC'\n## The following objects are masked from 'package:stats':\n## \n##     cov, smooth, var\n\n# 计算AUC，也就是C-statistic\nroc(tmp$dead, tmp$predvalue, legacy.axes = T, print.auc = T, print.auc.y = 45)\n## Setting levels: control = 0, case = 1\n## Setting direction: controls &lt; cases\n## \n## Call:\n## roc.default(response = tmp$dead, predictor = tmp$predvalue, legacy.axes = T,     print.auc = T, print.auc.y = 45)\n## \n## Data: tmp$predvalue in 471 controls (tmp$dead 0) &lt; 94 cases (tmp$dead 1).\n## Area under the curve: 0.8794\n\n也是可以直接画法ROC曲线的：\n\nroc.plot &lt;- roc(tmp$dead, tmp$predvalue)\n## Setting levels: control = 0, case = 1\n## Setting direction: controls &lt; cases\n\nplot(roc.plot,legacy.axes=T)\n\n\n\n\n\n\n26.1.4 方法4\n使用Hmisc包。结果中的C就是C-Statistic。\n\nlibrary(Hmisc)\nsomers2(tmp$predvalue, tmp$dead)\n##           C         Dxy           n     Missing \n##   0.8793875   0.7587749 565.0000000   0.0000000"
  },
  {
    "objectID": "cindex.html#cox回归的c-statistic",
    "href": "cindex.html#cox回归的c-statistic",
    "title": "26  C-index的计算",
    "section": "26.2 cox回归的C-statistic",
    "text": "26.2 cox回归的C-statistic\ncox回归的C-statistic可以用survival包计算，需要注意，生存分析的C-statistic和AUC是不一样的。\n使用survival包自带的lung数据集进行演示。\n\nlibrary(survival)\nlibrary(dplyr)\n\ndf1 &lt;- lung %&gt;% \n  mutate(status=ifelse(status == 1,1,0))\n\nstr(lung)\n## 'data.frame':    228 obs. of  10 variables:\n##  $ inst     : num  3 3 3 5 1 12 7 11 1 7 ...\n##  $ time     : num  306 455 1010 210 883 ...\n##  $ status   : num  2 2 1 2 2 1 2 2 2 2 ...\n##  $ age      : num  74 68 56 57 60 74 68 71 53 61 ...\n##  $ sex      : num  1 1 1 1 1 1 2 2 1 1 ...\n##  $ ph.ecog  : num  1 0 0 1 0 1 2 2 1 2 ...\n##  $ ph.karno : num  90 90 90 90 100 50 70 60 70 70 ...\n##  $ pat.karno: num  100 90 90 60 90 80 60 80 80 70 ...\n##  $ meal.cal : num  1175 1225 NA 1150 NA ...\n##  $ wt.loss  : num  NA 15 15 11 0 0 10 1 16 34 ...\n\nR语言自带的coxph函数即可给出C-index，非常简单：\n\ncox_fit1 &lt;- coxph(Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno,\n              data = lung,x = T, y = T)\n\nsummary(cox_fit1)\n## Call:\n## coxph(formula = Surv(time, status) ~ age + sex + ph.ecog + ph.karno + \n##     pat.karno, data = lung, x = T, y = T)\n## \n##   n= 223, number of events= 160 \n##    (5 observations deleted due to missingness)\n## \n##                coef exp(coef)  se(coef)      z Pr(&gt;|z|)   \n## age        0.011383  1.011448  0.009510  1.197  0.23134   \n## sex       -0.561464  0.570373  0.170689 -3.289  0.00100 **\n## ph.ecog    0.565533  1.760386  0.186716  3.029  0.00245 **\n## ph.karno   0.015853  1.015979  0.009853  1.609  0.10762   \n## pat.karno -0.010111  0.989940  0.006881 -1.470  0.14169   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##           exp(coef) exp(-coef) lower .95 upper .95\n## age          1.0114     0.9887    0.9928     1.030\n## sex          0.5704     1.7532    0.4082     0.797\n## ph.ecog      1.7604     0.5681    1.2209     2.538\n## ph.karno     1.0160     0.9843    0.9965     1.036\n## pat.karno    0.9899     1.0102    0.9767     1.003\n## \n## Concordance= 0.647  (se = 0.025 )\n## Likelihood ratio test= 32.9  on 5 df,   p=4e-06\n## Wald test            = 33  on 5 df,   p=4e-06\n## Score (logrank) test = 33.79  on 5 df,   p=3e-06\n\nConcordance就是C-statistic，本次示例中为0.647。\n以上就是C-statistic的计算。\n获取lowbirth数据请在公众号：医学和生信笔记 后台回复20220520"
  },
  {
    "objectID": "feature-selection_unimulti.html#准备数据",
    "href": "feature-selection_unimulti.html#准备数据",
    "title": "12  变量筛选之先单后多",
    "section": "12.1 准备数据",
    "text": "12.1 准备数据\n我们使用TCGA-BLCA的lncRNA数据，其中包括408个样本，time_months是生存时间，event是生存状态，1代表死亡，0代表生存，其余变量都是自变量。\n先简单处理一下数据：\n\nrm(list = ls())\nload(file = \"datasets/lnc_expr_clin.RData\")\n#去掉没有生存信息的样本\nlnc_expr_clin1 &lt;- lnc_expr_clin[!is.na(lnc_expr_clin$time_months),]\nlnc_expr_clin1 &lt;- lnc_expr_clin1[lnc_expr_clin1$time_months&gt;0,]\n\n#选择其中一部分数据\ndat.cox &lt;- lnc_expr_clin1[,c(72:73,1:59)]\ndim(dat.cox)\n## [1] 297  61\ndat.cox[1:4,1:6]\n##   event time_months   PGM5-AS1 LINC01082 AC005180.2 AC005180.1\n## 1     0       36.33 0.15064007 0.2642238  0.0000000  0.1547768\n## 2     0       13.87 0.06309362 0.1666554  0.3105983  0.2436603\n## 3     1       21.83 2.16399508 3.5662920  2.2454129  2.0073496\n## 4     0       18.20 2.73075081 1.7314314  0.8609916  0.7323014\n\n现在这个数据一共59个自变量，我们先对每一个自变量都做一遍单因素COX回归，但是要注意，这里的59个自变量都是连续型的，通常基因表达量增加1，死亡风险增加xx倍这种情况是不可能发生的，这样的结果解释也是不合理的，所以我们需要先把这样的变量重新分箱，比如根据中位数分成两组，再进行单因素COX回归。\n\ndat_cox &lt;- dat.cox\ndat_cox[,c(3:ncol(dat_cox))] &lt;- sapply(dat_cox[,c(3:ncol(dat_cox))],function(x){\n  ifelse(x&gt;median(x),\"high\",\"low\")\n})\ndat_cox[,c(3:ncol(dat_cox))] &lt;- lapply(dat_cox[,c(3:ncol(dat_cox))],factor)\ndat_cox[1:4,1:6]\n##   event time_months PGM5-AS1 LINC01082 AC005180.2 AC005180.1\n## 1     0       36.33     high       low        low        low\n## 2     0       13.87      low       low       high       high\n## 3     1       21.83     high      high       high       high\n## 4     0       18.20     high      high       high       high"
  },
  {
    "objectID": "feature-selection_unimulti.html#批量单因素cox",
    "href": "feature-selection_unimulti.html#批量单因素cox",
    "title": "12  变量筛选之先单后多",
    "section": "12.2 批量单因素cox",
    "text": "12.2 批量单因素cox\n然后就可以对每个变量进行单因素COX分析了：\n\nlibrary(survival)\n\ngene &lt;- colnames(dat_cox)[-c(1:2)]\ncox.result &lt;- list()\nfor (i in 1:length(gene)) {\n      #print(i)\n      group &lt;- dat_cox[, i + 2]\n      if (length(table(group)) == 1) next\n      #if (length(grep(\"high\", group)) &lt; min_sample_size) next\n      #if (length(grep(\"low\", group)) &lt; min_sample_size) next\n      x &lt;- survival::coxph(survival::Surv(time_months, event) ~ group, \n                           data = dat_cox)\n      tmp1 &lt;- broom::tidy(x, exponentiate = T, conf.int = T)\n      cox.result[[i]] &lt;- c(gene[i], tmp1)\n    }\n\nres.cox &lt;- data.frame(do.call(rbind, cox.result))\n\n筛选出P值小于0.1的变量：\n\nlibrary(dplyr)\n## Warning: package 'dplyr' was built under R version 4.2.3\n\nunifea &lt;- res.cox %&gt;% \n  filter(p.value&lt;0.1) %&gt;% \n  pull(V1) %&gt;% \n  unlist()\nunifea\n##  [1] \"AC005180.2\"   \"AC005180.1\"   \"AC053503.3\"   \"MIR100HG\"     \"AP001107.5\"  \n##  [6] \"C5orf66-AS1\"  \"AL162424.1\"   \"ADAMTS9-AS1\"  \"MIR200CHG\"    \"AC093010.3\"  \n## [11] \"AC079313.2\"   \"SNHG25\"       \"AL049555.1\"   \"MIR1-1HG-AS1\" \"SPINT1-AS1\"  \n## [16] \"KRT7-AS\"      \"HAND2-AS1\"    \"AC025575.2\"   \"MAFG-DT\"      \"AL390719.2\"  \n## [21] \"AC002398.2\"   \"AL161431.1\"   \"U62317.1\"     \"AL023284.4\"   \"AATBC\""
  },
  {
    "objectID": "feature-selection_unimulti.html#多因素cox",
    "href": "feature-selection_unimulti.html#多因素cox",
    "title": "12  变量筛选之先单后多",
    "section": "12.3 多因素cox",
    "text": "12.3 多因素cox\n把这些变量进行多因素COX回归\n\nsub_dat &lt;- dat_cox[,c(\"time_months\",\"event\",unifea)]\ndim(sub_dat)\n## [1] 297  27\nsub_dat[1:4,1:6]\n##   time_months event AC005180.2 AC005180.1 AC053503.3 MIR100HG\n## 1       36.33     0        low        low        low      low\n## 2       13.87     0       high       high       high      low\n## 3       21.83     1       high       high       high     high\n## 4       18.20     0       high       high       high     high\n\n拟合多因素cox回归模型并查看结果：\n\nfinal.fit &lt;- coxph(Surv(time_months,event)~., data = sub_dat)\nres &lt;- broom::tidy(final.fit)\nres\n## # A tibble: 25 × 5\n##    term             estimate std.error statistic p.value\n##    &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n##  1 AC005180.2low      0.146      0.413     0.354 0.723  \n##  2 AC005180.1low     -0.343      0.399    -0.859 0.390  \n##  3 AC053503.3low     -0.139      0.391    -0.355 0.723  \n##  4 MIR100HGlow       -0.365      0.366    -0.997 0.319  \n##  5 AP001107.5low      0.284      0.344     0.825 0.409  \n##  6 `C5orf66-AS1`low  -0.538      0.284    -1.89  0.0587 \n##  7 AL162424.1low      0.0418     0.335     0.125 0.901  \n##  8 `ADAMTS9-AS1`low  -0.947      0.360    -2.63  0.00853\n##  9 MIR200CHGlow       0.0336     0.329     0.102 0.919  \n## 10 AC093010.3low      0.905      0.323     2.80  0.00505\n## # ℹ 15 more rows\n\n查看P值小于0.05的变量：结果只有5个\n\nres %&gt;% filter(p.value&lt;0.05)\n## # A tibble: 5 × 5\n##   term             estimate std.error statistic p.value\n##   &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n## 1 `ADAMTS9-AS1`low   -0.947     0.360     -2.63 0.00853\n## 2 AC093010.3low       0.905     0.323      2.80 0.00505\n## 3 SNHG25low           0.592     0.280      2.11 0.0346 \n## 4 AC025575.2low       0.618     0.287      2.16 0.0311 \n## 5 AL161431.1low      -0.704     0.309     -2.28 0.0226\n\n这5个变量可以用于最终的模型中，但是考虑到不同变量之间的交互作用等情况，此时再拟合多因素cox模型，可能还会出现某个变量的P值大于0.05的情况，属于正常现象~\n\nfit5 &lt;- coxph(Surv(time_months,event)~`ADAMTS9-AS1`+AC093010.3+SNHG25+\n                AC025575.2+AL161431.1,data = sub_dat)\nlibrary(survminer)\n## Loading required package: ggplot2\n## Warning: package 'ggplot2' was built under R version 4.2.3\n## Loading required package: ggpubr\n## \n## Attaching package: 'survminer'\n## The following object is masked from 'package:survival':\n## \n##     myeloma\nsurvminer::ggforest(fit5)\n## Warning in .get_data(model, data = data): The `data` argument is not provided.\n## Data will be extracted from model fit."
  },
  {
    "objectID": "feature-selection_unimulti.html#行代码实现",
    "href": "feature-selection_unimulti.html#行代码实现",
    "title": "12  变量筛选之先单后多",
    "section": "12.4 1行代码实现",
    "text": "12.4 1行代码实现\n手动实现的过程就是为了告诉大家思路是怎样的，这样大家有一定的基础就可以自己做，不管是什么数据，都是一样的思路，用什么方法和工具不重要，思路才是最重要的。\n下面再给大家介绍一个R包，可以实现1行代码完成先单后多cox分析，得到的结果和我们的手动实现的结果是一样的。\n首先安装R包：\n\n#install.packages(\"devtools\")\ndevtools::install_github(\"cardiomoon/autoReg\")\n\n\nlibrary(autoReg)\n\n使用autoReg函数可以实现先单后多cox分析，首先先建立cox模型，此时是多因素cox的形式，但是这个函数会自动帮我们提取数据，然后先批量对每个变量做cox。\n但是！乱七八糟的变量名字是不行的，比如我们演示用的这个lncRNA数据集，变量名字中有-，导致函数报错：\nfit &lt;- coxph(Surv(time_months,event)~., data = dat_cox)\n\nautoReg(fit,\n        threshold = 0.1,\n        uni = T,\n        multi = F\n        )\n\n# 报错\nError in parse(text = eq) : &lt;text&gt;:1:23: unexpected symbol\n1: df[['MIR1-1HG-AS1']]+1HG\n^\n我们给这个数据集的变量名字修改一下即可，我这里直接把-去掉了：\n\ncolnames(dat_cox)&lt;- gsub(\"-\",\"\",colnames(dat_cox))\ndat_cox[1:4,1:6]\n##   event time_months PGM5AS1 LINC01082 AC005180.2 AC005180.1\n## 1     0       36.33    high       low        low        low\n## 2     0       13.87     low       low       high       high\n## 3     1       21.83    high      high       high       high\n## 4     0       18.20    high      high       high       high\n\n这样变量名字中就没有乱七八糟的符号了，此时再进行分析就不会报错了。\n而且结果直接给出了三线表的格式，看起来非常整洁：\n\nfit &lt;- coxph(Surv(time_months,event)~., data = dat_cox)\n\nft &lt;- autoReg(fit,\n        threshold = 0.1,\n        uni = T, # 单因素分析\n        multi = T, # 多因素分析\n        final = F # 逐步法，向后\n        )\nft\n\n表格太长了，只展示部分：\n\n这个结果是可以导出为Word或者Excel格式的：\n\nlibrary(rrtable)\n\ntable2docx(ft)\n\n除此之外，这个包还是一个非常强大的三线表绘制R包，可以1行代码实现多种精美的三线表、回归分析（线性回归、逻辑回归、生存分析）结果表格，大家感兴趣的可以去官网学习：https://cardiomoon.github.io/autoReg/index.html"
  },
  {
    "objectID": "feature-selection_filter.html",
    "href": "feature-selection_filter.html",
    "title": "15  单变量过滤法",
    "section": "",
    "text": "本文节选自R语言机器学习系列合集。\n\n之前已经给大家介绍了临床预测模型和机器学习中特征选择(变量选择)常见的方法分类：\n\n机器学习中的特征选择(变量筛选)方法简介\n\n今天就给大家演示过滤法在caret中的实现。\n首先要理解过滤法，其实很简单，就是在建立模型前先根据一些标准把一些变量过滤掉，然后再建模。\n举个简单的例子，假如你的结果变量是二分类，自变量是数值型，那么对于每一个自变量，我们都可以以结果变量为分组变量，对自变量做方差分析，如果一个自变量在两个类别（也就是两个组别）中没有统计学差异，那这个变量就可以删掉了，因为它在两种类别中没有差别，并不能帮我们判断一个样本到底属于哪种类别。\n类似的还有t检验、卡方检验、等等，这些方法的选择在这里主要是根据预测变量和结果变量的类型。比如预测变量是二分类，结果变量也是二分类，此时就可以用卡方检验或者Fisher精确概率法等，如果预测变量是数值型而结果变量是二分类，就可以用方差分析、t检验等。对于学过医学统计学的人来说应该不会很难理解！\n除此之外，还有其他一些过滤法，这些都在之前的推文中有介绍：机器学习中的特征选择(变量筛选)方法简介\n过滤法又称为单变量过滤法(Univariate Filters)，在caret中使用sbf()函数实现。\n基本使用语法：\n\nsbf(predictors, outcome, sbfControl = sbfControl(), ...)\n## or\nsbf(formula, data, sbfControl = sbfControl(), ...)\n\nsbf()的参数解释如下：\n\nfunctions：用于设置模型拟合、预测和特征选择的一系列函数，可以是lmSBF(线性回归),rfSBF(随机森林),treebagSBF(袋装决策树),ldaSBF(线性判别分析法),nbSBF(朴素贝叶斯)和caretSBF(自定义函数)。\nmethod：指定抽样方法，可以是boot(BootStrap抽样),cv(交叉验证抽样),LOOCV(留一交叉验证法)和LGOCV(留组交叉验证法)。\nsaveDetails：是否保存特征选择过程中的预测值和变量重要性，默认为FALSE。\nnumber：指定折数或者重抽样迭代次数,当method为cv或repeatedcv时，则默认从总体中抽取10份样本并迭代10次，否则抽取25份并迭代25次。\nrepeats：指定抽样组数，默认抽取一组样本。\nverbose：是否返回每次重抽样的详细信息，默认为FALSE。\nreturnResamp：返回重抽样的汇总信息。\np：如果指定method为LGOCV时，该参数起作用，指定训练集的比重。\nseeds：为抽样设置随机种子。\nallowParallel：在并行后台已加载和允许的情况下，是否允许并行运算。\n\n下面是演示，使用随机森林，10折交叉验证，筛选变量\n\nlibrary(caret)\n## Loading required package: ggplot2\n## Warning: package 'ggplot2' was built under R version 4.2.3\n## Loading required package: lattice\n\n# 加载后会在当前环境下出现自变量数据框bbbDescr，因变量是logBBB\ndata(BloodBrain)\ndim(bbbDescr)\n## [1] 208 134\n\n可以看到这个数据有208行，134列！也就是有134个自变量！\n下面我们用过滤法去掉一部分：\n\nsbfControl &lt;- sbfControl(functions = rfSBF, # 选择随机森林\n                         verbose = FALSE,\n                         seeds = c(1:11),# 需要重抽样次数+1个整数\n                         method = \"cv\")\nset.seed(1)\nRFwithGAM &lt;- sbf(bbbDescr, logBBB,\n                 sbfControl = sbfControl\n                 )\nRFwithGAM\n## \n## Selection By Filter\n## \n## Outer resampling method: Cross-Validated (10 fold) \n## \n## Resampling performance:\n## \n##    RMSE Rsquared    MAE  RMSESD RsquaredSD   MAESD\n##  0.5032    0.588 0.3802 0.08017     0.1058 0.05726\n## \n## Using the training set, 88 variables were selected:\n##    tpsa, vsa_hyd, a_aro, peoe_vsa.1, peoe_vsa.3...\n## \n## During resampling, the top 5 selected variables (out of a possible 99):\n##    a_acc (100%), a_acid (100%), a_aro (100%), achg (100%), adistd (100%)\n## \n## On average, 88.7 variables were selected (min = 86, max = 91)\n\n查看筛选出的变量：\n\nRFwithGAM$optVariables\n##  [1] \"tpsa\"                 \"vsa_hyd\"              \"a_aro\"               \n##  [4] \"peoe_vsa.1\"           \"peoe_vsa.3\"           \"peoe_vsa.5\"          \n##  [7] \"peoe_vsa.1.1\"         \"peoe_vsa.5.1\"         \"peoe_vsa.6.1\"        \n## [10] \"a_acc\"                \"a_acid\"               \"vsa_acc\"             \n## [13] \"vsa_acid\"             \"vsa_base\"             \"vsa_don\"             \n## [16] \"vsa_other\"            \"slogp_vsa0\"           \"slogp_vsa1\"          \n## [19] \"slogp_vsa2\"           \"slogp_vsa6\"           \"slogp_vsa7\"          \n## [22] \"slogp_vsa8\"           \"smr_vsa0\"             \"smr_vsa2\"            \n## [25] \"smr_vsa4\"             \"smr_vsa5\"             \"tpsa.1\"              \n## [28] \"logp.o.w.\"            \"frac.cation7.\"        \"andrewbind\"          \n## [31] \"rotatablebonds\"       \"mlogp\"                \"clogp\"               \n## [34] \"nocount\"              \"hbdnr\"                \"rule.of.5violations\" \n## [37] \"prx\"                  \"pol\"                  \"inthb\"               \n## [40] \"adistm\"               \"adistd\"               \"polar_area\"          \n## [43] \"nonpolar_area\"        \"psa_npsa\"             \"tcsa\"                \n## [46] \"tcpa\"                 \"tcnp\"                 \"most_negative_charge\"\n## [49] \"most_positive_charge\" \"sum_absolute_charge\"  \"dipole_moment\"       \n## [52] \"ppsa3\"                \"pnsa2\"                \"pnsa3\"               \n## [55] \"fpsa2\"                \"fpsa3\"                \"fnsa2\"               \n## [58] \"fnsa3\"                \"wpsa3\"                \"wnsa3\"               \n## [61] \"dpsa3\"                \"rpcg\"                 \"wncs\"                \n## [64] \"sadh1\"                \"sadh2\"                \"sadh3\"               \n## [67] \"chdh1\"                \"chdh2\"                \"chdh3\"               \n## [70] \"scdh1\"                \"scdh2\"                \"scdh3\"               \n## [73] \"saaa1\"                \"saaa2\"                \"saaa3\"               \n## [76] \"chaa1\"                \"chaa3\"                \"scaa1\"               \n## [79] \"scaa2\"                \"scaa3\"                \"ctdh\"                \n## [82] \"ctaa\"                 \"mchg\"                 \"achg\"                \n## [85] \"rdta\"                 \"n_sp2\"                \"n_sp3\"               \n## [88] \"o_sp2\"\n\n一下子就从134个自变量晒到了88个！\n以上就是caret中过滤法简单的演示，更多的使用方法大家自己探索，但是说实话不是很好用……"
  }
]